{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20. MTL vs STL Comparison\n",
    "\n",
    "## Objective\n",
    "Compare Multi-Task Learning (MTL) vs Single-Task Learning (STL) for 3H disease prediction.\n",
    "\n",
    "## Hypothesis\n",
    "MTL may improve performance by learning shared representations across tasks.\n",
    "\n",
    "## Background\n",
    "From comorbidity analysis:\n",
    "- 3H diseases have weak direct correlation (Phi < 0.1)\n",
    "- HTN ↔ HG: OR=1.72 (moderate association)\n",
    "- HTN ↔ DL: OR=1.07 (nearly independent)\n",
    "\n",
    "## Date: 2026-01-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing PyTorch...\n",
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp37-cp37m-win_amd64.whl (162.6 MB)\n",
      "     ------------------------------------- 162.6/162.6 MB 12.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\joechiboo\\appdata\\local\\anaconda3\\envs\\ai\\lib\\site-packages (from torch) (4.4.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.1\n",
      "PyTorch installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch if not available\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch already installed: {torch.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Installing PyTorch...\")\n",
    "    !pip install torch\n",
    "    print(\"PyTorch installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded\n",
      "PyTorch version: 1.13.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "print(\"Packages loaded\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 13,514 samples, 6,056 patients\n",
      "\n",
      "Features: 26\n",
      "Tasks: ['HTN', 'HG', 'DL']\n",
      "\n",
      "Prevalence:\n",
      "  HTN: 19.3%\n",
      "  HG: 5.9%\n",
      "  DL: 7.9%\n"
     ]
    }
   ],
   "source": [
    "# Load sliding window data\n",
    "df = pd.read_csv('../../data/01_primary/SUA/processed/SUA_sliding_window.csv')\n",
    "print(f\"Data: {len(df):,} samples, {df['patient_id'].nunique():,} patients\")\n",
    "\n",
    "# Features\n",
    "feature_cols = [\n",
    "    'sex', 'Age',\n",
    "    'FBG_Tinput1', 'TC_Tinput1', 'Cr_Tinput1', 'UA_Tinput1', 'GFR_Tinput1', 'BMI_Tinput1', 'SBP_Tinput1', 'DBP_Tinput1',\n",
    "    'FBG_Tinput2', 'TC_Tinput2', 'Cr_Tinput2', 'UA_Tinput2', 'GFR_Tinput2', 'BMI_Tinput2', 'SBP_Tinput2', 'DBP_Tinput2',\n",
    "    'Delta_FBG', 'Delta_TC', 'Delta_Cr', 'Delta_UA', 'Delta_GFR', 'Delta_BMI', 'Delta_SBP', 'Delta_DBP'\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "groups = df['patient_id']\n",
    "\n",
    "# Targets (convert 1/2 to 0/1)\n",
    "y_htn = (df['hypertension_target'] == 2).astype(int)\n",
    "y_hg = (df['hyperglycemia_target'] == 2).astype(int)\n",
    "y_dl = (df['dyslipidemia_target'] == 2).astype(int)\n",
    "\n",
    "# Combined target matrix for MTL\n",
    "Y = pd.DataFrame({\n",
    "    'HTN': y_htn,\n",
    "    'HG': y_hg,\n",
    "    'DL': y_dl\n",
    "})\n",
    "\n",
    "print(f\"\\nFeatures: {len(feature_cols)}\")\n",
    "print(f\"Tasks: {list(Y.columns)}\")\n",
    "print(f\"\\nPrevalence:\")\n",
    "for col in Y.columns:\n",
    "    print(f\"  {col}: {Y[col].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Models\n",
    "\n",
    "### STL (Single-Task Learning)\n",
    "- 3 independent models, one for each disease\n",
    "\n",
    "### MTL (Multi-Task Learning)\n",
    "- 1 shared model predicting all 3 diseases simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models defined\n"
     ]
    }
   ],
   "source": [
    "# PyTorch MTL Model\n",
    "class MTLNetwork(nn.Module):\n",
    "    \"\"\"Multi-Task Learning Network with shared layers\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=[64, 32], n_tasks=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Shared layers\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        self.shared = nn.Sequential(*layers)\n",
    "        \n",
    "        # Task-specific heads\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Linear(hidden_dims[-1], 1) for _ in range(n_tasks)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shared_repr = self.shared(x)\n",
    "        outputs = [torch.sigmoid(head(shared_repr)) for head in self.heads]\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "\n",
    "class STLNetwork(nn.Module):\n",
    "    \"\"\"Single-Task Learning Network (same architecture, but independent)\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=[64, 32]):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(hidden_dims[-1], 1))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.network(x))\n",
    "\n",
    "print(\"Models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined\n"
     ]
    }
   ],
   "source": [
    "def train_mtl_model(X_train, Y_train, X_val, Y_val, epochs=100, lr=0.001, batch_size=256):\n",
    "    \"\"\"Train MTL model\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train_t = torch.FloatTensor(X_train).to(device)\n",
    "    Y_train_t = torch.FloatTensor(Y_train.values).to(device)\n",
    "    X_val_t = torch.FloatTensor(X_val).to(device)\n",
    "    Y_val_t = torch.FloatTensor(Y_val.values).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_t, Y_train_t)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Model\n",
    "    model = MTLNetwork(X_train.shape[1]).to(device)\n",
    "    \n",
    "    # Class weights for imbalanced data\n",
    "    pos_weights = []\n",
    "    for i in range(Y_train.shape[1]):\n",
    "        pos_rate = Y_train.iloc[:, i].mean()\n",
    "        pos_weights.append((1 - pos_rate) / pos_rate)\n",
    "    pos_weight = torch.FloatTensor(pos_weights).to(device)\n",
    "    \n",
    "    criterion = nn.BCELoss(reduction='none')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training\n",
    "    best_auc = 0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, Y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            \n",
    "            # Weighted loss\n",
    "            loss = criterion(outputs, Y_batch)\n",
    "            weights = torch.where(Y_batch == 1, pos_weight, torch.ones_like(Y_batch))\n",
    "            loss = (loss * weights).mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_t).cpu().numpy()\n",
    "            val_aucs = [roc_auc_score(Y_val.iloc[:, i], val_outputs[:, i]) for i in range(3)]\n",
    "            mean_auc = np.mean(val_aucs)\n",
    "            \n",
    "            if mean_auc > best_auc:\n",
    "                best_auc = mean_auc\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    break\n",
    "    \n",
    "    # Final prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_val_t).cpu().numpy()\n",
    "    \n",
    "    return predictions, model\n",
    "\n",
    "\n",
    "def train_stl_models(X_train, Y_train, X_val, Y_val, epochs=100, lr=0.001, batch_size=256):\n",
    "    \"\"\"Train 3 independent STL models\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    X_train_t = torch.FloatTensor(X_train).to(device)\n",
    "    X_val_t = torch.FloatTensor(X_val).to(device)\n",
    "    \n",
    "    all_predictions = []\n",
    "    models = []\n",
    "    \n",
    "    for task_idx in range(Y_train.shape[1]):\n",
    "        y_train = Y_train.iloc[:, task_idx].values\n",
    "        y_val = Y_val.iloc[:, task_idx].values\n",
    "        \n",
    "        y_train_t = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
    "        \n",
    "        train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        model = STLNetwork(X_train.shape[1]).to(device)\n",
    "        \n",
    "        # Class weight\n",
    "        pos_rate = y_train.mean()\n",
    "        pos_weight = torch.FloatTensor([(1 - pos_rate) / pos_rate]).to(device)\n",
    "        \n",
    "        criterion = nn.BCELoss(reduction='none')\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        best_auc = 0\n",
    "        patience = 10\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                \n",
    "                loss = criterion(outputs, y_batch)\n",
    "                weights = torch.where(y_batch == 1, pos_weight, torch.ones_like(y_batch))\n",
    "                loss = (loss * weights).mean()\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_pred = model(X_val_t).cpu().numpy().flatten()\n",
    "                val_auc = roc_auc_score(y_val, val_pred)\n",
    "                \n",
    "                if val_auc > best_auc:\n",
    "                    best_auc = val_auc\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        break\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(X_val_t).cpu().numpy().flatten()\n",
    "        \n",
    "        all_predictions.append(predictions)\n",
    "        models.append(model)\n",
    "    \n",
    "    return np.column_stack(all_predictions), models\n",
    "\n",
    "print(\"Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Experiment with 5-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "5-Fold CV: MTL vs STL\n",
      "======================================================================\n",
      "\n",
      "Fold 1/5\n",
      "  MTL: HTN=0.747, HG=0.924, DL=0.879 (12.1s)\n",
      "  STL: HTN=0.755, HG=0.923, DL=0.884 (8.8s)\n",
      "\n",
      "Fold 2/5\n",
      "  MTL: HTN=0.741, HG=0.930, DL=0.866 (9.3s)\n",
      "  STL: HTN=0.738, HG=0.935, DL=0.865 (10.1s)\n",
      "\n",
      "Fold 3/5\n",
      "  MTL: HTN=0.741, HG=0.927, DL=0.858 (8.5s)\n",
      "  STL: HTN=0.749, HG=0.928, DL=0.859 (11.3s)\n",
      "\n",
      "Fold 4/5\n",
      "  MTL: HTN=0.695, HG=0.937, DL=0.861 (7.5s)\n",
      "  STL: HTN=0.713, HG=0.936, DL=0.864 (14.4s)\n",
      "\n",
      "Fold 5/5\n",
      "  MTL: HTN=0.749, HG=0.941, DL=0.876 (7.4s)\n",
      "  STL: HTN=0.756, HG=0.942, DL=0.874 (9.7s)\n",
      "\n",
      "======================================================================\n",
      "CV Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold CV with GroupKFold\n",
    "n_splits = 5\n",
    "cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "results = {\n",
    "    'MTL': {'HTN': [], 'HG': [], 'DL': [], 'time': []},\n",
    "    'STL': {'HTN': [], 'HG': [], 'DL': [], 'time': []}\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"5-Fold CV: MTL vs STL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y_htn, groups)):\n",
    "    print(f\"\\nFold {fold+1}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "    \n",
    "    # Verify no leakage\n",
    "    train_patients = set(groups.iloc[train_idx])\n",
    "    test_patients = set(groups.iloc[test_idx])\n",
    "    assert len(train_patients & test_patients) == 0\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # --- MTL ---\n",
    "    start_time = time.time()\n",
    "    mtl_preds, _ = train_mtl_model(X_train_scaled, Y_train, X_test_scaled, Y_test)\n",
    "    mtl_time = time.time() - start_time\n",
    "    \n",
    "    for i, task in enumerate(['HTN', 'HG', 'DL']):\n",
    "        auc = roc_auc_score(Y_test.iloc[:, i], mtl_preds[:, i])\n",
    "        results['MTL'][task].append(auc)\n",
    "    results['MTL']['time'].append(mtl_time)\n",
    "    \n",
    "    print(f\"  MTL: HTN={results['MTL']['HTN'][-1]:.3f}, HG={results['MTL']['HG'][-1]:.3f}, DL={results['MTL']['DL'][-1]:.3f} ({mtl_time:.1f}s)\")\n",
    "    \n",
    "    # --- STL ---\n",
    "    start_time = time.time()\n",
    "    stl_preds, _ = train_stl_models(X_train_scaled, Y_train, X_test_scaled, Y_test)\n",
    "    stl_time = time.time() - start_time\n",
    "    \n",
    "    for i, task in enumerate(['HTN', 'HG', 'DL']):\n",
    "        auc = roc_auc_score(Y_test.iloc[:, i], stl_preds[:, i])\n",
    "        results['STL'][task].append(auc)\n",
    "    results['STL']['time'].append(stl_time)\n",
    "    \n",
    "    print(f\"  STL: HTN={results['STL']['HTN'][-1]:.3f}, HG={results['STL']['HG'][-1]:.3f}, DL={results['STL']['DL'][-1]:.3f} ({stl_time:.1f}s)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CV Complete\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Results: MTL vs STL (5-Fold CV)\n",
      "======================================================================\n",
      "\n",
      "AUC Comparison:\n",
      "Method    MTL    STL\n",
      "Task                \n",
      "DL      0.868  0.869\n",
      "HG      0.932  0.933\n",
      "HTN     0.734  0.742\n",
      "\n",
      "Training Time:\n",
      "  MTL: 9.0s per fold\n",
      "  STL: 10.9s per fold\n",
      "  Speedup: 1.21x\n"
     ]
    }
   ],
   "source": [
    "# Summary table\n",
    "print(\"=\"*70)\n",
    "print(\"Results: MTL vs STL (5-Fold CV)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary = []\n",
    "for method in ['MTL', 'STL']:\n",
    "    for task in ['HTN', 'HG', 'DL']:\n",
    "        aucs = results[method][task]\n",
    "        summary.append({\n",
    "            'Method': method,\n",
    "            'Task': task,\n",
    "            'AUC_mean': np.mean(aucs),\n",
    "            'AUC_std': np.std(aucs)\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"\\nAUC Comparison:\")\n",
    "print(summary_df.pivot(index='Task', columns='Method', values='AUC_mean').round(3))\n",
    "\n",
    "# Time comparison\n",
    "print(f\"\\nTraining Time:\")\n",
    "print(f\"  MTL: {np.mean(results['MTL']['time']):.1f}s per fold\")\n",
    "print(f\"  STL: {np.mean(results['STL']['time']):.1f}s per fold\")\n",
    "print(f\"  Speedup: {np.mean(results['STL']['time']) / np.mean(results['MTL']['time']):.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Detailed Comparison\n",
      "======================================================================\n",
      "\n",
      "| Task | MTL AUC | STL AUC | Diff | Winner |\n",
      "|------|---------|---------|------|--------|\n",
      "| HTN | 0.734 | 0.742 | -0.008 | STL |\n",
      "| HG | 0.932 | 0.933 | -0.001 | Tie |\n",
      "| DL | 0.868 | 0.869 | -0.001 | Tie |\n",
      "| **Avg** | 0.845 | 0.848 | -0.003 | STL |\n"
     ]
    }
   ],
   "source": [
    "# Detailed comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Detailed Comparison\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n| Task | MTL AUC | STL AUC | Diff | Winner |\")\n",
    "print(\"|------|---------|---------|------|--------|\")\n",
    "\n",
    "for task in ['HTN', 'HG', 'DL']:\n",
    "    mtl_auc = np.mean(results['MTL'][task])\n",
    "    stl_auc = np.mean(results['STL'][task])\n",
    "    diff = mtl_auc - stl_auc\n",
    "    winner = 'MTL' if diff > 0.005 else 'STL' if diff < -0.005 else 'Tie'\n",
    "    print(f\"| {task} | {mtl_auc:.3f} | {stl_auc:.3f} | {diff:+.3f} | {winner} |\")\n",
    "\n",
    "# Overall\n",
    "mtl_avg = np.mean([np.mean(results['MTL'][t]) for t in ['HTN', 'HG', 'DL']])\n",
    "stl_avg = np.mean([np.mean(results['STL'][t]) for t in ['HTN', 'HG', 'DL']])\n",
    "print(f\"| **Avg** | {mtl_avg:.3f} | {stl_avg:.3f} | {mtl_avg-stl_avg:+.3f} | {'MTL' if mtl_avg > stl_avg else 'STL'} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/mtl_vs_stl_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame([\n",
    "    {'Method': method, 'Task': task, 'Fold': fold+1, 'AUC': auc}\n",
    "    for method in ['MTL', 'STL']\n",
    "    for task in ['HTN', 'HG', 'DL']\n",
    "    for fold, auc in enumerate(results[method][task])\n",
    "])\n",
    "results_df.to_csv('../../results/mtl_vs_stl_results.csv', index=False)\n",
    "print(\"Saved: results/mtl_vs_stl_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Performance**: (fill after running)\n",
    "   - MTL vs STL difference: ~X%\n",
    "\n",
    "2. **Training Time**:\n",
    "   - MTL: faster (shared computation)\n",
    "   - STL: slower (3 independent models)\n",
    "\n",
    "3. **Why MTL may not outperform STL**:\n",
    "   - 3H diseases have weak correlation (Phi < 0.1)\n",
    "   - Sample size (13,514) is sufficient for STL\n",
    "   - Task difficulties vary (HG AUC=0.94 vs HTN AUC=0.74)\n",
    "\n",
    "### Implication\n",
    "\n",
    "For this dataset, STL and MTL perform similarly. \n",
    "MTL's benefit (shared representation) is limited when:\n",
    "- Tasks are weakly correlated\n",
    "- Data is sufficient for independent learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
