{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 20. 多任務學習 (MTL) vs 單任務學習 (STL) 比較\n\n## 目的\n比較多任務學習（MTL）與單任務學習（STL）在三高疾病預測上的表現。\n\n## 假說\nMTL 可能透過學習跨任務的共享表徵來提升預測效能。\n\n## 背景\n根據共病分析：\n- 三高疾病之間的直接相關性較弱（Phi < 0.1）\n- 高血壓 ↔ 高血糖：OR=1.72（中度關聯）\n- 高血壓 ↔ 高血脂：OR=1.07（近乎獨立）\n\n## 日期：2026-01-13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 安裝 PyTorch（若未安裝）\ntry:\n    import torch\n    print(f\"PyTorch 已安裝：{torch.__version__}\")\nexcept ImportError:\n    print(\"正在安裝 PyTorch...\")\n    !pip install torch\n    print(\"PyTorch 安裝完成\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 匯入套件\nimport pandas as pd\nimport numpy as np\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.base import clone\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nprint(\"套件載入完成\")\nprint(f\"PyTorch 版本：{torch.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. 載入資料"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 載入滑動視窗資料\ndf = pd.read_csv('../../data/01_primary/SUA/processed/SUA_sliding_window.csv')\nprint(f\"資料：{len(df):,} 筆樣本，{df['patient_id'].nunique():,} 位患者\")\n\n# 特徵\nfeature_cols = [\n    'sex', 'Age',\n    'FBG_Tinput1', 'TC_Tinput1', 'Cr_Tinput1', 'UA_Tinput1', 'GFR_Tinput1', 'BMI_Tinput1', 'SBP_Tinput1', 'DBP_Tinput1',\n    'FBG_Tinput2', 'TC_Tinput2', 'Cr_Tinput2', 'UA_Tinput2', 'GFR_Tinput2', 'BMI_Tinput2', 'SBP_Tinput2', 'DBP_Tinput2',\n    'Delta_FBG', 'Delta_TC', 'Delta_Cr', 'Delta_UA', 'Delta_GFR', 'Delta_BMI', 'Delta_SBP', 'Delta_DBP'\n]\n\nX = df[feature_cols]\ngroups = df['patient_id']\n\n# 目標變數（將 1/2 轉換為 0/1）\ny_htn = (df['hypertension_target'] == 2).astype(int)\ny_hg = (df['hyperglycemia_target'] == 2).astype(int)\ny_dl = (df['dyslipidemia_target'] == 2).astype(int)\n\n# MTL 用的組合目標矩陣\nY = pd.DataFrame({\n    'HTN': y_htn,\n    'HG': y_hg,\n    'DL': y_dl\n})\n\nprint(f\"\\n特徵數：{len(feature_cols)}\")\nprint(f\"任務：{list(Y.columns)}\")\nprint(f\"\\n盛行率：\")\nfor col in Y.columns:\n    print(f\"  {col}：{Y[col].mean()*100:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. 定義模型\n\n### STL（單任務學習）\n- 3 個獨立模型，各預測一種疾病\n\n### MTL（多任務學習）\n- 1 個共享模型，同時預測 3 種疾病"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# PyTorch MTL 模型\nclass MTLNetwork(nn.Module):\n    \"\"\"多任務學習網路（含共享層）\"\"\"\n    def __init__(self, input_dim, hidden_dims=[64, 32], n_tasks=3):\n        super().__init__()\n        \n        # 共享層\n        layers = []\n        prev_dim = input_dim\n        for h_dim in hidden_dims:\n            layers.extend([\n                nn.Linear(prev_dim, h_dim),\n                nn.ReLU(),\n                nn.Dropout(0.2)\n            ])\n            prev_dim = h_dim\n        self.shared = nn.Sequential(*layers)\n        \n        # 任務專屬輸出層\n        self.heads = nn.ModuleList([\n            nn.Linear(hidden_dims[-1], 1) for _ in range(n_tasks)\n        ])\n    \n    def forward(self, x):\n        shared_repr = self.shared(x)\n        outputs = [torch.sigmoid(head(shared_repr)) for head in self.heads]\n        return torch.cat(outputs, dim=1)\n\n\nclass STLNetwork(nn.Module):\n    \"\"\"單任務學習網路（相同架構，但獨立訓練）\"\"\"\n    def __init__(self, input_dim, hidden_dims=[64, 32]):\n        super().__init__()\n        \n        layers = []\n        prev_dim = input_dim\n        for h_dim in hidden_dims:\n            layers.extend([\n                nn.Linear(prev_dim, h_dim),\n                nn.ReLU(),\n                nn.Dropout(0.2)\n            ])\n            prev_dim = h_dim\n        layers.append(nn.Linear(hidden_dims[-1], 1))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return torch.sigmoid(self.network(x))\n\nprint(\"模型定義完成\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_mtl_model(X_train, Y_train, X_val, Y_val, epochs=100, lr=0.001, batch_size=256):\n    \"\"\"訓練 MTL 模型\"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # 準備資料\n    X_train_t = torch.FloatTensor(X_train).to(device)\n    Y_train_t = torch.FloatTensor(Y_train.values).to(device)\n    X_val_t = torch.FloatTensor(X_val).to(device)\n    Y_val_t = torch.FloatTensor(Y_val.values).to(device)\n    \n    train_dataset = TensorDataset(X_train_t, Y_train_t)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    \n    # 模型\n    model = MTLNetwork(X_train.shape[1]).to(device)\n    \n    # 類別權重（處理不平衡資料）\n    pos_weights = []\n    for i in range(Y_train.shape[1]):\n        pos_rate = Y_train.iloc[:, i].mean()\n        pos_weights.append((1 - pos_rate) / pos_rate)\n    pos_weight = torch.FloatTensor(pos_weights).to(device)\n    \n    criterion = nn.BCELoss(reduction='none')\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    # 訓練\n    best_auc = 0\n    patience = 10\n    patience_counter = 0\n    \n    for epoch in range(epochs):\n        model.train()\n        for X_batch, Y_batch in train_loader:\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            \n            # 加權損失\n            loss = criterion(outputs, Y_batch)\n            weights = torch.where(Y_batch == 1, pos_weight, torch.ones_like(Y_batch))\n            loss = (loss * weights).mean()\n            \n            loss.backward()\n            optimizer.step()\n        \n        # 驗證\n        model.eval()\n        with torch.no_grad():\n            val_outputs = model(X_val_t).cpu().numpy()\n            val_aucs = [roc_auc_score(Y_val.iloc[:, i], val_outputs[:, i]) for i in range(3)]\n            mean_auc = np.mean(val_aucs)\n            \n            if mean_auc > best_auc:\n                best_auc = mean_auc\n                patience_counter = 0\n            else:\n                patience_counter += 1\n                if patience_counter >= patience:\n                    break\n    \n    # 最終預測\n    model.eval()\n    with torch.no_grad():\n        predictions = model(X_val_t).cpu().numpy()\n    \n    return predictions, model\n\n\ndef train_stl_models(X_train, Y_train, X_val, Y_val, epochs=100, lr=0.001, batch_size=256):\n    \"\"\"訓練 3 個獨立的 STL 模型\"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    X_train_t = torch.FloatTensor(X_train).to(device)\n    X_val_t = torch.FloatTensor(X_val).to(device)\n    \n    all_predictions = []\n    models = []\n    \n    for task_idx in range(Y_train.shape[1]):\n        y_train = Y_train.iloc[:, task_idx].values\n        y_val = Y_val.iloc[:, task_idx].values\n        \n        y_train_t = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n        \n        train_dataset = TensorDataset(X_train_t, y_train_t)\n        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n        \n        model = STLNetwork(X_train.shape[1]).to(device)\n        \n        # 類別權重\n        pos_rate = y_train.mean()\n        pos_weight = torch.FloatTensor([(1 - pos_rate) / pos_rate]).to(device)\n        \n        criterion = nn.BCELoss(reduction='none')\n        optimizer = optim.Adam(model.parameters(), lr=lr)\n        \n        best_auc = 0\n        patience = 10\n        patience_counter = 0\n        \n        for epoch in range(epochs):\n            model.train()\n            for X_batch, y_batch in train_loader:\n                optimizer.zero_grad()\n                outputs = model(X_batch)\n                \n                loss = criterion(outputs, y_batch)\n                weights = torch.where(y_batch == 1, pos_weight, torch.ones_like(y_batch))\n                loss = (loss * weights).mean()\n                \n                loss.backward()\n                optimizer.step()\n            \n            model.eval()\n            with torch.no_grad():\n                val_pred = model(X_val_t).cpu().numpy().flatten()\n                val_auc = roc_auc_score(y_val, val_pred)\n                \n                if val_auc > best_auc:\n                    best_auc = val_auc\n                    patience_counter = 0\n                else:\n                    patience_counter += 1\n                    if patience_counter >= patience:\n                        break\n        \n        model.eval()\n        with torch.no_grad():\n            predictions = model(X_val_t).cpu().numpy().flatten()\n        \n        all_predictions.append(predictions)\n        models.append(model)\n    \n    return np.column_stack(all_predictions), models\n\nprint(\"訓練函式定義完成\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. 執行 5-Fold 交叉驗證實驗"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 5-Fold CV（GroupKFold）\nn_splits = 5\ncv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\nresults = {\n    'MTL': {'HTN': [], 'HG': [], 'DL': [], 'time': []},\n    'STL': {'HTN': [], 'HG': [], 'DL': [], 'time': []}\n}\n\nprint(\"=\" * 70)\nprint(\"5-Fold CV：MTL vs STL\")\nprint(\"=\" * 70)\n\nfor fold, (train_idx, test_idx) in enumerate(cv.split(X, y_htn, groups)):\n    print(f\"\\nFold {fold+1}/{n_splits}\")\n    \n    # 資料分割\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n    \n    # 驗證無資料洩漏\n    train_patients = set(groups.iloc[train_idx])\n    test_patients = set(groups.iloc[test_idx])\n    assert len(train_patients & test_patients) == 0\n    \n    # 標準化\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # --- MTL ---\n    start_time = time.time()\n    mtl_preds, _ = train_mtl_model(X_train_scaled, Y_train, X_test_scaled, Y_test)\n    mtl_time = time.time() - start_time\n    \n    for i, task in enumerate(['HTN', 'HG', 'DL']):\n        auc = roc_auc_score(Y_test.iloc[:, i], mtl_preds[:, i])\n        results['MTL'][task].append(auc)\n    results['MTL']['time'].append(mtl_time)\n    \n    print(f\"  MTL: HTN={results['MTL']['HTN'][-1]:.3f}, HG={results['MTL']['HG'][-1]:.3f}, DL={results['MTL']['DL'][-1]:.3f} ({mtl_time:.1f}s)\")\n    \n    # --- STL ---\n    start_time = time.time()\n    stl_preds, _ = train_stl_models(X_train_scaled, Y_train, X_test_scaled, Y_test)\n    stl_time = time.time() - start_time\n    \n    for i, task in enumerate(['HTN', 'HG', 'DL']):\n        auc = roc_auc_score(Y_test.iloc[:, i], stl_preds[:, i])\n        results['STL'][task].append(auc)\n    results['STL']['time'].append(stl_time)\n    \n    print(f\"  STL: HTN={results['STL']['HTN'][-1]:.3f}, HG={results['STL']['HG'][-1]:.3f}, DL={results['STL']['DL'][-1]:.3f} ({stl_time:.1f}s)\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"交叉驗證完成\")\nprint(\"=\" * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. 結果摘要"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 摘要表格\nprint(\"=\" * 70)\nprint(\"結果：MTL vs STL（5-Fold CV）\")\nprint(\"=\" * 70)\n\nsummary = []\nfor method in ['MTL', 'STL']:\n    for task in ['HTN', 'HG', 'DL']:\n        aucs = results[method][task]\n        summary.append({\n            '方法': method,\n            '任務': task,\n            'AUC_mean': np.mean(aucs),\n            'AUC_std': np.std(aucs)\n        })\n\nsummary_df = pd.DataFrame(summary)\nprint(\"\\nAUC 比較：\")\nprint(summary_df.pivot(index='任務', columns='方法', values='AUC_mean').round(3))\n\n# 訓練時間比較\nprint(f\"\\n訓練時間：\")\nprint(f\"  MTL：{np.mean(results['MTL']['time']):.1f}s / fold\")\nprint(f\"  STL：{np.mean(results['STL']['time']):.1f}s / fold\")\nprint(f\"  加速比：{np.mean(results['STL']['time']) / np.mean(results['MTL']['time']):.2f}x\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 詳細比較\nprint(\"\\n\" + \"=\" * 70)\nprint(\"詳細比較\")\nprint(\"=\" * 70)\n\nprint(\"\\n| 任務 | MTL AUC | STL AUC | 差異 | 勝出 |\")\nprint(\"|------|---------|---------|------|------|\")\n\nfor task in ['HTN', 'HG', 'DL']:\n    mtl_auc = np.mean(results['MTL'][task])\n    stl_auc = np.mean(results['STL'][task])\n    diff = mtl_auc - stl_auc\n    winner = 'MTL' if diff > 0.005 else 'STL' if diff < -0.005 else '持平'\n    print(f\"| {task} | {mtl_auc:.3f} | {stl_auc:.3f} | {diff:+.3f} | {winner} |\")\n\n# 整體\nmtl_avg = np.mean([np.mean(results['MTL'][t]) for t in ['HTN', 'HG', 'DL']])\nstl_avg = np.mean([np.mean(results['STL'][t]) for t in ['HTN', 'HG', 'DL']])\nprint(f\"| **平均** | {mtl_avg:.3f} | {stl_avg:.3f} | {mtl_avg-stl_avg:+.3f} | {'MTL' if mtl_avg > stl_avg else 'STL'} |\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 儲存結果\nresults_df = pd.DataFrame([\n    {'方法': method, '任務': task, 'Fold': fold+1, 'AUC': auc}\n    for method in ['MTL', 'STL']\n    for task in ['HTN', 'HG', 'DL']\n    for fold, auc in enumerate(results[method][task])\n])\nresults_df.to_csv('../../results/mtl_vs_stl_results.csv', index=False)\nprint(\"已儲存：results/mtl_vs_stl_results.csv\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. 結論\n\n### 主要發現\n\n1. **預測效能**：\n   - MTL 與 STL 差異約 ~0.3%，無顯著差異\n\n2. **訓練時間**：\n   - MTL：較快（共享計算）\n   - STL：較慢（3 個獨立模型）\n\n3. **MTL 未能超越 STL 的可能原因**：\n   - 三高疾病之間的相關性弱（Phi < 0.1）\n   - 樣本數（13,514）對 STL 而言已足夠\n   - 各任務難度差異大（HG AUC=0.94 vs HTN AUC=0.74）\n\n### 結論\n\n在本資料集上，STL 與 MTL 表現相近。\n當以下情況成立時，MTL 的優勢（共享表徵）有限：\n- 任務之間相關性弱\n- 資料量足以進行獨立學習"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}