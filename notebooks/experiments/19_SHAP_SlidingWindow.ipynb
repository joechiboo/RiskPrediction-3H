{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19. SHAP Analysis (Sliding Window Data)\n",
    "\n",
    "## Changes from Notebook 08\n",
    "- **Data**: Using sliding window dataset (13,514 samples)\n",
    "- **Features**: Tinput1, Tinput2, Delta_ format\n",
    "- **Note**: This replaces 08_SHAP_Analysis for thesis results\n",
    "\n",
    "## Date: 2026-01-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial']\n",
    "plt.rcParams['axes.unicode_minus'] = True\n",
    "\n",
    "print(f\"SHAP version: {shap.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sliding Window Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sliding window data\n",
    "df = pd.read_csv('../../data/01_primary/SUA/processed/SUA_sliding_window.csv')\n",
    "print(f\"Data loaded: {len(df):,} samples from {df['patient_id'].nunique():,} patients\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "feature_cols = [\n",
    "    'sex', 'Age',\n",
    "    # Tinput1 features\n",
    "    'FBG_Tinput1', 'TC_Tinput1', 'Cr_Tinput1', 'UA_Tinput1', 'GFR_Tinput1', 'BMI_Tinput1', 'SBP_Tinput1', 'DBP_Tinput1',\n",
    "    # Tinput2 features\n",
    "    'FBG_Tinput2', 'TC_Tinput2', 'Cr_Tinput2', 'UA_Tinput2', 'GFR_Tinput2', 'BMI_Tinput2', 'SBP_Tinput2', 'DBP_Tinput2',\n",
    "    # Delta features\n",
    "    'Delta_FBG', 'Delta_TC', 'Delta_Cr', 'Delta_UA', 'Delta_GFR', 'Delta_BMI', 'Delta_SBP', 'Delta_DBP'\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Target variables (convert 1/2 to 0/1)\n",
    "targets = {\n",
    "    'Hypertension': (df['hypertension_target'] == 2).astype(int),\n",
    "    'Hyperglycemia': (df['hyperglycemia_target'] == 2).astype(int),\n",
    "    'Dyslipidemia': (df['dyslipidemia_target'] == 2).astype(int)\n",
    "}\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "for name, y in targets.items():\n",
    "    print(f\"  {name}: {y.mean()*100:.2f}% positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (use Hypertension for stratification)\n",
    "X_train, X_test, y_train_dict, y_test_dict = {}, {}, {}, {}\n",
    "\n",
    "# Split once, apply to all targets\n",
    "train_idx, test_idx = train_test_split(\n",
    "    df.index, test_size=0.2, random_state=42, \n",
    "    stratify=targets['Hypertension']\n",
    ")\n",
    "\n",
    "X_train = X.loc[train_idx]\n",
    "X_test = X.loc[test_idx]\n",
    "\n",
    "for name, y in targets.items():\n",
    "    y_train_dict[name] = y.loc[train_idx]\n",
    "    y_test_dict[name] = y.loc[test_idx]\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for SHAP\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=feature_cols, index=X_train.index)\n",
    "X_test_df = pd.DataFrame(X_test_scaled, columns=feature_cols, index=X_test.index)\n",
    "\n",
    "print(f\"Train: {len(X_train):,} samples\")\n",
    "print(f\"Test: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost models\n",
    "xgb_models = {}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Training XGBoost Models\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for disease in targets.keys():\n",
    "    y_train = y_train_dict[disease]\n",
    "    y_test = y_test_dict[disease]\n",
    "    \n",
    "    # Calculate scale_pos_weight\n",
    "    spw = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        scale_pos_weight=spw,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    xgb_models[disease] = model\n",
    "    print(f\"{disease}: AUC = {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SHAP Analysis - All Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values for all diseases\n",
    "shap_values_dict = {}\n",
    "explainer_dict = {}\n",
    "\n",
    "for disease, model in xgb_models.items():\n",
    "    print(f\"Computing SHAP values for {disease}...\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test_df)\n",
    "    \n",
    "    explainer_dict[disease] = explainer\n",
    "    shap_values_dict[disease] = shap_values\n",
    "    print(f\"  Done. Shape: {shap_values.shape}\")\n",
    "\n",
    "print(\"\\nAll SHAP values computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plots for each disease\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, (disease, shap_values) in enumerate(shap_values_dict.items()):\n",
    "    plt.sca(axes[idx])\n",
    "    shap.summary_plot(shap_values, X_test_df, plot_type=\"bar\", show=False, max_display=15)\n",
    "    axes[idx].set_title(f'{disease}', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('SHAP Feature Importance (Sliding Window Data)', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/shap_sliding_window_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/shap_sliding_window_importance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 8))\n",
    "\n",
    "for idx, (disease, shap_values) in enumerate(shap_values_dict.items()):\n",
    "    plt.sca(axes[idx])\n",
    "    shap.summary_plot(shap_values, X_test_df, show=False, max_display=15)\n",
    "    axes[idx].set_title(f'{disease}', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('SHAP Beeswarm Plots (Sliding Window Data)', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/shap_sliding_window_beeswarm.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/shap_sliding_window_beeswarm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean |SHAP| for each disease\n",
    "importance_df = pd.DataFrame({'Feature': feature_cols})\n",
    "\n",
    "for disease, shap_values in shap_values_dict.items():\n",
    "    importance_df[disease] = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# Sort by Hypertension importance\n",
    "importance_df = importance_df.sort_values('Hypertension', ascending=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SHAP Feature Importance (Top 15)\")\n",
    "print(\"=\"*80)\n",
    "print(importance_df.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize features\n",
    "def categorize_feature(name):\n",
    "    if name in ['sex', 'Age']:\n",
    "        return 'Demographics'\n",
    "    elif 'Tinput1' in name:\n",
    "        return 'Tinput1'\n",
    "    elif 'Tinput2' in name:\n",
    "        return 'Tinput2'\n",
    "    elif 'Delta' in name:\n",
    "        return 'Delta'\n",
    "    return 'Other'\n",
    "\n",
    "importance_df['Category'] = importance_df['Feature'].apply(categorize_feature)\n",
    "\n",
    "# Aggregate by category\n",
    "category_importance = importance_df.groupby('Category')[['Hypertension', 'Hyperglycemia', 'Dyslipidemia']].sum()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Feature Category Importance\")\n",
    "print(\"=\"*60)\n",
    "print(category_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize category importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "category_importance.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_xlabel('Feature Category', fontsize=12)\n",
    "ax.set_ylabel('Total |SHAP value|', fontsize=12)\n",
    "ax.set_title('Feature Category Importance (Tinput1 vs Tinput2 vs Delta)', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Disease', fontsize=10)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/shap_sliding_window_category.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/shap_sliding_window_category.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full results\n",
    "importance_df.to_csv('../../results/shap_sliding_window_importance.csv', index=False)\n",
    "print(\"Saved: results/shap_sliding_window_importance.csv\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Summary\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\"\"\n",
    "Data:\n",
    "  - Samples: {len(df):,} (sliding window)\n",
    "  - Patients: {df['patient_id'].nunique():,}\n",
    "  - Features: {len(feature_cols)}\n",
    "\n",
    "Top Features by Disease:\n",
    "\"\"\")\n",
    "\n",
    "for disease in ['Hypertension', 'Hyperglycemia', 'Dyslipidemia']:\n",
    "    top3 = importance_df.nlargest(3, disease)[['Feature', disease]]\n",
    "    print(f\"  {disease}:\")\n",
    "    for _, row in top3.iterrows():\n",
    "        print(f\"    - {row['Feature']}: {row[disease]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "This notebook uses the sliding window dataset (13,514 samples) for SHAP analysis.\n",
    "\n",
    "Key findings will be compared with the original 08_SHAP_Analysis results to verify consistency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
