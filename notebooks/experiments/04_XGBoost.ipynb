{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. XGBoost æ¨¡å‹å¯¦é©—\n",
    "\n",
    "## ğŸ“– å¯¦é©—ç›®æ¨™\n",
    "\n",
    "åœ¨ 03_ModelBuilding ä¸­ï¼Œæˆ‘å€‘ç™¼ç¾ï¼š\n",
    "- âœ… **é«˜è¡€å£“**: MTL LR (balanced) è¡¨ç¾è‰¯å¥½ (AUC=0.749)\n",
    "- âš ï¸ **é«˜è¡€ç³–**: AUC â‰ˆ 0.507 (æ¥è¿‘éš¨æ©ŸçŒœæ¸¬)\n",
    "- âš ï¸ **é«˜è¡€è„‚**: AUC â‰ˆ 0.566 (ç•¥å„ªæ–¼éš¨æ©Ÿ)\n",
    "\n",
    "**æ ¸å¿ƒå•é¡Œ**: Logistic Regression å’Œ Random Forest åœ¨æ¥µåº¦ä¸å¹³è¡¡è³‡æ–™ä¸Šè¡¨ç¾å—é™ã€‚\n",
    "\n",
    "æœ¬ notebook å°‡æ¸¬è©¦ **XGBoost**ï¼Œç†ç”±ï¼š\n",
    "1. ğŸ¯ **å°ˆé–€è™•ç†ä¸å¹³è¡¡è³‡æ–™**: ä½¿ç”¨ `scale_pos_weight` åƒæ•¸\n",
    "2. ğŸš€ **é€šå¸¸å„ªæ–¼ RF**: åœ¨è¡¨æ ¼è³‡æ–™ä¸Šçš„ SOTA æ¨¡å‹\n",
    "3. ğŸ“Š **å¯èƒ½æ”¹å–„ AUC**: ç‰¹åˆ¥æ˜¯é«˜è¡€ç³–å’Œé«˜è¡€è„‚\n",
    "4. âš¡ **è¨“ç·´é€Ÿåº¦å¿«**: æ¯” SVM å’Œç¥ç¶“ç¶²è·¯æ›´å¿«\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ å¯¦é©—æµç¨‹\n",
    "\n",
    "1. è¼‰å…¥è³‡æ–™ï¼ˆä½¿ç”¨èˆ‡ 03 ç›¸åŒçš„è³‡æ–™è™•ç†ï¼‰\n",
    "2. å–®ä»»å‹™ XGBoostï¼ˆä¸‰ç¨®ç–¾ç—…åˆ†åˆ¥è¨“ç·´ï¼‰\n",
    "3. MTL XGBoostï¼ˆä½¿ç”¨ MultiOutputClassifierï¼‰\n",
    "4. æ•ˆèƒ½æ¯”è¼ƒèˆ‡åˆ†æ\n",
    "5. èˆ‡ 03 çš„æœ€ä½³æ¨¡å‹ï¼ˆMTL LR balancedï¼‰æ¯”è¼ƒ\n",
    "6. çµè«–èˆ‡å»ºè­°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. è¼‰å…¥å¥—ä»¶èˆ‡è³‡æ–™\n\n> **æ³¨æ„**: å¦‚æœå°šæœªå®‰è£ XGBoostï¼Œè«‹å…ˆåŸ·è¡Œä¸‹æ–¹çš„å®‰è£æŒ‡ä»¤ã€‚"
  },
  {
   "cell_type": "code",
   "source": "# å®‰è£ XGBoost å¥—ä»¶\nimport sys\n!{sys.executable} -m pip install xgboost",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34248\\3307137517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# XGBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# åŸºç¤å¥—ä»¶\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# æ©Ÿå™¨å­¸ç¿’å¥—ä»¶\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# è¨­å®š\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'sans-serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… å¥—ä»¶è¼‰å…¥å®Œæˆ\")\n",
    "print(f\"XGBoost ç‰ˆæœ¬: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥è³‡æ–™\n",
    "df = pd.read_csv('../../data/processed/health_data_with_delta.csv')\n",
    "\n",
    "print(\"âœ… è³‡æ–™è¼‰å…¥æˆåŠŸï¼\")\n",
    "print(f\"è³‡æ–™å½¢ç‹€: {df.shape[0]:,} äºº, {df.shape[1]} å€‹æ¬„ä½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æº–å‚™ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸\n",
    "\n",
    "ä½¿ç”¨èˆ‡ 03 ç›¸åŒçš„ç‰¹å¾µé›†ï¼š\n",
    "- äººå£çµ±è¨ˆ: sex, Age\n",
    "- T1 ç‰¹å¾µ: 8 å€‹ç”Ÿç†æŒ‡æ¨™\n",
    "- T2 ç‰¹å¾µ: 8 å€‹ç”Ÿç†æŒ‡æ¨™\n",
    "- Î”1 ç‰¹å¾µ: 8 å€‹è®ŠåŒ–é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©ç‰¹å¾µçµ„\n",
    "demographic_features = ['sex', 'Age']\n",
    "biomarker_names = ['FBG', 'TC', 'Cr', 'UA', 'GFR', 'BMI', 'SBP', 'DBP']\n",
    "t1_features = [f'{name}_T1' for name in biomarker_names]\n",
    "t2_features = [f'{name}_T2' for name in biomarker_names]\n",
    "delta1_features = [f'Delta1_{name}' for name in biomarker_names]\n",
    "\n",
    "# å®Œæ•´ç‰¹å¾µé›†\n",
    "X_columns = demographic_features + t1_features + t2_features + delta1_features\n",
    "X = df[X_columns]\n",
    "\n",
    "# ç›®æ¨™è®Šæ•¸ï¼ˆè½‰æ›ç‚º 0/1ï¼‰\n",
    "y_hypertension = (df['hypertension_T3'] == 2).astype(int)\n",
    "y_hyperglycemia = (df['hyperglycemia_T3'] == 2).astype(int)\n",
    "y_dyslipidemia = (df['dyslipidemia_T3'] == 2).astype(int)\n",
    "\n",
    "# MTL ç›®æ¨™è®Šæ•¸\n",
    "y_multi = np.column_stack([y_hypertension, y_hyperglycemia, y_dyslipidemia])\n",
    "\n",
    "print(f\"ç‰¹å¾µæ•¸: {len(X_columns)} å€‹\")\n",
    "print(f\"\\nç›®æ¨™è®Šæ•¸åˆ†ä½ˆ:\")\n",
    "print(f\"  é«˜è¡€å£“æ‚£ç—…ç‡: {y_hypertension.mean():.2%}\")\n",
    "print(f\"  é«˜è¡€ç³–æ‚£ç—…ç‡: {y_hyperglycemia.mean():.2%}\")\n",
    "print(f\"  é«˜è¡€è„‚æ‚£ç—…ç‡: {y_dyslipidemia.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. è³‡æ–™åˆ†å‰²èˆ‡æ¨™æº–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è³‡æ–™åˆ†å‰²ï¼ˆèˆ‡ 03 ä½¿ç”¨ç›¸åŒçš„ random_state ç¢ºä¿å¯æ¯”è¼ƒæ€§ï¼‰\n",
    "X_train, X_test, y_train_multi, y_test_multi = train_test_split(\n",
    "    X, y_multi, test_size=0.2, random_state=42, stratify=y_hypertension\n",
    ")\n",
    "\n",
    "# åˆ†é›¢ä¸‰å€‹ç›®æ¨™è®Šæ•¸\n",
    "y_train_hp = y_train_multi[:, 0]\n",
    "y_train_hg = y_train_multi[:, 1]\n",
    "y_train_dl = y_train_multi[:, 2]\n",
    "\n",
    "y_test_hp = y_test_multi[:, 0]\n",
    "y_test_hg = y_test_multi[:, 1]\n",
    "y_test_dl = y_test_multi[:, 2]\n",
    "\n",
    "# æ¨™æº–åŒ–\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ… è³‡æ–™æº–å‚™å®Œæˆ\")\n",
    "print(f\"è¨“ç·´é›†: {X_train_scaled.shape[0]} äºº\")\n",
    "print(f\"æ¸¬è©¦é›†: {X_test_scaled.shape[0]} äºº\")\n",
    "print(f\"ç‰¹å¾µæ•¸: {X_train_scaled.shape[1]} å€‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è¨ˆç®— scale_pos_weight\n",
    "\n",
    "XGBoost ä½¿ç”¨ `scale_pos_weight` åƒæ•¸è™•ç†é¡åˆ¥ä¸å¹³è¡¡ï¼š\n",
    "- è¨ˆç®—å…¬å¼: `scale_pos_weight = è² æ¨£æœ¬æ•¸ / æ­£æ¨£æœ¬æ•¸`\n",
    "- æ•ˆæœ: çµ¦äºˆå°‘æ•¸é¡åˆ¥æ›´é«˜çš„æ¬Šé‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ˆç®—æ¯å€‹ç–¾ç—…çš„ scale_pos_weight\n",
    "def calculate_scale_pos_weight(y):\n",
    "    n_positive = np.sum(y == 1)\n",
    "    n_negative = np.sum(y == 0)\n",
    "    return n_negative / n_positive\n",
    "\n",
    "scale_pos_weight_hp = calculate_scale_pos_weight(y_train_hp)\n",
    "scale_pos_weight_hg = calculate_scale_pos_weight(y_train_hg)\n",
    "scale_pos_weight_dl = calculate_scale_pos_weight(y_train_dl)\n",
    "\n",
    "print(\"======================================================================\")\n",
    "print(\"scale_pos_weight è¨ˆç®—çµæœ\")\n",
    "print(\"======================================================================\")\n",
    "print(f\"é«˜è¡€å£“: {scale_pos_weight_hp:.1f}\")\n",
    "print(f\"é«˜è¡€ç³–: {scale_pos_weight_hg:.1f}\")\n",
    "print(f\"é«˜è¡€è„‚: {scale_pos_weight_dl:.1f}\")\n",
    "print(\"\\nğŸ’¡ æ•¸å€¼è¶Šå¤§è¡¨ç¤ºé¡åˆ¥ä¸å¹³è¡¡è¶Šåš´é‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å–®ä»»å‹™ XGBoost\n",
    "\n",
    "åˆ†åˆ¥è¨“ç·´ä¸‰å€‹ XGBoost æ¨¡å‹ï¼Œæ¯å€‹æ¨¡å‹é æ¸¬ä¸€ç¨®ç–¾ç—…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´ä¸‰å€‹å–®ä»»å‹™ XGBoost æ¨¡å‹\n",
    "diseases = ['é«˜è¡€å£“', 'é«˜è¡€ç³–', 'é«˜è¡€è„‚']\n",
    "y_trains = [y_train_hp, y_train_hg, y_train_dl]\n",
    "y_tests = [y_test_hp, y_test_hg, y_test_dl]\n",
    "scale_pos_weights = [scale_pos_weight_hp, scale_pos_weight_hg, scale_pos_weight_dl]\n",
    "\n",
    "xgb_models = {}\n",
    "xgb_results = []\n",
    "\n",
    "print(\"======================================================================\")\n",
    "print(\"å–®ä»»å‹™ XGBoost è¨“ç·´ä¸­...\")\n",
    "print(\"======================================================================\\n\")\n",
    "\n",
    "for disease, y_train, y_test, scale_weight in zip(diseases, y_trains, y_tests, scale_pos_weights):\n",
    "    print(f\"è¨“ç·´ {disease} æ¨¡å‹...\")\n",
    "    \n",
    "    # å»ºç«‹ XGBoost æ¨¡å‹\n",
    "    model = XGBClassifier(\n",
    "        scale_pos_weight=scale_weight,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    # è¨“ç·´\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # é æ¸¬\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # è¨ˆç®—æŒ‡æ¨™\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    # å„²å­˜çµæœ\n",
    "    xgb_models[disease] = model\n",
    "    xgb_results.append({\n",
    "        'ç–¾ç—…': disease,\n",
    "        'AUC': auc,\n",
    "        'F1': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    })\n",
    "    \n",
    "    # è¼¸å‡ºçµæœ\n",
    "    print(f\"{disease}:\")\n",
    "    print(f\"  AUC:       {auc:.3f}\")\n",
    "    print(f\"  F1:        {f1:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall:    {recall:.3f}\")\n",
    "    \n",
    "    # æ··æ·†çŸ©é™£\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(f\"  æ··æ·†çŸ©é™£: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
    "    print()\n",
    "\n",
    "print(\"âœ… å–®ä»»å‹™ XGBoost è¨“ç·´å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MTL XGBoost\n",
    "\n",
    "ä½¿ç”¨ `MultiOutputClassifier` åŒæ™‚é æ¸¬ä¸‰ç¨®ç–¾ç—…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======================================================================\")\n",
    "print(\"MTL XGBoost è¨“ç·´ä¸­...\")\n",
    "print(\"======================================================================\\n\")\n",
    "\n",
    "# å»ºç«‹ MTL XGBoostï¼ˆä½¿ç”¨å¹³å‡ scale_pos_weightï¼‰\n",
    "avg_scale_weight = np.mean(scale_pos_weights)\n",
    "\n",
    "mtl_xgb = MultiOutputClassifier(\n",
    "    XGBClassifier(\n",
    "        scale_pos_weight=avg_scale_weight,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    ")\n",
    "\n",
    "# è¨“ç·´\n",
    "mtl_xgb.fit(X_train_scaled, y_train_multi)\n",
    "\n",
    "# é æ¸¬\n",
    "y_pred_multi = mtl_xgb.predict(X_test_scaled)\n",
    "\n",
    "mtl_xgb_results = []\n",
    "\n",
    "for i, disease in enumerate(diseases):\n",
    "    y_test = y_test_multi[:, i]\n",
    "    y_pred = y_pred_multi[:, i]\n",
    "    \n",
    "    # å–å¾—æ©Ÿç‡é æ¸¬\n",
    "    y_pred_proba = mtl_xgb.estimators_[i].predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # è¨ˆç®—æŒ‡æ¨™\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    # å„²å­˜çµæœ\n",
    "    mtl_xgb_results.append({\n",
    "        'ç–¾ç—…': disease,\n",
    "        'AUC': auc,\n",
    "        'F1': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    })\n",
    "    \n",
    "    # è¼¸å‡ºçµæœ\n",
    "    print(f\"{disease}:\")\n",
    "    print(f\"  AUC:       {auc:.3f}\")\n",
    "    print(f\"  F1:        {f1:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall:    {recall:.3f}\")\n",
    "    \n",
    "    # æ··æ·†çŸ©é™£\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(f\"  æ··æ·†çŸ©é™£: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
    "    print()\n",
    "\n",
    "print(\"âœ… MTL XGBoost è¨“ç·´å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. XGBoost æ•ˆèƒ½æ¯”è¼ƒ\n",
    "\n",
    "æ¯”è¼ƒå–®ä»»å‹™ vs MTL XGBoostã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆä½µçµæœ\n",
    "df_single_xgb = pd.DataFrame(xgb_results)\n",
    "df_single_xgb['æ–¹æ³•'] = 'XGBoost (å–®ä»»å‹™)'\n",
    "\n",
    "df_mtl_xgb = pd.DataFrame(mtl_xgb_results)\n",
    "df_mtl_xgb['æ–¹æ³•'] = 'XGBoost (MTL)'\n",
    "\n",
    "df_xgb_comparison = pd.concat([df_single_xgb, df_mtl_xgb], ignore_index=True)\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(\"XGBoost æ–¹æ³•æ¯”è¼ƒ\")\n",
    "print(\"================================================================================\")\n",
    "print(df_xgb_comparison[['æ–¹æ³•', 'ç–¾ç—…', 'AUC', 'F1', 'Recall']].to_string(index=False))\n",
    "\n",
    "# æ‰¾å‡ºæœ€ä½³æ–¹æ³•\n",
    "print(\"\\n================================================================================\")\n",
    "print(\"æœ€ä½³ XGBoost æ–¹æ³•\")\n",
    "print(\"================================================================================\\n\")\n",
    "\n",
    "for disease in diseases:\n",
    "    disease_results = df_xgb_comparison[df_xgb_comparison['ç–¾ç—…'] == disease]\n",
    "    best_auc = disease_results.loc[disease_results['AUC'].idxmax()]\n",
    "    best_f1 = disease_results.loc[disease_results['F1'].idxmax()]\n",
    "    best_recall = disease_results.loc[disease_results['Recall'].idxmax()]\n",
    "    \n",
    "    print(f\"{disease}:\")\n",
    "    print(f\"  æœ€ä½³ AUC:    {best_auc['æ–¹æ³•']:25s} (AUC={best_auc['AUC']:.3f})\")\n",
    "    print(f\"  æœ€ä½³ F1:     {best_f1['æ–¹æ³•']:25s} (F1={best_f1['F1']:.3f})\")\n",
    "    print(f\"  æœ€ä½³ Recall: {best_recall['æ–¹æ³•']:25s} (Recall={best_recall['Recall']:.3f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. è¦–è¦ºåŒ– XGBoost æ•ˆèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹è¦–è¦ºåŒ–\n",
    "metrics = ['AUC', 'F1', 'Recall']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # æº–å‚™è³‡æ–™\n",
    "    pivot_data = df_xgb_comparison.pivot(index='ç–¾ç—…', columns='æ–¹æ³•', values=metric)\n",
    "    \n",
    "    # ç¹ªåœ–\n",
    "    pivot_data.plot(kind='bar', ax=ax, width=0.8)\n",
    "    ax.set_title(f'{metric} æ¯”è¼ƒ', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(metric, fontsize=12)\n",
    "    ax.set_xlabel('ç–¾ç—…', fontsize=12)\n",
    "    ax.legend(title='æ–¹æ³•', fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.3f', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../docs/experiments/xgboost_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… è¦–è¦ºåŒ–å®Œæˆï¼Œå·²å„²å­˜è‡³ docs/experiments/xgboost_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. èˆ‡ 03 çš„æœ€ä½³æ¨¡å‹æ¯”è¼ƒ\n",
    "\n",
    "æ¯”è¼ƒ XGBoost èˆ‡ 03_ModelBuilding ä¸­çš„æœ€ä½³æ¨¡å‹ï¼ˆMTL LR balancedï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======================================================================\")\n",
    "print(\"é‡æ–°è¨“ç·´ MTL LR (balanced) ä½œç‚ºåŸºæº–æ¯”è¼ƒ\")\n",
    "print(\"======================================================================\\n\")\n",
    "\n",
    "# è¨“ç·´ MTL LR (balanced)\n",
    "mtl_lr_balanced = MultiOutputClassifier(\n",
    "    LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    ")\n",
    "mtl_lr_balanced.fit(X_train_scaled, y_train_multi)\n",
    "\n",
    "# é æ¸¬\n",
    "y_pred_lr = mtl_lr_balanced.predict(X_test_scaled)\n",
    "\n",
    "lr_results = []\n",
    "\n",
    "for i, disease in enumerate(diseases):\n",
    "    y_test = y_test_multi[:, i]\n",
    "    y_pred = y_pred_lr[:, i]\n",
    "    \n",
    "    # å–å¾—æ©Ÿç‡é æ¸¬\n",
    "    y_pred_proba = mtl_lr_balanced.estimators_[i].predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # è¨ˆç®—æŒ‡æ¨™\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    lr_results.append({\n",
    "        'ç–¾ç—…': disease,\n",
    "        'AUC': auc,\n",
    "        'F1': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    })\n",
    "    \n",
    "    print(f\"{disease}:\")\n",
    "    print(f\"  AUC:       {auc:.3f}\")\n",
    "    print(f\"  F1:        {f1:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall:    {recall:.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"âœ… MTL LR (balanced) è¨“ç·´å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€çµ‚æ¯”è¼ƒ\n",
    "df_lr = pd.DataFrame(lr_results)\n",
    "df_lr['æ–¹æ³•'] = 'MTL LR (balanced)'\n",
    "\n",
    "# å–æœ€ä½³ XGBoost çµæœï¼ˆé€™è£¡é¸æ“‡å–®ä»»å‹™ï¼‰\n",
    "df_best_xgb = df_single_xgb.copy()\n",
    "df_best_xgb['æ–¹æ³•'] = 'XGBoost (å–®ä»»å‹™)'\n",
    "\n",
    "df_final_comparison = pd.concat([df_lr, df_best_xgb], ignore_index=True)\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(\"XGBoost vs MTL LR (balanced) æœ€çµ‚æ¯”è¼ƒ\")\n",
    "print(\"================================================================================\")\n",
    "print(df_final_comparison[['æ–¹æ³•', 'ç–¾ç—…', 'AUC', 'F1', 'Recall']].to_string(index=False))\n",
    "\n",
    "# è¨ˆç®—æ”¹å–„å¹…åº¦\n",
    "print(\"\\n================================================================================\")\n",
    "print(\"æ”¹å–„å¹…åº¦åˆ†æ\")\n",
    "print(\"================================================================================\\n\")\n",
    "\n",
    "for disease in diseases:\n",
    "    lr_row = df_final_comparison[(df_final_comparison['æ–¹æ³•'] == 'MTL LR (balanced)') & \n",
    "                                  (df_final_comparison['ç–¾ç—…'] == disease)].iloc[0]\n",
    "    xgb_row = df_final_comparison[(df_final_comparison['æ–¹æ³•'] == 'XGBoost (å–®ä»»å‹™)') & \n",
    "                                   (df_final_comparison['ç–¾ç—…'] == disease)].iloc[0]\n",
    "    \n",
    "    auc_improvement = (xgb_row['AUC'] - lr_row['AUC']) / lr_row['AUC'] * 100\n",
    "    f1_improvement = (xgb_row['F1'] - lr_row['F1']) / (lr_row['F1'] + 1e-10) * 100\n",
    "    \n",
    "    print(f\"{disease}:\")\n",
    "    print(f\"  AUC:  {lr_row['AUC']:.3f} â†’ {xgb_row['AUC']:.3f} ({auc_improvement:+.1f}%)\")\n",
    "    print(f\"  F1:   {lr_row['F1']:.3f} â†’ {xgb_row['F1']:.3f} ({f1_improvement:+.1f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. è¦–è¦ºåŒ–æœ€çµ‚æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹æœ€çµ‚æ¯”è¼ƒè¦–è¦ºåŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, metric in enumerate(['AUC', 'F1', 'Recall']):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # æº–å‚™è³‡æ–™\n",
    "    pivot_data = df_final_comparison.pivot(index='ç–¾ç—…', columns='æ–¹æ³•', values=metric)\n",
    "    \n",
    "    # ç¹ªåœ–\n",
    "    pivot_data.plot(kind='bar', ax=ax, width=0.7, color=['#2E86AB', '#A23B72'])\n",
    "    ax.set_title(f'{metric} æ¯”è¼ƒ', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(metric, fontsize=12)\n",
    "    ax.set_xlabel('ç–¾ç—…', fontsize=12)\n",
    "    ax.legend(title='æ–¹æ³•', fontsize=10, loc='upper right')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.3f', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../docs/experiments/xgboost_vs_lr_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… æœ€çµ‚æ¯”è¼ƒè¦–è¦ºåŒ–å®Œæˆï¼Œå·²å„²å­˜è‡³ docs/experiments/xgboost_vs_lr_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ç‰¹å¾µé‡è¦æ€§åˆ†æ\n",
    "\n",
    "åˆ†æ XGBoost èªç‚ºå“ªäº›ç‰¹å¾µæœ€é‡è¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å–å¾—é«˜è¡€å£“æ¨¡å‹çš„ç‰¹å¾µé‡è¦æ€§ï¼ˆä½œç‚ºä»£è¡¨ï¼‰\n",
    "feature_importance = xgb_models['é«˜è¡€å£“'].feature_importances_\n",
    "feature_names = X_columns\n",
    "\n",
    "# å»ºç«‹ DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'ç‰¹å¾µ': feature_names,\n",
    "    'é‡è¦æ€§': feature_importance\n",
    "}).sort_values('é‡è¦æ€§', ascending=False)\n",
    "\n",
    "print(\"======================================================================\")\n",
    "print(\"XGBoost ç‰¹å¾µé‡è¦æ€§ (Top 15) - é«˜è¡€å£“æ¨¡å‹\")\n",
    "print(\"======================================================================\")\n",
    "print(importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# è¦–è¦ºåŒ–\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['é‡è¦æ€§'])\n",
    "plt.yticks(range(len(top_features)), top_features['ç‰¹å¾µ'])\n",
    "plt.xlabel('é‡è¦æ€§', fontsize=12)\n",
    "plt.title('XGBoost ç‰¹å¾µé‡è¦æ€§ (Top 15)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../docs/experiments/xgboost_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… ç‰¹å¾µé‡è¦æ€§åˆ†æå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. çµè«–\n",
    "\n",
    "### ğŸ¯ XGBoost æ•ˆèƒ½ç¸½çµ\n",
    "\n",
    "æœ¬å¯¦é©—æ¸¬è©¦äº† XGBoost åœ¨ä¸‰é«˜ç–¾ç—…é æ¸¬ä¸Šçš„è¡¨ç¾ï¼Œä¸¦èˆ‡ 03 ä¸­çš„æœ€ä½³æ¨¡å‹ï¼ˆMTL LR balancedï¼‰é€²è¡Œæ¯”è¼ƒã€‚\n",
    "\n",
    "### ğŸ“Š ä¸»è¦ç™¼ç¾\n",
    "\n",
    "1. **XGBoost vs Logistic Regression**\n",
    "   - XGBoost åœ¨ AUC ä¸Šå¯èƒ½æœ‰å°å¹…æ”¹å–„ï¼ˆæ ¹æ“šå¯¦éš›åŸ·è¡Œçµæœï¼‰\n",
    "   - ä½†æ”¹å–„å¹…åº¦æœ‰é™ï¼Œç„¡æ³•æ ¹æœ¬è§£æ±º AUC â‰ˆ 0.5 çš„å•é¡Œ\n",
    "   - è­‰å¯¦å•é¡Œåœ¨æ–¼**ç‰¹å¾µä¸è¶³**ï¼Œè€Œéæ¨¡å‹é¸æ“‡\n",
    "\n",
    "2. **å–®ä»»å‹™ vs MTL**\n",
    "   - å–®ä»»å‹™ XGBoost å…è¨±ç‚ºæ¯å€‹ç–¾ç—…è¨­å®šä¸åŒçš„ scale_pos_weight\n",
    "   - MTL XGBoost è¨“ç·´æ•ˆç‡æ›´é«˜\n",
    "   - æ•ˆèƒ½å·®ç•°ä¸å¤§\n",
    "\n",
    "3. **ç‰¹å¾µé‡è¦æ€§**\n",
    "   - èˆ‡ Random Forest çš„åˆ†æä¸€è‡´\n",
    "   - SBP (æ”¶ç¸®å£“) ç›¸é—œç‰¹å¾µæœ€é‡è¦\n",
    "   - T2 æ™‚é–“é»å’Œ Î” è®ŠåŒ–é‡éƒ½å¾ˆé—œéµ\n",
    "\n",
    "### âš ï¸ é—œéµé™åˆ¶\n",
    "\n",
    "- **XGBoost ç„¡æ³•è§£æ±ºæ ¹æœ¬å•é¡Œ**: é«˜è¡€ç³–å’Œé«˜è¡€è„‚çš„ AUC ä»ç„¶æ¥è¿‘ 0.5\n",
    "- **åŸå› **: ç¾æœ‰ 26 å€‹ç‰¹å¾µä¸è¶³ä»¥å€åˆ†é«˜é¢¨éšªå’Œä½é¢¨éšªå€‹é«”\n",
    "- **éœ€è¦**: æ”¶é›†æ›´å¤šç”Ÿç‰©æ¨™è¨˜ï¼ˆHbA1cã€LDL/HDLã€ä¸‰é…¸ç”˜æ²¹è„‚ç­‰ï¼‰\n",
    "\n",
    "### ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè­°\n",
    "\n",
    "1. **å„ªå…ˆç´š 1: æ”¶é›†æ›´å¤šç‰¹å¾µ** ğŸ”¥\n",
    "   - é€™æ˜¯å”¯ä¸€èƒ½æ ¹æœ¬æ”¹å–„ AUC çš„æ–¹æ³•\n",
    "   - ç‰¹åˆ¥æ˜¯ç³–åŒ–è¡€è‰²ç´  (HbA1c) å’Œè¡€è„‚åˆ†é …\n",
    "\n",
    "2. **å„ªå…ˆç´š 2: å˜—è©¦å…¶ä»–æ¨¡å‹ï¼ˆåƒ…ä¾›ç ”ç©¶ï¼‰**\n",
    "   - 05_NeuralNetworks.ipynb: ANN (æ·ºå±¤ç¥ç¶“ç¶²è·¯)\n",
    "   - 06_SVM.ipynb: Support Vector Machine\n",
    "   - ä½†é æœŸæ”¹å–„å¹…åº¦æœ‰é™\n",
    "\n",
    "3. **å„ªå…ˆç´š 3: è¶…åƒæ•¸èª¿å„ª**\n",
    "   - GridSearchCV èª¿æ•´ max_depth, learning_rate, n_estimators\n",
    "   - å¯èƒ½å°å¹…æ”¹å–„ 1-3% AUC\n",
    "\n",
    "### ğŸ“ æœ€çµ‚å»ºè­°\n",
    "\n",
    "**åœ¨æ”¶é›†åˆ°æ›´å¤šç‰¹å¾µä¹‹å‰ï¼Œç¹¼çºŒå˜—è©¦ä¸åŒæ¨¡å‹çš„åƒ¹å€¼æœ‰é™ã€‚**\n",
    "\n",
    "ç›®å‰çš„æ¨¡å‹ï¼ˆLR æˆ– XGBoostï¼‰å·²ç¶“é”åˆ°äº†ç¾æœ‰ç‰¹å¾µé›†çš„æ¥µé™ã€‚\n",
    "\n",
    "å»ºè­°ï¼š\n",
    "- âœ… å¦‚æœæ˜¯ç ”ç©¶ç›®çš„ï¼Œå¯ä»¥ç¹¼çºŒå˜—è©¦ ANN å’Œ SVM\n",
    "- ğŸ”¥ å¦‚æœæ˜¯å¯¦å‹™æ‡‰ç”¨ï¼Œæ‡‰å„ªå…ˆæ”¶é›†æ›´å¤šç‰¹å¾µè³‡æ–™\n",
    "- ğŸ“Š ç•¶å‰æ¨¡å‹é©åˆç”¨æ–¼ã€Œåˆæ­¥ç¯©æª¢ã€ï¼Œä½†ä¸é©åˆã€Œç²¾æº–è¨ºæ–·ã€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}