{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 07. Genetic Programming (GP) å¯¦é©—\n",
    "\n",
    "## ğŸ“– å¯¦é©—ç›®æ¨™\n",
    "\n",
    "åœ¨å‰é¢çš„å¯¦é©—ä¸­ï¼Œæˆ‘å€‘æ¸¬è©¦äº†å¤šç¨®æ¨¡å‹ï¼š\n",
    "- âœ… **Logistic Regression**: é«˜è¡€ç³–/é«˜è¡€è„‚è¡¨ç¾æœ€ä½³ (AUC 0.93/0.89)\n",
    "- âœ… **XGBoost**: å¹³è¡¡æ•ˆèƒ½èˆ‡å¯è§£é‡‹æ€§çš„é€šç”¨é¸æ“‡\n",
    "- âœ… **ANN**: é«˜è¡€å£“è¡¨ç¾æœ€ä½³ (AUC 0.803)\n",
    "- âœ… **SVM**: ç©©å®šçš„ä¸­éšè¡¨ç¾ (11 ç§’è¨“ç·´å®Œæˆ)\n",
    "\n",
    "æœ¬ notebook å°‡æ¸¬è©¦ **Genetic Programming (GP)**ï¼Œç†ç”±ï¼š\n",
    "1. ğŸ§¬ **ç¬¦è™Ÿå›æ­¸**: è‡ªå‹•ç™¼ç¾æ•¸å­¸å…¬å¼ï¼Œæœ€é«˜å¯è§£é‡‹æ€§\n",
    "2. ğŸ” **ç‰¹å¾µäº¤äº’ç™¼ç¾**: èƒ½æ‰¾åˆ°äººé¡é›£ä»¥ç™¼ç¾çš„ç‰¹å¾µçµ„åˆ\n",
    "3. ğŸ“ **æŒ‡å°æ•™æˆå°ˆé•·**: æŒ‡å°æ•™æˆå°ˆç²¾ GPï¼Œå€¼å¾—æ·±å…¥æ¢ç´¢\n",
    "4. ğŸ“Š **éç·šæ€§å»ºæ¨¡**: ä¸å‡è¨­æ¨¡å‹å½¢å¼ï¼Œå¾è³‡æ–™ä¸­æ¼”åŒ–å‡ºæœ€ä½³å…¬å¼\n",
    "\n",
    "**âš ï¸ æ³¨æ„**ï¼š\n",
    "- GP è¨“ç·´**éå¸¸æ…¢**ï¼ˆéœ€è¦æ¼”åŒ–å¤šå€‹ä¸–ä»£ï¼Œå¯èƒ½éœ€è¦æ•¸å°æ™‚ï¼‰\n",
    "- å®¹æ˜“éæ“¬åˆï¼ˆå…¬å¼å¯èƒ½éæ–¼è¤‡é›œï¼‰\n",
    "- éœ€è¦æ§åˆ¶å…¬å¼è¤‡é›œåº¦ï¼ˆmax_depth, parsimony_coefficientï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ å¯¦é©—æµç¨‹\n",
    "\n",
    "1. è¼‰å…¥è³‡æ–™ï¼ˆä½¿ç”¨èˆ‡ 03-06 ç›¸åŒçš„è³‡æ–™è™•ç†ï¼‰\n",
    "2. ä½¿ç”¨ **gplearn** å¥—ä»¶é€²è¡Œç¬¦è™Ÿå›æ­¸\n",
    "3. åˆ†ææ¼”åŒ–å‡ºçš„å…¬å¼\n",
    "4. èˆ‡æœ€ä½³æ¨¡å‹æ¯”è¼ƒ\n",
    "5. æå–ç‰¹å¾µé‡è¦æ€§èˆ‡äº¤äº’ä½œç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32zppawxog5",
   "metadata": {},
   "source": [
    "## 0. å®‰è£å¿…è¦å¥—ä»¶\n",
    "\n",
    "âš ï¸ **é¦–æ¬¡åŸ·è¡Œå‰è«‹å…ˆå®‰è£ gplearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mw0y2jh4h1",
   "metadata": {},
   "outputs": [],
   "source": "# å®‰è£ gplearn å¥—ä»¶ (å¦‚æœå°šæœªå®‰è£)\nimport sys\n!{sys.executable} -m pip install gplearn\n\nprint(\"âœ… gplearn å®‰è£å®Œæˆï¼\")"
  },
  {
   "cell_type": "markdown",
   "id": "gx17ty6e9c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. è¼‰å…¥å¥—ä»¶èˆ‡è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ gplearn æœªå®‰è£\n",
      "è«‹åŸ·è¡Œ: pip install gplearn\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gplearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37908\\1996233609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Genetic Programming å¥—ä»¶\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mgplearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenetic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSymbolicClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"âœ… gplearn è¼‰å…¥æˆåŠŸ\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gplearn'"
     ]
    }
   ],
   "source": [
    "# åŸºç¤å¥—ä»¶\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# æ©Ÿå™¨å­¸ç¿’å¥—ä»¶\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Genetic Programming å¥—ä»¶\n",
    "try:\n",
    "    from gplearn.genetic import SymbolicClassifier\n",
    "    print(\"âœ… gplearn è¼‰å…¥æˆåŠŸ\")\n",
    "except ImportError:\n",
    "    print(\"âŒ gplearn æœªå®‰è£\")\n",
    "    print(\"è«‹åŸ·è¡Œ: pip install gplearn\")\n",
    "    raise\n",
    "\n",
    "# è¨­å®š\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'sans-serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… å¥—ä»¶è¼‰å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥è³‡æ–™\n",
    "data_path = Path('../../data/processed/SUA_CVDs_wide_format.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"âœ… è³‡æ–™è¼‰å…¥æˆåŠŸï¼\")\n",
    "print(f\"è³‡æ–™å½¢ç‹€: {df.shape[0]:,} äºº, {df.shape[1]} å€‹æ¬„ä½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. æº–å‚™ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©ç‰¹å¾µçµ„\n",
    "demographic_features = ['sex', 'Age']\n",
    "biomarker_names = ['FBG', 'TC', 'Cr', 'UA', 'GFR', 'BMI', 'SBP', 'DBP']\n",
    "t1_features = [f'{name}_T1' for name in biomarker_names]\n",
    "t2_features = [f'{name}_T2' for name in biomarker_names]\n",
    "delta1_features = [f'Delta1_{name}' for name in biomarker_names]\n",
    "\n",
    "# å®Œæ•´ç‰¹å¾µé›†\n",
    "X_columns = demographic_features + t1_features + t2_features + delta1_features\n",
    "X = df[X_columns]\n",
    "\n",
    "# ç›®æ¨™è®Šæ•¸ï¼ˆè½‰æ›ç‚º 0/1ï¼‰\n",
    "y_hypertension = (df['hypertension_T3'] == 2).astype(int)\n",
    "y_hyperglycemia = (df['hyperglycemia_T3'] == 2).astype(int)\n",
    "y_dyslipidemia = (df['dyslipidemia_T3'] == 2).astype(int)\n",
    "\n",
    "print(f\"ç‰¹å¾µæ•¸: {len(X_columns)} å€‹\")\n",
    "print(f\"\\nç›®æ¨™è®Šæ•¸åˆ†ä½ˆ:\")\n",
    "print(f\"  é«˜è¡€å£“æ‚£ç—…ç‡: {y_hypertension.mean():.2%}\")\n",
    "print(f\"  é«˜è¡€ç³–æ‚£ç—…ç‡: {y_hyperglycemia.mean():.2%}\")\n",
    "print(f\"  é«˜è¡€è„‚æ‚£ç—…ç‡: {y_dyslipidemia.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. è³‡æ–™åˆ†å‰²èˆ‡æ¨™æº–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è³‡æ–™åˆ†å‰²\n",
    "X_train, X_test, y_train_hp, y_test_hp = train_test_split(\n",
    "    X, y_hypertension, test_size=0.2, random_state=42, stratify=y_hypertension\n",
    ")\n",
    "\n",
    "_, _, y_train_hg, y_test_hg = train_test_split(\n",
    "    X, y_hyperglycemia, test_size=0.2, random_state=42, stratify=y_hypertension\n",
    ")\n",
    "\n",
    "_, _, y_train_dl, y_test_dl = train_test_split(\n",
    "    X, y_dyslipidemia, test_size=0.2, random_state=42, stratify=y_hypertension\n",
    ")\n",
    "\n",
    "# æ¨™æº–åŒ–\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ… è³‡æ–™æº–å‚™å®Œæˆ\")\n",
    "print(f\"è¨“ç·´é›†: {X_train_scaled.shape[0]} äºº\")\n",
    "print(f\"æ¸¬è©¦é›†: {X_test_scaled.shape[0]} äºº\")\n",
    "print(f\"ç‰¹å¾µæ•¸: {X_train_scaled.shape[1]} å€‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Genetic Programming è¨­å®š\n",
    "\n",
    "**gplearn SymbolicClassifier åƒæ•¸èªªæ˜**ï¼š\n",
    "\n",
    "**æ¼”åŒ–åƒæ•¸**ï¼š\n",
    "- `population_size=1000`: æ¯ä¸€ä»£çš„å€‹é«”æ•¸é‡ï¼ˆæ—ç¾¤å¤§å°ï¼‰\n",
    "- `generations=20`: æ¼”åŒ–ä¸–ä»£æ•¸ï¼ˆæ§åˆ¶è¨“ç·´æ™‚é–“ï¼‰\n",
    "- `tournament_size=20`: ç«¶è³½é¸æ“‡çš„å€‹é«”æ•¸ï¼ˆè¶Šå¤§è¶Šå‚¾å‘é¸æ“‡å¥½çš„å€‹é«”ï¼‰\n",
    "\n",
    "**å…¬å¼è¤‡é›œåº¦æ§åˆ¶**ï¼š\n",
    "- `init_depth=(2, 6)`: åˆå§‹å…¬å¼æ·±åº¦ç¯„åœ\n",
    "- `init_method='half and half'`: åˆå§‹åŒ–æ–¹æ³•ï¼ˆæ··åˆ full å’Œ growï¼‰\n",
    "- `function_set`: å…è¨±çš„å‡½æ•¸é›†åˆï¼ˆåŠ æ¸›ä¹˜é™¤ã€logã€sqrtã€sinã€cos ç­‰ï¼‰\n",
    "- `parsimony_coefficient=0.01`: æ‡²ç½°è¤‡é›œå…¬å¼ï¼ˆé¿å…éæ“¬åˆï¼‰\n",
    "\n",
    "**éºå‚³ç®—å­**ï¼š\n",
    "- `p_crossover=0.7`: äº¤é…æ©Ÿç‡\n",
    "- `p_subtree_mutation=0.1`: å­æ¨¹çªè®Šæ©Ÿç‡\n",
    "- `p_hoist_mutation=0.05`: æå‡çªè®Šæ©Ÿç‡\n",
    "- `p_point_mutation=0.1`: é»çªè®Šæ©Ÿç‡\n",
    "\n",
    "**å…¶ä»–**ï¼š\n",
    "- `metric='log loss'`: åˆ†é¡ä½¿ç”¨ log loss\n",
    "- `n_jobs=-1`: ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒåŠ é€Ÿ\n",
    "- `verbose=1`: é¡¯ç¤ºè¨“ç·´é€²åº¦\n",
    "\n",
    "â±ï¸ **é è¨ˆè¨“ç·´æ™‚é–“**ï¼šæ¯å€‹æ¨¡å‹ 30-60 åˆ†é˜ï¼ˆå–æ±ºæ–¼ generationsï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾© GP åƒæ•¸\n",
    "gp_params = {\n",
    "    'population_size': 1000,\n",
    "    'generations': 20,\n",
    "    'tournament_size': 20,\n",
    "    'init_depth': (2, 6),\n",
    "    'init_method': 'half and half',\n",
    "    'function_set': ('add', 'sub', 'mul', 'div', 'log', 'sqrt', 'abs', 'neg', 'max', 'min'),\n",
    "    'parsimony_coefficient': 0.01,\n",
    "    'p_crossover': 0.7,\n",
    "    'p_subtree_mutation': 0.1,\n",
    "    'p_hoist_mutation': 0.05,\n",
    "    'p_point_mutation': 0.1,\n",
    "    'metric': 'log loss',\n",
    "    'n_jobs': -1,\n",
    "    'verbose': 1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(\"âœ… GP åƒæ•¸è¨­å®šå®Œæˆ\")\n",
    "print(f\"æ—ç¾¤å¤§å°: {gp_params['population_size']}\")\n",
    "print(f\"æ¼”åŒ–ä¸–ä»£: {gp_params['generations']}\")\n",
    "print(f\"é è¨ˆè¨“ç·´æ™‚é–“: ~{gp_params['generations'] * 2}-{gp_params['generations'] * 3} åˆ†é˜/æ¨¡å‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. è¨“ç·´ GP æ¨¡å‹\n",
    "\n",
    "âš ï¸ **æ³¨æ„**: GP è¨“ç·´**éå¸¸æ…¢**ï¼Œè«‹è€å¿ƒç­‰å€™ï¼\n",
    "\n",
    "å¦‚æœæ™‚é–“ä¸è¶³ï¼Œå¯ä»¥æ¸›å°‘ `generations` åƒæ•¸ï¼ˆä¾‹å¦‚æ”¹ç‚º 10ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´ä¸‰å€‹ GP æ¨¡å‹\n",
    "diseases = ['é«˜è¡€å£“', 'é«˜è¡€ç³–', 'é«˜è¡€è„‚']\n",
    "y_trains = [y_train_hp, y_train_hg, y_train_dl]\n",
    "y_tests = [y_test_hp, y_test_hg, y_test_dl]\n",
    "\n",
    "gp_models = {}\n",
    "gp_results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Genetic Programming è¨“ç·´ä¸­...ï¼ˆé€™æœƒå¾ˆæ…¢ï¼Œè«‹è€å¿ƒç­‰å€™ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "for disease, y_train, y_test in zip(diseases, y_trains, y_tests):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"è¨“ç·´ {disease} GP æ¨¡å‹...\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # å»ºç«‹ GP æ¨¡å‹\n",
    "    model = SymbolicClassifier(**gp_params)\n",
    "    \n",
    "    # è¨“ç·´\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # é æ¸¬\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # è¨ˆç®—æŒ‡æ¨™\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    # å„²å­˜çµæœ\n",
    "    gp_models[disease] = model\n",
    "    gp_results.append({\n",
    "        'ç–¾ç—…': disease,\n",
    "        'AUC': auc,\n",
    "        'F1': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'è¨“ç·´æ™‚é–“(ç§’)': training_time,\n",
    "        'è¨“ç·´æ™‚é–“(åˆ†é˜)': training_time / 60,\n",
    "        'å…¬å¼é•·åº¦': len(str(model._program)),\n",
    "        'å…¬å¼æ·±åº¦': model._program.depth()\n",
    "    })\n",
    "    \n",
    "    # è¼¸å‡ºçµæœ\n",
    "    print(f\"\\n{disease} è¨“ç·´å®Œæˆ:\")\n",
    "    print(f\"  è¨“ç·´æ™‚é–“:  {training_time:.1f} ç§’ ({training_time/60:.1f} åˆ†é˜)\")\n",
    "    print(f\"  AUC:       {auc:.3f}\")\n",
    "    print(f\"  F1:        {f1:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall:    {recall:.3f}\")\n",
    "    print(f\"  å…¬å¼æ·±åº¦:  {model._program.depth()}\")\n",
    "    print(f\"  å…¬å¼é•·åº¦:  {len(str(model._program))} å­—å…ƒ\")\n",
    "    \n",
    "    # æ··æ·†çŸ©é™£\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(f\"  æ··æ·†çŸ©é™£: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… Genetic Programming è¨“ç·´å®Œæˆï¼\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. GP æ•ˆèƒ½ç¸½çµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¡¯ç¤º GP çµæœ\n",
    "df_gp = pd.DataFrame(gp_results)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"Genetic Programming æ•ˆèƒ½ç¸½çµ\")\n",
    "print(\"=\"*100)\n",
    "print(df_gp[['ç–¾ç—…', 'AUC', 'F1', 'Precision', 'Recall', 'è¨“ç·´æ™‚é–“(åˆ†é˜)', 'å…¬å¼æ·±åº¦']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nè¨“ç·´æ™‚é–“çµ±è¨ˆ:\")\n",
    "print(f\"  ç¸½è¨“ç·´æ™‚é–“: {df_gp['è¨“ç·´æ™‚é–“(ç§’)'].sum():.1f} ç§’ ({df_gp['è¨“ç·´æ™‚é–“(åˆ†é˜)'].sum():.1f} åˆ†é˜)\")\n",
    "print(f\"  å¹³å‡è¨“ç·´æ™‚é–“: {df_gp['è¨“ç·´æ™‚é–“(åˆ†é˜)'].mean():.1f} åˆ†é˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. æ¼”åŒ–å‡ºçš„å…¬å¼åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¡¯ç¤ºæ¼”åŒ–å‡ºçš„å…¬å¼\n",
    "print(\"=\"*100)\n",
    "print(\"æ¼”åŒ–å‡ºçš„é æ¸¬å…¬å¼\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for disease in diseases:\n",
    "    model = gp_models[disease]\n",
    "    print(f\"\\n{disease}:\")\n",
    "    print(f\"  æ·±åº¦: {model._program.depth()}\")\n",
    "    print(f\"  é•·åº¦: {len(str(model._program))} å­—å…ƒ\")\n",
    "    print(f\"  å…¬å¼: {str(model._program)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 8. èˆ‡æœ€ä½³æ¨¡å‹æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"é‡æ–°è¨“ç·´åŸºæº–æ¨¡å‹ä½œç‚ºæ¯”è¼ƒ\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# æº–å‚™ y_multi\n",
    "y_train_multi = np.column_stack([y_train_hp, y_train_hg, y_train_dl])\n",
    "y_test_multi = np.column_stack([y_test_hp, y_test_hg, y_test_dl])\n",
    "\n",
    "# è¨“ç·´ MTL LR\n",
    "mtl_lr = MultiOutputClassifier(\n",
    "    LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    ")\n",
    "mtl_lr.fit(X_train_scaled, y_train_multi)\n",
    "\n",
    "# è¨“ç·´ XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_models = {}\n",
    "for disease, y_train, y_test in zip(diseases, y_trains, y_tests):\n",
    "    n_positive = np.sum(y_train == 1)\n",
    "    n_negative = np.sum(y_train == 0)\n",
    "    scale_pos_weight = n_negative / n_positive\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    xgb_models[disease] = model\n",
    "\n",
    "print(\"âœ… åŸºæº–æ¨¡å‹è¨“ç·´å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ˆç®—æ‰€æœ‰æ¨¡å‹çš„çµæœ\n",
    "all_results = []\n",
    "\n",
    "# MTL LR\n",
    "y_pred_lr = mtl_lr.predict(X_test_scaled)\n",
    "for i, disease in enumerate(diseases):\n",
    "    y_test = y_test_multi[:, i]\n",
    "    y_pred = y_pred_lr[:, i]\n",
    "    y_pred_proba = mtl_lr.estimators_[i].predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    all_results.append({\n",
    "        'æ–¹æ³•': 'LR',\n",
    "        'ç–¾ç—…': disease,\n",
    "        'AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred, zero_division=0)\n",
    "    })\n",
    "\n",
    "# XGBoost\n",
    "for disease, y_test in zip(diseases, y_tests):\n",
    "    model = xgb_models[disease]\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    all_results.append({\n",
    "        'æ–¹æ³•': 'XGBoost',\n",
    "        'ç–¾ç—…': disease,\n",
    "        'AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred, zero_division=0)\n",
    "    })\n",
    "\n",
    "# GP\n",
    "for result in gp_results:\n",
    "    all_results.append({\n",
    "        'æ–¹æ³•': 'GP',\n",
    "        'ç–¾ç—…': result['ç–¾ç—…'],\n",
    "        'AUC': result['AUC'],\n",
    "        'F1': result['F1'],\n",
    "        'Recall': result['Recall']\n",
    "    })\n",
    "\n",
    "df_all = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"æ‰€æœ‰æ¨¡å‹æ•ˆèƒ½æ¯”è¼ƒ (å« GP)\")\n",
    "print(\"=\"*100)\n",
    "print(df_all[['æ–¹æ³•', 'ç–¾ç—…', 'AUC', 'F1', 'Recall']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 9. è¦–è¦ºåŒ–æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹è¦–è¦ºåŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, metric in enumerate(['AUC', 'F1', 'Recall']):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # æº–å‚™è³‡æ–™\n",
    "    pivot_data = df_all.pivot(index='ç–¾ç—…', columns='æ–¹æ³•', values=metric)\n",
    "    \n",
    "    # ç¹ªåœ–\n",
    "    pivot_data.plot(kind='bar', ax=ax, width=0.8)\n",
    "    ax.set_title(f'{metric} æ¯”è¼ƒ (å« GP)', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(metric, fontsize=12)\n",
    "    ax.set_xlabel('ç–¾ç—…', fontsize=12)\n",
    "    ax.legend(title='æ–¹æ³•', fontsize=10, loc='lower right')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.2f', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../docs/experiments/gp_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… è¦–è¦ºåŒ–å®Œæˆï¼Œå·²å„²å­˜è‡³ docs/experiments/gp_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 10. çµè«–\n",
    "\n",
    "### ğŸ§¬ Genetic Programming æ•ˆèƒ½ç¸½çµ\n",
    "\n",
    "æœ¬å¯¦é©—æ¸¬è©¦äº† Genetic Programming (GP) åœ¨ä¸‰é«˜ç–¾ç—…é æ¸¬ä¸Šçš„è¡¨ç¾ã€‚\n",
    "\n",
    "### ğŸ“Š GP å¯¦éš›è¡¨ç¾\n",
    "\n",
    "**æ•ˆèƒ½çµæœ**ï¼š\n",
    "- **é«˜è¡€å£“**: AUC=?, F1=?, Recall=?, è¨“ç·´æ™‚é–“=? åˆ†é˜\n",
    "- **é«˜è¡€ç³–**: AUC=?, F1=?, Recall=?, è¨“ç·´æ™‚é–“=? åˆ†é˜\n",
    "- **é«˜è¡€è„‚**: AUC=?, F1=?, Recall=?, è¨“ç·´æ™‚é–“=? åˆ†é˜\n",
    "\n",
    "### ğŸ† æ¨¡å‹æ’åæ¯”è¼ƒ\n",
    "\n",
    "ï¼ˆåŸ·è¡Œå®Œæˆå¾Œå¡«å…¥å¯¦éš›æ’åï¼‰\n",
    "\n",
    "### ğŸ§¬ æ¼”åŒ–å…¬å¼åˆ†æ\n",
    "\n",
    "ï¼ˆåŸ·è¡Œå®Œæˆå¾Œåˆ†ææ¼”åŒ–å‡ºçš„å…¬å¼ï¼‰\n",
    "\n",
    "### ğŸ” GP çš„å„ªç¼ºé»åˆ†æ\n",
    "\n",
    "**âœ… å„ªé»**ï¼š\n",
    "- **æœ€é«˜å¯è§£é‡‹æ€§**: æ¼”åŒ–å‡ºæ˜ç¢ºçš„æ•¸å­¸å…¬å¼\n",
    "- **ç‰¹å¾µäº¤äº’ç™¼ç¾**: è‡ªå‹•æ‰¾åˆ°ç‰¹å¾µçµ„åˆ\n",
    "- **ç„¡éœ€å‡è¨­æ¨¡å‹å½¢å¼**: å®Œå…¨å¾è³‡æ–™ä¸­å­¸ç¿’\n",
    "- **ç¬¦è™Ÿå›æ­¸**: å¯ç”¨æ–¼ç§‘å­¸ç™¼ç¾\n",
    "\n",
    "**âŒ ç¼ºé»**ï¼š\n",
    "- **è¨“ç·´æ¥µæ…¢**: éœ€è¦æ¼”åŒ–å¤šå€‹ä¸–ä»£\n",
    "- **æ˜“éæ“¬åˆ**: å…¬å¼å¯èƒ½éæ–¼è¤‡é›œ\n",
    "- **é›£ä»¥èª¿åƒ**: æ¼”åŒ–åƒæ•¸å¤šä¸”æ•æ„Ÿ\n",
    "- **è¨ˆç®—è³‡æºéœ€æ±‚å¤§**: CPU å¯†é›†å‹\n",
    "\n",
    "### ğŸ’¡ æœ€çµ‚å»ºè­°\n",
    "\n",
    "ï¼ˆåŸ·è¡Œå®Œæˆå¾Œæ ¹æ“šå¯¦éš›çµæœæä¾›å»ºè­°ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "**ä¸‹ä¸€æ­¥**: å»ºç«‹å®Œæ•´çš„æ¨¡å‹æ¯”è¼ƒç¸½çµè¡¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}