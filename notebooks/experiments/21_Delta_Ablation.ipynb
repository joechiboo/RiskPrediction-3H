{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 21. Delta 特徵消融研究\n\n## 目的\n透過比較加入與移除 Delta 特徵（Δ）後的模型效能，驗證 Delta 特徵的價值。\n\n## 假說\nDelta 特徵捕捉時序變化，應能提升預測效能。\n\n## 消融設計\n- **完整模型**：T1 + T2 + Delta 特徵（26 個特徵）\n- **消融模型**：僅 T1 + T2（18 個特徵，無 Delta）\n\n## 日期：2026-01-13\n## 執行時間：約 47 分 13 秒（8 模型 × 4 特徵集 × 3 目標 × 5-Fold CV = 480 次訓練）"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 匯入套件\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score, average_precision_score\n\nprint(\"套件載入完成\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. 載入資料與定義特徵集"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 載入滑動視窗資料\ndf = pd.read_csv('../../data/01_primary/SUA/processed/SUA_sliding_window.csv')\nprint(f\"資料：{len(df):,} 筆樣本，{df['patient_id'].nunique():,} 位患者\")\n\n# 定義特徵集\nbase_features = ['sex', 'Age']\n\nt1_features = ['FBG_Tinput1', 'TC_Tinput1', 'Cr_Tinput1', 'UA_Tinput1', \n               'GFR_Tinput1', 'BMI_Tinput1', 'SBP_Tinput1', 'DBP_Tinput1']\n\nt2_features = ['FBG_Tinput2', 'TC_Tinput2', 'Cr_Tinput2', 'UA_Tinput2',\n               'GFR_Tinput2', 'BMI_Tinput2', 'SBP_Tinput2', 'DBP_Tinput2']\n\ndelta_features = ['Delta_FBG', 'Delta_TC', 'Delta_Cr', 'Delta_UA',\n                  'Delta_GFR', 'Delta_BMI', 'Delta_SBP', 'Delta_DBP']\n\n# 消融用特徵集\nfeature_sets = {\n    '完整 (T1+T2+Δ)': base_features + t1_features + t2_features + delta_features,\n    '無 Δ (T1+T2)': base_features + t1_features + t2_features,\n    '僅 T2+Δ': base_features + t2_features + delta_features,\n    '僅 T2': base_features + t2_features,\n}\n\nprint(\"\\n特徵集：\")\nfor name, features in feature_sets.items():\n    print(f\"  {name}：{len(features)} 個特徵\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 準備目標變數\ngroups = df['patient_id']\n\ntargets = {\n    'HTN': (df['hypertension_target'] == 2).astype(int),\n    'HG': (df['hyperglycemia_target'] == 2).astype(int),\n    'DL': (df['dyslipidemia_target'] == 2).astype(int)\n}\n\nprint(\"目標變數準備完成\")\nfor name, y in targets.items():\n    print(f\"  {name}：{y.mean()*100:.1f}% 陽性\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. 執行消融實驗"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_models(random_state=42):\n    \"\"\"定義 8 種模型供消融比較\"\"\"\n    return {\n        'LR': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=random_state),\n        'NB': GaussianNB(),\n        'LDA': LinearDiscriminantAnalysis(),\n        'DT': DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=random_state),\n        'RF': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=random_state, n_jobs=-1),\n        'XGB': xgb.XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=random_state, \n                                   use_label_encoder=False, eval_metric='logloss', verbosity=0),\n        'SVM': SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=random_state),\n        'MLP': MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=random_state),\n    }\n\ndef run_ablation_cv(X, y, groups, model_name, model, n_splits=5):\n    \"\"\"執行 5-Fold CV，回傳平均 AUC 與 PR-AUC\"\"\"\n    cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n    \n    aucs = []\n    pr_aucs = []\n    \n    for train_idx, test_idx in cv.split(X, y, groups):\n        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n        \n        # 標準化\n        scaler = StandardScaler()\n        X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n        X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n        \n        # 處理 XGB 的 scale_pos_weight\n        if model_name == 'XGB':\n            neg_count = (y_train == 0).sum()\n            pos_count = (y_train == 1).sum()\n            model.set_params(scale_pos_weight=neg_count / pos_count)\n        \n        model.fit(X_train_scaled, y_train)\n        \n        # 預測\n        y_prob = model.predict_proba(X_test_scaled)[:, 1]\n        \n        # 評估指標\n        aucs.append(roc_auc_score(y_test, y_prob))\n        pr_aucs.append(average_precision_score(y_test, y_prob))\n    \n    return np.mean(aucs), np.std(aucs), np.mean(pr_aucs), np.std(pr_aucs)\n\nprint(\"消融函式定義完成（8 種模型）\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 對每個模型、目標、特徵集執行消融實驗\nresults = []\nmodels = get_models()\n\nprint(\"=\" * 80)\nprint(\"Delta 特徵消融研究 - 全部模型\")\nprint(\"=\" * 80)\n\nfor target_name, y in targets.items():\n    print(f\"\\n{'='*80}\")\n    print(f\"目標：{target_name}\")\n    print(f\"{'='*80}\")\n    \n    for model_name, model in models.items():\n        print(f\"\\n  --- {model_name} ---\")\n        \n        for feature_set_name, features in feature_sets.items():\n            X = df[features]\n            \n            # 每次重新初始化模型\n            fresh_models = get_models()\n            fresh_model = fresh_models[model_name]\n            \n            auc_mean, auc_std, pr_auc_mean, pr_auc_std = run_ablation_cv(\n                X, y, groups, model_name, fresh_model\n            )\n            \n            results.append({\n                'Target': target_name,\n                'Model': model_name,\n                'Feature_Set': feature_set_name,\n                'N_Features': len(features),\n                'AUC_mean': auc_mean,\n                'AUC_std': auc_std,\n                'PR_AUC_mean': pr_auc_mean,\n                'PR_AUC_std': pr_auc_std\n            })\n            \n            print(f\"    {feature_set_name}：AUC={auc_mean:.3f}±{auc_std:.3f}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"消融實驗完成\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. 結果分析"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 建立結果 DataFrame\nresults_df = pd.DataFrame(results)\n\n# 關鍵比較：T2+Δ vs 僅 T2（最有意義的比較）\nprint(\"=\" * 80)\nprint(\"各模型的 Delta 貢獻：T2+Δ vs 僅 T2\")\nprint(\"=\" * 80)\n\nprint(\"\\n| 模型 | 類型 | HTN Δ | HG Δ | DL Δ | 平均 Δ |\")\nprint(\"|------|------|-------|------|------|--------|\")\n\nmodel_types = {\n    'LR': '傳統統計', 'NB': '傳統統計', 'LDA': '傳統統計',\n    'DT': '樹模型', 'RF': '樹模型', 'XGB': '樹模型',\n    'SVM': '核方法', 'MLP': '神經網路'\n}\n\ndelta_contributions = []\n\nfor model_name in ['LR', 'NB', 'LDA', 'DT', 'RF', 'XGB', 'SVM', 'MLP']:\n    deltas = []\n    for target in ['HTN', 'HG', 'DL']:\n        t2_delta = results_df[(results_df['Target'] == target) & \n                              (results_df['Model'] == model_name) &\n                              (results_df['Feature_Set'] == '僅 T2+Δ')]['AUC_mean'].values[0]\n        t2_only = results_df[(results_df['Target'] == target) & \n                             (results_df['Model'] == model_name) &\n                             (results_df['Feature_Set'] == '僅 T2')]['AUC_mean'].values[0]\n        deltas.append(t2_delta - t2_only)\n    \n    avg_delta = np.mean(deltas)\n    model_type = model_types[model_name]\n    print(f\"| {model_name:5s} | {model_type:6s} | {deltas[0]:+.3f} | {deltas[1]:+.3f} | {deltas[2]:+.3f} | {avg_delta:+.3f} |\")\n    delta_contributions.append({'Model': model_name, 'Type': model_type, 'Avg_Delta': avg_delta})\n\n# 依模型類型彙整\nprint(\"\\n\" + \"=\" * 80)\nprint(\"各模型類型的平均 Delta 貢獻\")\nprint(\"=\" * 80)\n\ndc_df = pd.DataFrame(delta_contributions)\ntype_avg = dc_df.groupby('Type')['Avg_Delta'].mean()\nfor t in ['傳統統計', '樹模型', '核方法', '神經網路']:\n    if t in type_avg.index:\n        print(f\"  {t}：{type_avg[t]:+.3f} AUC\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 資訊冗餘性檢驗：完整 (T1+T2+Δ) vs 無 Δ (T1+T2)\nprint(\"=\" * 80)\nprint(\"資訊冗餘性檢驗：完整 (T1+T2+Δ) vs 無 Δ (T1+T2)\")\nprint(\"=\" * 80)\n\nprint(\"\\n| 模型 | 類型 | HTN Δ | HG Δ | DL Δ | 平均 Δ |\")\nprint(\"|------|------|-------|------|------|--------|\")\n\nfor model_name in ['LR', 'NB', 'LDA', 'DT', 'RF', 'XGB', 'SVM', 'MLP']:\n    deltas = []\n    for target in ['HTN', 'HG', 'DL']:\n        full = results_df[(results_df['Target'] == target) & \n                          (results_df['Model'] == model_name) &\n                          (results_df['Feature_Set'] == '完整 (T1+T2+Δ)')]['AUC_mean'].values[0]\n        no_delta = results_df[(results_df['Target'] == target) & \n                              (results_df['Model'] == model_name) &\n                              (results_df['Feature_Set'] == '無 Δ (T1+T2)')]['AUC_mean'].values[0]\n        deltas.append(full - no_delta)\n    \n    avg_delta = np.mean(deltas)\n    model_type = model_types[model_name]\n    print(f\"| {model_name:5s} | {model_type:6s} | {deltas[0]:+.3f} | {deltas[1]:+.3f} | {deltas[2]:+.3f} | {avg_delta:+.3f} |\")\n\nprint(\"\\n備註：接近零 = 模型可從 T1+T2 自行推導 Δ（資訊冗餘）\")\nprint(\"正值 = 模型需要明確的 Δ 特徵（無法自動推導）\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# T1 特徵貢獻（比較 T2+Δ vs 完整模型）\nprint(\"\\n\" + \"=\" * 80)\nprint(\"T1 特徵貢獻\")\nprint(\"=\" * 80)\n\nprint(\"\\n| 目標 | 完整模型 | 僅 T2+Δ | T1 貢獻 |\")\nprint(\"|------|---------|---------|---------|\")\n\nfor target in ['HTN', 'HG', 'DL']:\n    full = results_df[(results_df['Target'] == target) & \n                      (results_df['Feature_Set'] == '完整 (T1+T2+Δ)')]['AUC_mean'].values[0]\n    t2_delta = results_df[(results_df['Target'] == target) & \n                          (results_df['Feature_Set'] == '僅 T2+Δ')]['AUC_mean'].values[0]\n    t1_contrib = full - t2_delta\n    \n    print(f\"| {target} | {full:.3f} | {t2_delta:.3f} | {t1_contrib:+.3f} |\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 儲存結果\nresults_df.to_csv('../../results/delta_ablation_all_models.csv', index=False)\nprint(\"已儲存：results/delta_ablation_all_models.csv\")\nprint(f\"總實驗數：{len(results_df)}（8 模型 × 4 特徵集 × 3 目標）\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. 結論\n\n### 關鍵研究問題\n\n1. **傳統統計方法（NB、LDA）是否比 ML 模型更受益於明確的 Δ 特徵？**\n   - NB 假設特徵獨立 → 無法推導 T2-T1 的關係 → 預期受益較多\n   - LDA 考慮共變異數 → 可能部分捕捉 → 預期中度受益\n   - 樹模型與 MLP 可學習非線性交互作用 → 預期受益較小\n\n2. **資訊冗餘性檢驗（完整模型 vs 無 Δ）**\n   - 接近零：模型可從 T1+T2 自動推導 Δ\n   - 正值：模型需要明確的 Δ 特徵\n\n3. **實用價值檢驗（T2+Δ vs 僅 T2）**\n   - 臨床上最有意義的比較\n   - 當僅有近期資料 + 變化資訊時，Δ 能提供多少幫助？"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}