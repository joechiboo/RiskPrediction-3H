# 混淆矩陣評估指標補充

> **建立日期**：2025-12-04
> **來源**：Meeting 17 教授建議
> **狀態**：待執行

---

## 背景

目前主要評估指標：**AUC**

教授建議：加入基本的**混淆矩陣**相關指標

---

## 混淆矩陣基礎

```
                    預測值
                 正 (1)    負 (0)
實際值  正 (1)    TP        FN
        負 (0)    FP        TN
```

| 術語 | 說明 | 臨床意義 |
|------|------|----------|
| **TP** (True Positive) | 預測有病，實際有病 | 正確識別患者 |
| **TN** (True Negative) | 預測沒病，實際沒病 | 正確識別健康人 |
| **FP** (False Positive) | 預測有病，實際沒病 | 假警報（過度診斷） |
| **FN** (False Negative) | 預測沒病，實際有病 | 漏診（最危險！） |

---

## 需要補充的指標

### 基本指標

| 指標 | 公式 | 意義 | 目前有無 |
|------|------|------|:--------:|
| **Accuracy** | (TP+TN) / Total | 整體正確率 | ⬜ 需補充 |
| **Precision** | TP / (TP+FP) | 預測為正的準確率 | ⬜ 需補充 |
| **Recall (Sensitivity)** | TP / (TP+FN) | 實際為正的召回率 | ✅ 有 |
| **Specificity** | TN / (TN+FP) | 實際為負的正確率 | ⬜ 需補充 |
| **F1 Score** | 2×(P×R)/(P+R) | Precision 和 Recall 調和 | ✅ 有 |

### 進階指標

| 指標 | 公式 | 意義 |
|------|------|------|
| **NPV** | TN / (TN+FN) | 預測為負的準確率 |
| **PPV** | TP / (TP+FP) | 同 Precision |

---

## 實作程式碼

```python
from sklearn.metrics import (
    confusion_matrix,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    classification_report
)

def evaluate_model(y_true, y_pred, y_proba):
    """完整評估模型效能"""

    # 混淆矩陣
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()

    # 計算各項指標
    metrics = {
        'AUC': roc_auc_score(y_true, y_proba),
        'Accuracy': accuracy_score(y_true, y_pred),
        'Precision': precision_score(y_true, y_pred),
        'Recall': recall_score(y_true, y_pred),
        'Specificity': tn / (tn + fp),
        'F1': f1_score(y_true, y_pred),
        'TP': tp,
        'TN': tn,
        'FP': fp,
        'FN': fn,
    }

    return metrics, cm

# 使用範例
for disease in ['高血壓', '高血糖', '高血脂']:
    metrics, cm = evaluate_model(y_test, y_pred, y_proba)
    print(f"\n{disease}")
    print(f"混淆矩陣:\n{cm}")
    print(f"Accuracy: {metrics['Accuracy']:.3f}")
    print(f"Precision: {metrics['Precision']:.3f}")
    print(f"Recall: {metrics['Recall']:.3f}")
    print(f"Specificity: {metrics['Specificity']:.3f}")
```

---

## 預期產出表格

### 各模型混淆矩陣（以高血壓為例）

| 模型 | TP | TN | FP | FN |
|------|---:|---:|---:|---:|
| LR | ? | ? | ? | ? |
| RF | ? | ? | ? | ? |
| XGBoost | ? | ? | ? | ? |
| ANN | ? | ? | ? | ? |
| SVM | ? | ? | ? | ? |

### 各模型評估指標彙整

| 模型 | AUC | Accuracy | Precision | Recall | Specificity | F1 |
|------|-----|----------|-----------|--------|-------------|-----|
| LR | 0.749 | ? | ? | 0.728 | ? | 0.425 |
| RF | 0.796 | ? | ? | 0.035 | ? | 0.065 |
| ... | ... | ... | ... | ... | ... | ... |

---

## 臨床意義解讀

### 疾病篩檢情境

| 指標 | 重要性 | 原因 |
|------|:------:|------|
| **Recall** | ⭐⭐⭐ | 不能漏診患者 |
| **Specificity** | ⭐⭐ | 減少不必要檢查 |
| **Precision** | ⭐ | 減少假警報 |
| **Accuracy** | ⭐ | 參考用，不平衡資料下會誤導 |

### 為什麼 Accuracy 在不平衡資料下不可靠？

```
假設：1000 人中只有 50 人有病（5%）

模型 A：全部預測「沒病」
- Accuracy = 950/1000 = 95% ← 看起來很高！
- Recall = 0/50 = 0% ← 完全沒抓到患者！

結論：Accuracy 會被多數類主導，不適合作為主要指標
```

---

## 論文呈現建議

### 建議新增的圖表

1. **混淆矩陣熱力圖**（每個疾病 × 最佳模型）
2. **多指標雷達圖**（比較不同模型）
3. **完整指標表格**（補充 Accuracy, Precision, Specificity）

### 論文段落範例

> 表 X 呈現各模型在測試集上的混淆矩陣結果。以高血壓預測為例，
> Logistic Regression 達到最高的 Recall（0.728），代表能識別出 72.8% 的患者，
> 但 Precision 僅 0.XX，顯示存在一定比例的假陽性。
> 相較之下，Random Forest 雖然 AUC 較高（0.796），但 Recall 僅 0.035，
> 在臨床篩檢情境下可能錯過大量患者。

---

## 優先級

- **優先級**：中
- **預估時間**：0.5 天
- **相依性**：需要各模型的預測結果

---

**相關文件**：

- [訓練集與測試集的切分方式.md](訓練集與測試集的切分方式.md)
- [class_weight消融實驗設計.md](class_weight消融實驗設計.md)
