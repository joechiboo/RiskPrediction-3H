# 第二章 文獻探討

本章回顧與本研究相關的文獻，包括三高疾病預測研究、縱向資料分析與變化量特徵工程、機器學習方法，以及相關研究的比較分析。最後定義本研究的問題框架與評估指標。

## 2.1 三高疾病預測研究

本研究使用的資料集來自 Luo et al. (2024)[^0] 之公開資料，三高疾病的確診狀態依據以下標準標記：高血壓定義為 SBP ≥ 140 或 DBP ≥ 90 mmHg，或已確診且正在服用降壓藥物；高血糖定義為 FBG ≥ 7.0 mmol/L 或自我報告糖尿病；高血脂定義為 TC ≥ 6.22 mmol/L。上述閾值與國際通用的診斷標準一致[^1][^2][^3]。

[^0]: Luo, Y., et al. (2024). Associations of serum uric acid with cardiovascular disease risk factors. *BMJ Open*, 13(9), e073930.
[^1]: James, P. A., et al. (2014). 2014 evidence-based guideline for the management of high blood pressure in adults (JNC 8). *JAMA*, 311(5), 507-520. 值得注意的是，2017 年 ACC/AHA 指引已將高血壓門檻下修至 130/80 mmHg，但本資料集採用 JNC 8 的 140/90 mmHg 標準，此標準仍為多數亞洲國家及國際研究的主流採用標準。
[^2]: American Diabetes Association. (2025). Standards of Care in Diabetes—2025. *Diabetes Care*, 48(Suppl 1).
[^3]: National Cholesterol Education Program. (2002). Third Report of the Expert Panel on Detection, Evaluation, and Treatment of High Blood Cholesterol in Adults (ATP III). *JAMA*, 285(19), 2486-2497.

### 2.1.1 高血壓預測

Sun et al. (2017) 系統性回顧了 26 篇高血壓預測研究，共涵蓋 48 個預測模型。該回顧指出，常見的風險因子包括 BMI、年齡、血壓水平、吸菸與家族史等，而統計方法以 Logistic Regression（12 篇）、COX Regression（7 篇）和 Weibull Regression（6 篇）為主，顯示傳統統計方法在該領域長期居於主流地位。

近年來，機器學習方法逐漸被引入高血壓預測。Kanegae et al. (2020) 使用日本職場健檢資料（18,258 人）建立高血壓預測模型，採用 XGBoost 和 Ensemble 方法，達到 AUC 0.881。該研究的重要貢獻在於使用縱向變化量特徵（Year(-2) → Year(-1) → Year(0)），證明 Δ 特徵在高血壓預測上的有效性。

Ye et al. (2018) 使用美國 Maine 州的電子健康紀錄（EHR），以 823,627 人的回顧性資料和 680,810 人的前瞻性資料，採用 XGBoost 建立一年期高血壓預測模型，回顧性驗證 AUC 達 0.917，前瞻性驗證 AUC 為 0.870。然而，後續評論指出該研究的前五名重要特徵均為降壓藥物，可能存在資料洩漏問題，提醒研究者在特徵選擇時需審慎避免將結果資訊混入預測因子。

Wang et al. (2024) 使用台灣美兆（MJ）健檢資料進行大規模研究（207,488 人），發現健檢次數越多，預測準確度越高（4 次以上最佳），達到 AUC 0.889。此研究支持多時間點特徵串接的設計理念，與本研究的縱向設計概念一致。

### 2.1.2 高血糖與糖尿病預測

Liu et al. (2024) 使用台中榮總電子病歷（6,687 人，追蹤 10 年），以 XGBoost 達到 AUC 0.93，關鍵特徵包括 HbA1c、空腹血糖、體重等。

Chen et al. (2025) 同樣使用 MJ 健檢資料（6,247 位 18-35 歲男性），提出雙框架設計同時預測血糖變化量（δ-FPG）與前驅糖尿病風險。研究發現基線空腹血糖（FPGbase）對預測 δ-FPG 的重要性達 100%，遠超第二名體脂肪的 17.64%，顯示縱向血糖變化具有高度可預測性。本研究的 Δ 特徵設計即參考此概念。

### 2.1.3 高血脂預測

相較於高血壓與糖尿病，高血脂的機器學習預測研究較少。多數研究將高血脂作為心血管疾病的風險因子，而非獨立的預測目標。本研究將高血脂納入三高同時預測的框架中，填補此研究缺口。

## 2.2 縱向資料分析與變化量特徵

### 2.2.1 縱向研究設計

縱向研究（Longitudinal Study）追蹤同一群體在不同時間點的變化，相較於橫斷面研究（Cross-sectional Study）具有以下優勢：

1. **捕捉動態變化**：能觀察生理指標隨時間的趨勢
2. **時序因果關係**：可建立預測因子與結果的時間順序
3. **個體內變異**：控制個體間差異，專注於個體內的變化

然而，縱向資料也面臨挑戰，包括追蹤期間的樣本流失、時間間隔不一致、以及缺失值處理等問題。

### 2.2.2 變化量特徵工程

變化量特徵（Delta Features）定義為兩個時間點之間生理指標的差值：

$$\delta_j = x_{j,Y_{-1}} - x_{j,Y_{-2}}$$

其中 $x_j$ 為第 j 個生理指標。Chen et al. (2025) 以 δ-FPG（空腹血糖變化量）作為預測目標，證明縱向變化量具有高度可預測性。Kanegae et al. (2020) 同樣使用 Δ 特徵預測高血壓，證明此方法的跨疾病適用性。

本研究採用八個變化量特徵：ΔSBP、ΔDBP、ΔFBG、ΔTC、ΔCr、ΔUA、ΔeGFR、ΔBMI，分別捕捉血壓、血糖、血脂、腎功能與身體質量指數的動態變化。

## 2.3 傳統統計方法

根據 Sun et al. (2017) 的系統性回顧，在 26 篇高血壓預測研究所涵蓋的 48 個模型中，Logistic Regression 佔 12 篇（25%）為最大宗，其次為 COX Regression（7 篇）和 Weibull Regression（6 篇），顯示傳統統計方法長期作為疾病風險預測的主流工具。本節介紹本研究所採用的三種傳統統計分類方法。

### 2.3.1 Logistic Regression

Logistic Regression（邏輯斯迴歸）是疾病預測研究中最常用的基準模型。其模型形式為：

$$P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \cdots + \beta_n X_n)}}$$

其中 $\beta_i$ 為迴歸係數，$e^{\beta_i}$ 可直接解釋為勝算比（Odds Ratio），表示第 $i$ 個特徵每增加一個單位時，疾病風險的倍數變化。此特性使 LR 在臨床應用中具有高度可解釋性，醫療人員可直觀理解各風險因子的貢獻程度。

在 Sun et al. (2017) 回顧的研究中，LR 的 C-statistic（等同 AUC）多落在 0.72–0.85 之間，顯示即使在非線性關係存在的情境下，LR 仍能提供具競爭力的預測效能。然而，LR 假設特徵與對數勝算之間為線性關係，可能無法捕捉複雜的非線性交互作用。

### 2.3.2 Naive Bayes

Naive Bayes（單純貝氏分類器）基於貝氏定理進行分類：

$$P(Y=k|X) = \frac{P(X|Y=k) \cdot P(Y=k)}{P(X)}$$

其核心假設為各特徵在給定類別下條件獨立，即：

$$P(X|Y=k) = \prod_{j=1}^{n} P(X_j|Y=k)$$

對於連續型特徵，Gaussian Naive Bayes 假設每個特徵在各類別下服從常態分佈。此方法的優點包括：計算效率極高（時間複雜度為 $O(nd)$，$n$ 為樣本數、$d$ 為特徵數）、無需調參、在小樣本情境下表現穩健。然而，特徵獨立假設在醫療資料中往往不成立，例如收縮壓與舒張壓、血糖與 BMI 之間均存在相關性，此假設的違反可能影響機率估計的校準度，但對分類排序（AUC）的影響通常較小。

Naive Bayes 屬於生成式模型（Generative Model），與 Logistic Regression 的判別式模型（Discriminative Model）形成理論上的互補，兩者的比較有助於理解資料的分佈特性。

### 2.3.3 Linear Discriminant Analysis

Linear Discriminant Analysis（線性判別分析，LDA）由 Fisher (1936) 提出，是統計學中最經典的分類方法之一。LDA 透過尋找最佳的線性投影方向，最大化類別間變異與類別內變異的比值：

$$J(w) = \frac{w^T S_B w}{w^T S_W w}$$

其中 $S_B$ 為類別間散布矩陣（Between-class scatter matrix），$S_W$ 為類別內散布矩陣（Within-class scatter matrix），$w$ 為投影方向。LDA 假設各類別的特徵服從多變量常態分佈且共享相同的共變異數矩陣。

相較於 Logistic Regression，LDA 同時考慮特徵的聯合分佈結構，在特徵間存在多重共線性時仍能維持穩定性。此外，LDA 的降維特性（將 $d$ 維特徵投影至最多 $k-1$ 維空間，$k$ 為類別數）使其在高維度資料中具有正則化效果。然而，常態分佈與等共變異數假設在實際資料中可能不完全成立，限制了其對非線性關係的捕捉能力。

## 2.4 機器學習方法

### 2.4.1 樹狀模型

Decision Tree（決策樹）透過遞迴分割建立規則，具有高度可解釋性。Random Forest（隨機森林）是決策樹的集成方法，透過 Bagging 降低過擬合風險。XGBoost 採用梯度提升策略，在多項疾病預測競賽中表現優異。Alaa et al. (2019) 使用 AutoPrognosis 自動化機器學習預測心血管疾病，達到 AUC 0.774。Liu et al. (2024) 和 Chen et al. (2025) 皆報告 XGBoost 達到最佳預測效能。Dinh et al. (2019) 使用 NHANES 公開資料集（21,131 筆）以 XGBoost 預測糖尿病，不含實驗室數據時達到 AUC 0.862，並以 Information Gain 進行特徵重要性分析。

### 2.4.2 支援向量機

Support Vector Machine（SVM）透過尋找最大間隔超平面（Maximum Margin Hyperplane）進行分類，並可使用核函數（Kernel Function）將資料映射至高維空間以處理非線性問題。相較於樹模型依賴特徵的離散分割，SVM 在特徵空間中建立連續的決策邊界，對小樣本與高維資料具有較好的泛化能力。Hung et al. (2021) 在台灣隱匿性高血壓預測中納入 SVM 作為比較模型之一，Chen et al. (2025) 亦在七種機器學習模型的比較中使用 SVM。本研究採用 SVM 作為核方法（Kernel Method）的代表，與線性方法（LR、NB、LDA）、樹模型（DT、RF、XGBoost）及神經網路（MLP）形成四類方法的完整比較架構。

### 2.4.3 神經網路

多層感知器（MLP）可學習複雜的非線性關係，但面臨可解釋性不足與過擬合風險。Taiwan MTL (2025) 使用 Attention 機制進行多疾病預測，透過注意力分數提供一定程度的可解釋性。

### 2.4.4 符號回歸

符號回歸（Symbolic Regression）透過遺傳規劃演化出可解釋的數學公式。相較於黑盒模型，符號回歸產出的公式可直接理解其醫學意義。然而，符號回歸的搜尋過程具有隨機性，結果穩定性較低。

## 2.5 類別不平衡處理

三高疾病的發病率通常低於 20%，造成正負類別樣本數量懸殊的類別不平衡（Class Imbalance）問題。在此情境下，模型容易偏向預測多數類（健康），導致少數類（患病）的識別率低落。He & Garcia (2009) 將類別不平衡的處理策略歸納為兩大層面：資料層面與演算法層面。

### 2.5.1 資料層面方法

資料層面方法透過調整訓練資料的類別分佈來緩解不平衡問題，主要包括過採樣（Over-sampling）與欠採樣（Under-sampling）兩類策略。

**過採樣**方面，SMOTE（Synthetic Minority Over-sampling Technique）是最具代表性的方法（Chawla et al., 2002）。SMOTE 透過在少數類樣本的特徵空間中進行線性內插，生成合成樣本，避免了簡單複製造成的過擬合問題。其衍生方法包括 Borderline-SMOTE（僅對邊界樣本進行合成）和 ADASYN（根據樣本學習難度自適應生成）。然而，過採樣方法可能引入雜訊樣本，且在高維特徵空間中，合成樣本的品質難以保證。

**欠採樣**方面，Random Under-sampling 隨機移除多數類樣本以達到類別平衡，但可能丟失重要資訊。Tomek Links 和 Edited Nearest Neighbours（ENN）等方法則透過移除邊界區域的多數類樣本來清理決策邊界，在保留資訊的同時改善類別分離度。

### 2.5.2 演算法層面方法

演算法層面方法在不改變資料分佈的前提下，透過修改學習演算法本身來處理不平衡問題。

**成本敏感學習（Cost-sensitive Learning）** 是最常用的演算法層面策略。其核心思想是對不同類別的誤分類賦予不同的代價（cost），使模型更重視少數類的正確分類。在實務上，scikit-learn 等框架提供 class_weight 參數，設定為 'balanced' 時會自動依據類別頻率的倒數調整權重：

$$w_k = \frac{n}{K \cdot n_k}$$

其中 $n$ 為總樣本數，$K$ 為類別數，$n_k$ 為第 $k$ 類的樣本數。此方法的優點在於不改變訓練資料的原始分佈，避免了合成樣本可能引入的雜訊，且計算成本極低。

**決策門檻調整（Threshold Moving）** 則在模型訓練後，調整分類的機率門檻（預設 0.5）來平衡 Sensitivity 與 Specificity。此方法不影響模型訓練過程，但需要額外的驗證集來選定最佳門檻。

本研究採用 class_weight='balanced' 作為主要的類別不平衡處理策略，並以 AUC-ROC 作為主要評估指標（因 AUC 不受門檻選擇影響），同時報告 Sensitivity 和 Specificity 以反映臨床應用需求。實驗中亦比較了 SMOTE 與 class_weight 兩種策略的效果差異（詳見第四章）。

## 2.6 研究缺口與本研究定位

### 2.6.1 相關研究比較

表 2-1 比較本研究與相關文獻的差異。

**表 2-1 相關研究比較**

| 研究 | 預測目標 | 資料來源 | 樣本數 | 研究設計 | 最佳模型 | 最佳 AUC | Δ 特徵 | 可解釋性 |
| ------ | ---------- | ---------- | -------- | ---------- | ---------- | ---------- | -------- | ---------- |
| Alaa et al. (2019) | 心血管疾病 | UK Biobank | 423,604 | 縱向 | AutoPrognosis | 0.774 | 無 | 無 |
| Dinh et al. (2019) | 糖尿病 | NHANES | 21,131 | 橫斷面 | XGBoost | 0.862 | 無 | Information Gain |
| Kanegae et al. (2020) | 高血壓 | 日本職場健檢 | 18,258 | 縱向 | XGBoost | 0.881 | 有 | 特徵重要性 |
| Hung et al. (2021) | 隱匿性高血壓 | 台灣醫院 | — | 橫斷面 | SVM | — | 無 | 無 |
| Liu et al. (2024) | 糖尿病 | 台中榮總 EHR | 6,687 | 縱向 | XGBoost | 0.930 | 無 | 特徵重要性 |
| Wang et al. (2024) | 高血壓 | Taiwan MJ | 207,488 | 縱向 | XGBoost | 0.889 | 無 | 特徵重要性 |
| Chen et al. (2025) | 前驅糖尿病 | Taiwan MJ | 6,247 | 縱向 | XGBoost | — | 有 | SHAP |
| **本研究** | **三高（同時）** | 杭州社區調查 | 6,056 | **縱向** | LR / XGBoost | 0.721–0.938 | **有** | **SHAP + 符號回歸** |

### 2.6.2 研究缺口

綜觀現有文獻，本研究識別以下研究缺口：

1. **多疾病同時預測**：多數研究僅針對單一疾病，缺乏三高疾病的綜合預測框架
2. **變化量特徵的系統性驗證**：雖然 Chen et al. (2025) 和 Kanegae et al. (2020) 證明 Δ 特徵有效，但僅針對單一疾病，缺乏跨疾病的驗證
3. **模型比較的完整性**：現有研究通常只比較少數模型，缺乏傳統統計、樹模型、神經網路、符號回歸的全面比較
4. **可解釋性與效能的平衡**：多數研究偏重預測效能，較少探討臨床可解釋性

## 2.7 問題定義

本研究使用連續三次健檢紀錄，定義以下時間點：

- $Y\text{-}2$：第一次健檢（最早）
- $Y\text{-}1$：第二次健檢
- $Y_0$：第三次健檢（預測目標時間點）

### 2.7.1 特徵定義

給定 $d$ 個基本特徵與 $p$ 個健檢指標，輸入特徵向量定義為：

$$X = [X_{base}, X_{Y-2}, X_{Y-1}, \Delta X] \in \mathbb{R}^{d + 3p}$$

其中：

- $X_{base} \in \mathbb{R}^{d}$：人口學基本資訊
- $X_{Y-2} \in \mathbb{R}^{p}$：Y-2 時間點的健檢指標
- $X_{Y-1} \in \mathbb{R}^{p}$：Y-1 時間點的健檢指標
- $\Delta X = X_{Y-1} - X_{Y-2} \in \mathbb{R}^{p}$：變化量特徵

### 2.7.2 預測任務

給定輸入特徵 $X$，學習預測函數 $f$ 使得：

$$\hat{Y} = f(X) = [\hat{y}_{HTN}, \hat{y}_{DM}, \hat{y}_{DLP}] \approx Y \in \{0, 1\}^{3}$$

其中：

- $\hat{y}_{HTN}$：高血壓（Hypertension）
- $\hat{y}_{DM}$：高血糖（Diabetes Mellitus）
- $\hat{y}_{DLP}$：高血脂（Dyslipidemia）
