# 模型比較實驗計畫

## 研究目標

比較不同類型的機器學習模型在三高預測任務上的性能，找出最適合的模型架構。

---

## 模型分類與選擇理由

### 1. 傳統機器學習模型（Baseline）

#### 1.1 Logistic Regression (LR)
- **類型**：線性模型
- **選擇理由**：
  - 最簡單的 baseline
  - 高度可解釋（係數直接對應特徵影響）
  - 醫療領域廣泛使用
  - 快速訓練與預測
- **適用情境**：線性可分、需要高可解釋性
- **預期性能**：AUC 0.70-0.75

#### 1.2 Random Forest (RF)
- **類型**：集成學習（Bagging）
- **選擇理由**：
  - 處理非線性關係
  - 提供特徵重要性
  - 不易過擬合
  - 對缺失值有一定容忍度
- **適用情境**：中等規模資料、需要可解釋性
- **預期性能**：AUC 0.75-0.82
- **參考**：Liu et al. (2024) 使用 RF 達 AUC 0.99（糖尿病）

---

### 2. Gradient Boosting 系列（高性能模型）

#### 2.1 XGBoost
- **類型**：集成學習（Boosting）
- **選擇理由**：
  - 結構化資料的 SOTA 方法之一
  - 自動處理缺失值
  - 提供特徵重要性
  - 正則化防止過擬合
- **適用情境**：追求高性能、中大型資料集
- **預期性能**：AUC 0.80-0.85
- **參考**：Liu et al. (2024) 使用 XGBoost 達 AUC 0.93（糖尿病）

#### 2.2 LightGBM
- **類型**：集成學習（Boosting）
- **選擇理由**：
  - 比 XGBoost 更快（適合大資料）
  - 記憶體使用更少
  - 性能與 XGBoost 相當
- **適用情境**：大型資料集、需要快速訓練
- **預期性能**：AUC 0.80-0.85

#### 2.3 CatBoost（可選）
- **類型**：集成學習（Boosting）
- **選擇理由**：
  - 自動處理類別變數（如性別）
  - 減少調參工作
- **適用情境**：有類別特徵、需要快速建模
- **預期性能**：AUC 0.80-0.85

---

### 3. 深度學習模型

#### 3.1 Multi-Layer Perceptron (MLP)
- **類型**：前饋神經網路
- **架構**：
  ```
  Input (30 features)
    ↓
  Dense(128) + ReLU + Dropout(0.3)
    ↓
  Dense(64) + ReLU + Dropout(0.3)
    ↓
  Dense(32) + ReLU
    ↓
  Output(3) + Sigmoid  # 三高二元輸出
  ```
- **選擇理由**：
  - 捕捉複雜非線性關係
  - 可處理高維特徵交互
  - 端到端學習
- **適用情境**：特徵數多、非線性關係複雜
- **預期性能**：AUC 0.78-0.83
- **挑戰**：需調參、易過擬合、可解釋性低

#### 3.2 Multi-Task Learning (MTL) Network
- **類型**：多任務神經網路
- **架構**：
  ```
  Input (30 features)
    ↓
  [共享層]
  Dense(128) + ReLU + Dropout(0.3)
  Dense(64) + ReLU + Dropout(0.3)
    ↓
  ┌──────────┬──────────┬──────────┐
  │ Task 1   │ Task 2   │ Task 3   │
  │ 高血壓   │ 高血糖   │ 高血脂   │
  │ Dense(32)│ Dense(32)│ Dense(32)│
  │ Output(1)│ Output(1)│ Output(1)│
  └──────────┴──────────┴──────────┘
  ```
- **選擇理由**：
  - 同時預測三高，共享特徵表示
  - 捕捉疾病間的相關性
  - 提升資料利用效率
- **適用情境**：多個相關預測任務
- **預期性能**：AUC 0.80-0.85
- **參考**：Taiwan MTL (2025) 同時預測 4 種慢性病，AUC 0.85-0.88

---

### 4. 演化算法

#### 4.1 Genetic Algorithm for Feature Selection (GA-FS)
- **類型**：演化計算 + 傳統 ML
- **用途**：特徵選擇
- **流程**：
  ```
  1. 初始化：隨機生成 N 組特徵組合（染色體）
  2. 適應度評估：用 RF/XGBoost 計算每組的 AUC
  3. 選擇：保留表現好的組合
  4. 交配：兩組特徵組合互換基因
  5. 突變：隨機改變某些特徵的選擇狀態
  6. 重複 2-5，直到收斂或達最大代數
  ```
- **選擇理由**：
  - 全域搜索，避免局部最優
  - 適合組合優化問題（2^30 種特徵組合）
  - 不依賴梯度，靈活性高
- **與其他方法比較**：
  - Filter (Mutual Info)：快速但不考慮特徵交互
  - Wrapper (RFE)：考慮交互但僅做局部搜索
  - GA：全域搜索 + 考慮交互
- **預期發現**：可能找到傳統方法無法發現的特徵組合
- **挑戰**：計算成本高、需調參（族群大小、突變率）

#### 4.2 Genetic Programming (GP)（可選）
- **類型**：演化計算
- **用途**：自動特徵工程
- **範例**：
  ```python
  # GP 可能自動發現有用的特徵組合：
  新特徵 = log(BMI₂) * ΔSBP + Age₂^2
  ```
- **選擇理由**：探索人工無法想到的特徵組合
- **挑戰**：極高計算成本、可解釋性差

---

### 5. 其他模型（可選）

#### 5.1 Support Vector Machine (SVM)
- **選擇理由**：小樣本表現好、核函數處理非線性
- **缺點**：大資料集計算慢、調參複雜
- **預期性能**：AUC 0.75-0.80

#### 5.2 Naive Bayes
- **選擇理由**：極快速、可解釋、適合快速原型
- **缺點**：假設特徵獨立（通常不成立）
- **預期性能**：AUC 0.70-0.75

---

## 實驗設計

### Phase 1: Baseline 建立（1-2 週）

**目標**：快速建立性能基準

**模型**：
1. Logistic Regression
2. Random Forest
3. XGBoost

**實驗內容**：
- 使用 2 次記錄（T₁, T₂ → T₃）
- 使用所有可用特徵（約 30 個）
- 固定資料分割（Train 70% / Val 15% / Test 15%）
- 評估指標：AUC-ROC, F1-Score, Recall

**預期輸出**：
```
Model           | AUC (Test) | F1 (Test) | Recall (Test)
----------------|------------|-----------|---------------
LR              | 0.73       | 0.62      | 0.65
RF              | 0.78       | 0.68      | 0.70
XGBoost         | 0.82       | 0.72      | 0.74
```

---

### Phase 2: 深度學習探索（2-3 週）

**目標**：探討深度學習是否能提升性能

**模型**：
1. Multi-Layer Perceptron (MLP)
2. Multi-Task Learning (MTL)

**實驗內容**：
- 比較 MLP vs. 三個獨立 MLP（每個疾病一個）
- 比較 MTL vs. XGBoost（是否值得用深度學習）
- 超參數調優：隱藏層大小、Dropout、學習率

**預期輸出**：
```
Model           | AUC-高血壓 | AUC-高血糖 | AUC-高血脂 | Avg AUC
----------------|-----------|-----------|-----------|--------
XGBoost (3個)   | 0.82      | 0.84      | 0.80      | 0.82
MLP (3個)       | 0.80      | 0.82      | 0.78      | 0.80
MTL (共享)      | 0.83      | 0.85      | 0.82      | 0.83
```

**關鍵問題**：
- MTL 是否優於獨立模型？
- 深度學習的性能提升是否值得額外的複雜度？

---

### Phase 3: 演化算法應用（2-3 週）

**目標**：使用 GA 找出最佳特徵組合

**實驗設定**：
```python
GA 參數：
- 族群大小：50
- 演化代數：100
- 交配率：0.8
- 突變率：0.1
- 適應度函數：XGBoost 的 5-Fold CV AUC
```

**實驗內容**：
1. **GA 特徵選擇 vs. 傳統方法**
   ```
   方法              | 選出特徵數 | AUC (Test)
   ------------------|-----------|------------
   All Features      | 30        | 0.82
   Mutual Info Top-5 | 5         | 0.78
   RFE Top-5         | 5         | 0.80
   GA Top-5          | 5         | 0.81  ← 是否更好？
   ```

2. **GA 自動找出最佳特徵數**
   - 不限制特徵數，讓 GA 自動演化
   - 預期：可能發現「7 個特徵是最佳平衡點」

3. **疾病專屬 vs. 共享特徵**
   - GA 為三高分別找出最佳特徵組合
   - 分析共享特徵與專屬特徵

**預期發現**：
- GA 可能發現非直觀的特徵組合（如 Cr × GFR 的交互作用）
- 驗證邊際效應遞減的臨界點

**挑戰**：
- 計算時間長（可能需數小時到數天）
- 需防止過擬合（用 Test Set 驗證最終結果）

---

### Phase 4: 邊際效應遞減實驗（1-2 週）

**目標**：系統性探討記錄數與特徵數的邊際效應

#### 實驗 A：記錄數的邊際效應
```python
for n_records in [2, 3, 4, 5, 6, 7]:
    # 使用 XGBoost（固定模型）
    # 使用所有特徵（固定特徵）
    # 評估性能
```

**預期輸出**：
```
記錄數 | AUC | △AUC (邊際收益)
-------|-----|----------------
2      | 0.80| -
3      | 0.84| +0.04
4      | 0.86| +0.02
5      | 0.87| +0.01  ← 邊際收益降低
6      | 0.87| +0.00  ← 飽和
```

#### 實驗 B：特徵數的邊際效應
```python
for k in [3, 5, 7, 10, 15, 20, 30]:
    # 使用 2 次記錄（固定記錄數）
    # 使用 XGBoost（固定模型）
    # 使用 Top-K 特徵（由 GA 或 RFE 選出）
    # 評估性能
```

**預期輸出**：
```
特徵數 | AUC | △AUC (邊際收益)
-------|-----|----------------
3      | 0.75| -
5      | 0.80| +0.05
7      | 0.82| +0.02
10     | 0.83| +0.01  ← 邊際收益降低
15     | 0.83| +0.00  ← 飽和
```

#### 實驗 C：二維探索（記錄數 × 特徵數）
生成熱圖，找出最佳組合

---

### Phase 5: 最終模型比較（1 週）

**目標**：綜合所有實驗，產出最終比較表

**比較維度**：
1. **性能**：AUC, F1, Recall
2. **訓練時間**：秒/分鐘/小時
3. **可解釋性**：高/中/低
4. **部署難度**：易/中/難
5. **對缺失值的容忍度**：高/中/低

**最終比較表**：
| 模型 | AUC | F1 | Recall | 訓練時間 | 可解釋性 | 部署難度 | 推薦情境 |
|------|-----|----|----|---------|---------|---------|---------|
| LR | 0.73 | 0.62 | 0.65 | 1s | 高 | 易 | 快速篩檢 |
| RF | 0.78 | 0.68 | 0.70 | 10s | 中 | 易 | 平衡方案 |
| XGBoost | 0.82 | 0.72 | 0.74 | 30s | 中 | 易 | 高性能需求 |
| MLP | 0.80 | 0.70 | 0.72 | 2m | 低 | 中 | 探索非線性 |
| MTL | 0.83 | 0.73 | 0.75 | 5m | 低 | 難 | 多任務預測 |
| XGB+GA | 0.84 | 0.74 | 0.76 | 1h | 中 | 中 | 特徵選擇優化 |

---

## 評估方法

### 1. 資料分割策略
- **方法**：Group K-Fold Cross-Validation (K=5)
- **分組依據**：病患 ID（避免資料洩漏）
- **最終測試**：獨立 Test Set（15%）

### 2. 評估指標

#### 主要指標
- **AUC-ROC**：整體分類能力
- **F1-Score**：平衡精確率與召回率
- **Recall**：識別高風險病患的能力（醫療重視）

#### 次要指標
- **Precision**：陽性預測準確度
- **Specificity**：識別低風險病患的能力
- **95% CI**：使用 Bootstrap 計算信賴區間

### 3. 統計顯著性檢驗
```python
from scipy.stats import wilcoxon

# 比較兩個模型的 5-fold CV 結果
stat, p_value = wilcoxon(auc_xgboost, auc_mtl)
if p_value < 0.05:
    print("MTL 顯著優於 XGBoost")
```

---

## 實驗環境

### 硬體
- **CPU**：多核心（GA 可平行化）
- **RAM**：16GB+（處理 14,466 筆資料）
- **GPU**：（可選）加速深度學習訓練

### 軟體
```python
# 傳統 ML
scikit-learn==1.5.0
xgboost==2.0.3
lightgbm==4.3.0

# 深度學習
tensorflow==2.15.0  # 或 pytorch==2.1.0
keras==2.15.0

# 演化算法
sklearn-genetic==0.7.0
deap==1.4.1  # Distributed Evolutionary Algorithms in Python

# 視覺化
matplotlib==3.8.0
seaborn==0.13.0
shap==0.44.0  # 模型解釋
```

---

## 預期貢獻

### 1. 方法學貢獻
- **系統性模型比較**：涵蓋傳統 ML、深度學習、演化算法
- **多任務學習驗證**：MTL 是否適合三高預測
- **GA 在醫療預測的應用**：探索演化算法的實用性

### 2. 實務貢獻
- **模型選擇指引**：不同情境下的最佳模型建議
- **性能-成本權衡**：訓練時間、可解釋性、部署難度的考量

### 3. 理論貢獻
- **邊際效應遞減**：記錄數與特徵數的飽和點
- **特徵交互探索**：GA 可能發現的非線性特徵組合

---

## 論文撰寫結構

### Methods 章節
```
3. Methods
  3.1 Data Preprocessing
  3.2 Feature Engineering
  3.3 Model Selection
    3.3.1 Traditional Machine Learning
    3.3.2 Deep Learning
    3.3.3 Evolutionary Algorithms
  3.4 Evaluation Strategy
  3.5 Hyperparameter Tuning
```

### Results 章節
```
4. Results
  4.1 Baseline Model Performance
    - Table 1: LR, RF, XGBoost 性能比較
  4.2 Deep Learning vs. Traditional ML
    - Table 2: MLP, MTL 性能比較
    - Figure 1: MTL 架構與共享特徵視覺化
  4.3 Feature Selection via Genetic Algorithm
    - Table 3: GA vs. 傳統特徵選擇方法
    - Figure 2: GA 演化過程（適應度 vs. 代數）
  4.4 Diminishing Marginal Returns
    - Figure 3: 記錄數 vs. AUC 曲線
    - Figure 4: 特徵數 vs. AUC 曲線
    - Figure 5: 二維熱圖（記錄數 × 特徵數）
  4.5 Final Model Comparison
    - Table 4: 綜合比較表（性能、時間、可解釋性）
```

### Discussion 章節
```
5. Discussion
  5.1 Key Findings
    - XGBoost 達最高 AUC (0.82)
    - MTL 略優於獨立模型（共享特徵有效）
    - GA 找出 Top-7 特徵組合
    - 3 次記錄 + 5 個特徵達性能-成本平衡
  5.2 Comparison with Literature
    - vs. Liu et al. (2024): 多疾病 vs. 單疾病
    - vs. Taiwan MTL (2025): 相似架構、不同資料
  5.3 Clinical Implications
    - 建議檢驗組合：3 次記錄、5 個核心指標
    - 模型選擇建議：XGBoost（高性能）vs. LR（可解釋）
  5.4 Limitations
    - 合成資料 vs. 真實資料
    - 單一資料源
    - 未考慮用藥史
```

---

## 時間規劃

| 階段 | 任務 | 預計時間 |
|------|------|---------|
| Phase 1 | Baseline 建立 | 1-2 週 |
| Phase 2 | 深度學習探索 | 2-3 週 |
| Phase 3 | 演化算法應用 | 2-3 週 |
| Phase 4 | 邊際效應實驗 | 1-2 週 |
| Phase 5 | 最終比較與分析 | 1 週 |
| **總計** | | **7-11 週** |

---

## 風險與應對

### 風險 1: GA 計算時間過長
**應對**：
- 減少族群大小（50 → 30）
- 減少演化代數（100 → 50）
- 使用平行計算（joblib）
- 若仍太慢，改用簡化版 GA 或放棄 GP

### 風險 2: 深度學習過擬合
**應對**：
- 增加 Dropout (0.3 → 0.5)
- 使用 Early Stopping
- 增加 L2 正則化
- 資料增強（如 SMOTE，謹慎使用）

### 風險 3: 模型性能不如預期
**應對**：
- 檢查資料品質（缺失值、異常值）
- 重新設計特徵工程
- 調整診斷標準（是否過嚴/過鬆）
- 分析預測失敗案例（Error Analysis）

### 風險 4: 不同模型結果相近
**應對**：
- 強調「性能相近但各有優勢」
- 從可解釋性、訓練時間、部署難度等維度分析
- 提供不同情境的模型選擇建議

---

## 參考文獻

### 三高預測相關
- Liu et al. (2024) - 台中榮總糖尿病預測（XGBoost, RF）
- Taiwan MTL (2025) - 多疾病預測（MTL）

### 演化算法在醫療的應用
- [待補充] GA 在特徵選擇的應用
- [待補充] GP 在生物醫學的應用

### 多任務學習
- [待補充] MTL 在醫療預測的應用
- [待補充] Hard sharing vs. Soft sharing

---

## 會議討論紀錄

**日期**: 2025-01-14
**討論內容**：
- 確認需比較的模型類型
- GA/GP 用於特徵選擇與自動特徵工程
- 傳統 ML (LR, RF) 作為 baseline
- 深度學習（MLP, MTL）探索多任務學習

---

## 後續工作

- [ ] 完成 Phase 1: Baseline 模型（LR, RF, XGBoost）
- [ ] 實作 MLP 與 MTL 架構
- [ ] 研究 sklearn-genetic 或 DEAP 套件
- [ ] 設計 GA 特徵選擇實驗
- [ ] 規劃模型比較的視覺化圖表

---

## 標籤

`#模型比較` `#XGBoost` `#RandomForest` `#深度學習` `#MultiTaskLearning` `#GeneticAlgorithm` `#特徵選擇` `#實驗設計`
