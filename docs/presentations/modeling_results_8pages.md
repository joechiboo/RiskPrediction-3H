# 三高疾病預測建模成果報告

**研究主題**: 基於縱向健檢資料的三高疾病預測模型比較
**研究期間**: 2024年 - 2026年
**報告人**: 紀伯喬
**日期**: Meeting 17

---

## 封面講稿 (1分鐘)

各位好，今天要向大家報告「基於縱向健檢資料的三高疾病預測模型比較」。

首先要特別說明標題中的「縱向」兩個字。過去我們看了許多疾病預測的論文，大部分都是橫斷面研究，也就是只用單一時間點的資料來預測疾病風險。但這種方法有個重要的限制：它無法捕捉個體健康狀態的動態變化。

什麼是縱向資料呢？就是對同一個人持續追蹤多年，記錄他每次健檢的結果。舉例來說，我們可以看到某個人第一年血糖90，第二年92，第三年95，這種逐年上升的趨勢，就是橫斷面研究無法捕捉的重要資訊。

所以在命名論文時，我們使用「縱向」這個詞，就是要清楚識別這個特點：我們追蹤的不是一群不同的人，而是同一群人在不同時間點的健康變化。這種設計讓我們能夠計算變化量特徵，也就是Delta特徵，這正是本研究的核心創新。

接下來我會詳細介紹資料集的特性、面臨的挑戰，以及六種模型的比較結果。

---

## Slide 1: 資料集品質與檢查次數分佈

### 📊 資料來源
- **原始資料**: 6,119 位受檢者
- **篩選後**: 6,056 位 (移除 63 筆不完整記錄)
- **平均檢查次數**: 4.2 次

### 📈 檢查次數分佈

![檢查次數分佈圖](../experiments/figures/checkup_distribution_full.png)

| 檢查次數 | 1次 | 2次 | 3次 | 4次 | 5次 | 6次 | 7次 | 8次 |
|---------|-----|-----|------|------|------|-----|-----|-----|
| 人數 | 8 | 55 | 1,754 | 1,776 | 1,935 | 556 | 31 | 4 |
| 百分比 | 0.1% | 0.9% | 28.7% | 29.0% | 31.6% | 9.1% | 0.5% | 0.1% |

- **已排除**: 1-2次 (63人，資料不足)
- **核心樣本**: 3-5次 (5,465人，89.3%)

### 📢 講稿 (1分鐘)

各位好,今天要向大家報告三高疾病預測的建模成果。首先看資料集的品質,我們從6,119位受檢者中篩選出6,056位樣本。

我們對資料做了兩個主要的過濾。第一,我們捨棄了檢驗次數低於3次的紀錄,只保留至少有3次檢驗的受檢者,因為我們的研究設計是把T1到T2當作訓練集,T2到T3當作測試集,至少需要三個時間點。

第二個過濾更重要,我們針對慢性疾病早期症狀不明顯的特性做設計。如果一個人有多次檢驗結果,我們只取前三次,因為前期的檢驗結果較可能是正常的,這樣才能真正測試模型對早期風險的預測能力。這是一個縱向資料集,將近90%的人有3到5次檢查記錄,平均4.2次,讓我們能夠追蹤健康狀態的動態變化。

---

## Slide 2: 問題描述

### 🎯 研究問題（數學表述）

**給定**: 個體在 T₁, T₂ 的健檢資料
**預測**: T₃ 是否罹患三高疾病

```
f(X_T₁, X_T₂, Δ) → Y_T₃ ∈ {0, 1}

其中:
• X_T₁, X_T₂: T₁, T₂ 時間點的生物標記
• Δ = X_T₂ - X_T₁: 縱向變化量（核心創新）
• Y_T₃: T₃ 的疾病狀態（高血壓/高血糖/高血脂）
```

### 📊 預測目標（三個二元分類問題）
- **高血壓** (16.68%, 1,010人)
- **高血糖** (5.53%, 335人)
- **高血脂** (5.96%, 361人)

### 🔑 核心挑戰
1. **類別極度不平衡** (< 6%)
2. **如何有效利用 Δ 特徵?**
3. **模型選擇** (可解釋 vs 性能)

### 📢 講稿 (40秒)

我們的研究問題用數學式表達就是:給定個體在T1和T2兩個時間點的健檢資料,預測T3時是否會罹患三高疾病。這裡的關鍵是Δ,也就是Delta,代表T2減T1的變化量,這是我們的核心創新。

預測目標是三個二元分類問題:高血壓、高血糖、高血脂。面臨三大挑戰:第一是類別極度不平衡,高血糖和高血脂只有6%左右;第二是如何有效利用Delta特徵;第三是如何在可解釋性與預測性能間取得平衡。

---

## Slide 3: 實驗設計與模型總覽

### 🎯 評估指標
- **AUC** (主要指標): 模型區分能力
- **F1 Score**: 精確率與召回率的調和平均
- **Recall**: 疾病篩檢的敏感度（重要！）

### 🔬 測試模型 (6 種)

| 編號 | 模型 | 類型 | 主要特色 |
|------|------|------|----------|
| 01 | Logistic Regression | 傳統統計 | 可解釋性最高 |
| 02 | Random Forest | 集成學習 | 原生多輸出支援、快速訓練 |
| 03 | XGBoost | 集成學習 | 產業標準、特徵重要性 |
| 04 | Neural Networks | 深度學習 | 非線性建模 |
| 05 | SVM | 核方法 | 最大間隔分類器 |
| 06 | Genetic Programming | 演化計算 | 符號回歸、公式發現 |

### 🛠️ 類別不平衡處理
- **LR/RF/XGBoost/SVM**: `class_weight='balanced'`
- **ANN**: Custom class weight dictionary
- **GP**: ❌ gplearn 不支援 (致命缺陷)

### 📢 講稿 (1分鐘)

為了全面評估不同模型的表現,我們總共測試了6種模型,涵蓋了從傳統統計到前沿演化計算的各種方法。包括最經典的Logistic Regression、Random Forest和XGBoost這些集成學習方法、深度學習的Neural Networks、支援向量機SVM,以及較新的Genetic Programming。我們選擇AUC作為主要評估指標,因為它能有效衡量模型的區分能力,不受類別不平衡影響。同時也關注F1分數和Recall,特別是Recall在疾病篩檢中非常重要,因為我們希望能捕捉到盡可能多的潛在患者。針對類別不平衡問題,我們在大部分模型中使用了class_weight='balanced'機制,讓模型更重視少數類別的樣本。但要特別注意的是,Genetic Programming因為套件限制無法使用這個機制,這也成為它後來失敗的主要原因。

---

## Slide 4: 模型效能總覽 (AUC 比較)

### 🏆 六種模型 × 三種疾病 AUC 比較

| 疾病 \ 模型 | LR | RF | XGBoost | ANN | SVM | GP |
|------------|----|----|---------|-----|-----|----|
| **高血壓** | 0.749 | 0.796 | 0.795 | **0.803** 🥇 | 0.793 | 0.714 |
| **高血糖** | **0.931** 🥇 | 0.892 | 0.903 | 0.899 | 0.904 | - |
| **高血脂** | **0.888** 🥇 | 0.868 | 0.886 | 0.861 | 0.858 | 0.500 |
| **平均訓練時間** | ~1秒 | 秒級 | 秒級 | ~7秒 | ~11秒 | 3.8分鐘 |

**特別標註**: RF 多任務學習（MTL）在高血糖達到 **0.914** 🥈

### 📊 關鍵發現
1. **沒有單一最佳模型** - 不同疾病最佳模型不同
2. **LR 表現驚豔** - 在高血糖/高血脂達到最佳 AUC
3. **ANN 高血壓最佳** - AUC 0.803 (超越所有模型)
4. **RF 穩定優秀** - 三個疾病都在前四名 (第2-3名)
5. **MTL RF 突破** - 高血糖 AUC=0.914 達到第2名！
6. **XGBoost 最穩定** - 三個疾病都在前三名
7. **GP 全面失敗** - 高血脂 AUC=0.5 (隨機猜測)

### ⚡ 訓練速度比較
- **LR**: ~1秒（最快）
- **RF/XGBoost**: 秒級
- **ANN**: ~7秒/模型（MTL 版本 9.3秒可同時預測三種疾病）
- **SVM**: ~11秒
- **GP**: 3.8分鐘（最慢且無效）

### 📢 講稿 (1分鐘)

現在來看整體的模型效能比較。這張表格展示了各模型在三種疾病上的AUC排名,我們可以看到一個非常重要的發現:沒有單一最佳模型。不同疾病的最佳模型完全不同。在高血壓預測上,ANN以0.803的AUC拿下冠軍,Random Forest和XGBoost緊追在後。但在高血糖和高血脂的預測上,最簡單的Logistic Regression反而表現最好,AUC分別達到0.931和0.888,這真的讓我們相當驚訝。XGBoost展現了最穩定的表現,在三種疾病上都進入前三名。Random Forest也相當穩定,特別值得一提的是它的多任務學習版本在高血糖預測上達到第二名,AUC 0.914。最讓人失望的是Genetic Programming,在高血脂上的AUC只有0.5,等於隨機猜測。從訓練速度來看,所有成功的模型都在秒級完成,LR最快只需1秒,ANN平均每個疾病7秒,SVM約11秒,都非常有效率。只有GP需要3.8分鐘但完全無效。

---

## Slide 5: 五大模型全面比較

### 📊 綜合效能比較表

| 模型 | 高血壓 AUC | 高血糖 AUC | 高血脂 AUC | 訓練速度 | 核心優勢 | 主要劣勢 |
|------|-----------|-----------|-----------|----------|----------|----------|
| **LR** | 0.749 (5th) | **0.931 (1st)** | **0.888 (1st)** | **~1秒** | 最高Recall(0.73-0.83)、完美可解釋性 | 高血壓表現一般 |
| **RF** | 0.796 (2nd) | 0.892 (5th) | 0.868 (3rd) | **秒級** | 原生多輸出、MTL優異(高血糖0.914) | F1/Recall偏低 |
| **XGBoost** | 0.795 (3rd) | 0.903 (4th) | 0.886 (2nd) | **秒級** | 最高F1、最穩定(全進前三) | 無突出劣勢 |
| **ANN** | **0.803 (1st)** | 0.899 (4th) | 0.861 (4th) | 分鐘級 | 高血壓冠軍、高Recall(81.2%) | 訓練慢、不可解釋 |
| **SVM** | 0.793 (4th) | 0.904 (3rd) | 0.858 (5th) | 11秒 | 訓練速度驚喜(比預期快300倍) | 無明顯優勢 |

### 🎯 模型特性深度分析

#### **Logistic Regression** - 醫學應用首選 🥇
- **驚豔表現**: 🥇 高血糖/高血脂雙冠軍 (AUC: 0.931, 0.888)
- **最高Recall**: 全部疾病 Recall 最高 (0.728-0.833),捕捉最多患者
- **極致效率**: 訓練僅需 ~1 秒
- **完美可解釋**: 提供係數、Odds Ratio,符合醫學邏輯
- **特徵重要性**: 高血壓看SBP/DBP、高血糖看FBG、高血脂看TC
- **適用場景**: 臨床解釋、快速部署、疾病篩檢

#### **Random Forest** - 多任務學習之星
- **穩定排名**: 高血壓第2、高血脂第3名
- **MTL突破**: 多任務版本高血糖AUC=0.914(第2名),提升0.022
- **原生多輸出**: 單一模型同時預測三種疾病
- **特徵重要性**: 提供feature_importances_,可視覺化
- **缺點**: F1和Recall偏低,需調整threshold
- **適用場景**: 多疾病聯合預測、快速原型

#### **XGBoost** - 最穩定通用模型
- **最穩定**: 三個疾病全進前三名 (2nd, 4th, 2nd)
- **最高F1**: 所有疾病F1分數第一 (0.449-0.537)
- **平衡效能**: Precision與Recall最佳平衡
- **訓練快速**: 秒級完成,提供特徵重要性
- **適用場景**: 實務部署首選、特徵工程、模型分析

#### **Neural Networks** - 高血壓專家 🥇
- **🥇 高血壓冠軍**: AUC=0.803,超越所有模型
- **高Recall**: 高血壓Recall=0.812,捕捉81.2%患者
- **架構**: Input(26) → Dense(64,ReLU) → Dropout(0.3) → Dense(32,ReLU) → Dropout(0.3) → Output(1,Sigmoid)
- **MTL挑戰**: 初步MTL失敗(高血脂F1=0),需調整loss_weights=[1.0, 3.0, 3.0]
- **缺點**: 訓練時間長、可解釋性差
- **適用場景**: 追求極致效能、研究用途

#### **SVM** - 速度驚喜但無優勢
- **速度驚喜**: 總訓練11秒,比預期快300倍(原估1-2小時)
- **中階表現**: 高血糖第3名(0.904)、高血壓第4名(0.793)
- **高Recall**: 高血壓Recall=0.738
- **原因分析**: 資料標準化良好、sklearn優化、樣本數適中
- **結論**: 穩定但無突出優勢,不如XGBoost/LR
- **適用場景**: 不推薦優先使用

### 🔑 關鍵發現總結
1. **疾病特異性**: 不同疾病需要不同模型(LR擅長高血糖/高血脂,ANN擅長高血壓)
2. **簡單有效**: LR以最簡單架構達到兩項冠軍,證明複雜≠更好
3. **穩定性價值**: XGBoost和RF展現優秀的跨疾病穩定性
4. **MTL潛力**: RF的多任務學習版本顯著提升高血糖預測
5. **速度效率**: 除ANN外,所有5個成功模型都能秒級訓練,實務可行性高

### 📢 講稿 (1分鐘)

現在來看五大成功模型的全面比較。這張表格整合了所有表現良好的模型在三種疾病上的效能。首先是Logistic Regression,它是本研究最大的驚喜,在高血糖和高血脂上都是冠軍,而且所有疾病的Recall都是最高的,加上只需要1秒訓練和完美的可解釋性,非常適合臨床應用。Random Forest展現了穩定的排名,更令人興奮的是它的多任務學習版本在高血糖上達到第二名,證明單一模型可以有效同時預測三種疾病。XGBoost是最穩定的通用模型,三個疾病全部進入前三名,F1分數最高,是實務部署的首選。ANN在高血壓上表現最好,AUC 0.803,但訓練時間較長且不可解釋。SVM雖然訓練速度比預期快300倍,但整體表現沒有突出優勢。這五個模型展現了各自的優勢和適用場景,為實務應用提供了豐富的選擇。

---

## Slide 6: Genetic Programming 建模方式與失敗分析

### 🧬 GP 簡介與建模方式

**使用套件**: `gplearn` - Python 的 Genetic Programming 套件

**核心概念**: 符號回歸 (Symbolic Regression)
- 不預設模型形式，讓演化算法自動發現最佳數學公式
- 從資料中「演化」出預測公式，而非「擬合」參數

### ⚙️ 關鍵參數設定

| 參數 | 設定值 | 功能說明 |
|------|--------|----------|
| `population_size` | 1000 | 每個世代的公式數量 |
| `generations` | 20 | 演化世代數 |
| `tournament_size` | 20 | 錦標賽選擇：隨機挑 20 個，選最佳當父母 |
| `function_set` | +, -, ×, ÷, log, √ | 允許的數學運算子 |
| `parsimony_coefficient` | 0.01 | **複雜度懲罰**：越大越偏好簡單公式 |
| `metric` | log loss | 適應度函數：評估公式好壞 |

### 🔄 GP 演化流程

```
1. 初始化 → 隨機生成 1000 個公式（樹狀結構）
2. 評估   → 用 log loss 計算每個公式的適應度
3. 選擇   → 錦標賽選擇：隨機挑 20 個，最佳者繁殖
4. 繁殖   → 交配 (70%) + 突變 (25%) + 複製 (5%)
5. 重複   → 執行 20 個世代
6. 輸出   → 返回最佳公式
```

### 📊 演化結果：公式分析

| 疾病 | 演化公式 | AUC | 問題 |
|------|----------|-----|------|
| 高血壓 | `add(log(-0.14), X8)` | 0.714 | 只用 DBP_T2，log(負數) |
| 高血糖 | `log(mul(X10, -0.14))` | 0.838 | 只用 TC_T2 |
| 高血脂 | `log(-0.058)` | **0.500** | ⚠️ **常數！完全沒用特徵** |

### ❌ 失敗根本原因

#### 1️⃣ **gplearn 不支援 class_weight**
- 其他模型都能用 `class_weight='balanced'` 處理不平衡
- GP 無此機制，導致模型偏向預測多數類（健康）

#### 2️⃣ **parsimony_coefficient 過大**
```
實際適應度 = 預測適應度 + 0.01 × 公式長度
```
- 在類別不平衡下，「預測常數」既簡單又能降低 loss
- 高血脂直接退化成常數公式 `log(-0.058)`

#### 3️⃣ **log loss 在不平衡數據的問題**
- 高血脂只有 5.96% 正樣本
- 預測全部為 0 的 log loss ≈ 0.22（看起來「還不錯」）
- GP 找到了「作弊」策略：預測常數

### 📚 學術價值：有價值的負面結果

1. **證明 class_weight 的重要性** - 與其他 5 個成功模型對比
2. **揭示 GP 的適用限制** - 不適合高維度、高度不平衡的醫學資料
3. **避免 publication bias** - 誠實報告失敗，增強研究完整性

### 📢 講稿 (1分鐘)

接下來介紹Genetic Programming的建模方式和失敗分析。我們使用gplearn套件進行符號回歸,這是一種讓演化算法自動發現數學公式的方法。關鍵參數包括族群大小1000、演化20個世代,以及parsimony coefficient設為0.01來控制公式複雜度。演化流程是:先隨機生成1000個公式,用log loss評估適應度,透過錦標賽選擇優秀個體,再經過交配和突變產生下一代。然而結果令人失望,高血脂的公式竟然退化成常數log負0.058,AUC只有0.5等於隨機猜測。失敗原因有三:第一,gplearn不支援class_weight機制;第二,parsimony coefficient設定讓GP過度追求簡單公式;第三,log loss在不平衡數據下會讓模型傾向預測多數類。雖然GP失敗了,但這是有價值的負面結果,證明了class_weight機制的重要性,也為模型選擇提供了重要參考。

---

## Slide 7: Multi-Task Learning 嘗試與反思

### 🎯 什麼是 MTL？為何嘗試？

**定義**: 單一模型同時預測多個任務（高血壓、高血糖、高血脂）

**當初動機**: 預期能減少計算時間、共享疾病間的關聯特徵

### 💭 預期 vs 實際

| 面向 | 原本預期 | 實際情況 |
|------|----------|----------|
| **計算效率** | 減少訓練時間 | 資料量小 (6,056)，所有模型**秒級完成** |
| **效能提升** | 共享表徵學習 | 僅高血糖 +0.022，**其他無提升** |

### 📊 實驗結果

| 模型 | 結果 | 說明 |
|------|------|------|
| **RF MTL** | 高血糖 AUC 0.892→0.914 (+0.022) | ✅ 唯一成功案例 |
| **ANN MTL** | 高血脂 F1=0，完全失敗 | ❌ 類別不平衡導致少數類被忽略 |

### ⚠️ 結論：未來將捨棄 MTL

**原因**：
1. **效率優勢不存在** - 資料量小，Single-Task 也是秒級
2. **效能提升有限** - 僅高血糖微幅提升
3. **Single-Task 已足夠好** - LR 在高血糖/高血脂已是冠軍

**決定**: 回歸 Single-Task，各疾病選用最佳模型

### 📢 講稿 (40秒)

接下來談談Multi-Task Learning的嘗試。當初選擇MTL是預期能減少計算時間,但實際資料量只有6056筆,所有模型都是秒級完成,效率優勢不存在。實驗結果方面,Random Forest的MTL版本在高血糖上提升了0.022,但ANN的MTL版本完全失敗。綜合評估後,我們決定未來將捨棄MTL,回歸Single-Task模型,因為Logistic Regression單任務在高血糖和高血脂已經是冠軍,沒有必要增加複雜度。

---

## Slide 8: 下一步研究計畫

### 🎯 具體待辦事項

#### 1️⃣ **SHAP 可解釋性分析**
- 對 XGBoost/LR 進行 SHAP 分析
- 驗證 Δ 特徵的重要性排名

#### 2️⃣ **消融實驗：驗證 Δ 特徵貢獻**
- 比較：有 Δ 特徵 vs 無 Δ 特徵
- 量化 Δ 特徵對 AUC 的提升幅度

#### 3️⃣ **重新檢視 GP 實驗**
- 調整 parsimony_coefficient（0.01 → 0.001）
- 嘗試 SMOTE 過採樣處理類別不平衡
- 確認是否為參數問題或方法本身限制

#### 4️⃣ **論文撰寫**
- 從第三章（研究方法）開始，素材最齊全
- 再寫第四章（實驗結果）

#### 5️⃣ **外部驗證** (視資料取得情況)
- 尋找其他健檢資料集測試泛化能力

### 📢 講稿 (30秒)

最後說明下一步的研究計畫。首先是SHAP分析,驗證Delta特徵的重要性。第二是消融實驗,量化Delta特徵對AUC的貢獻。第三是重新檢視GP實驗,調整參數看能否改善效能。第四是論文撰寫,從第三章研究方法開始。最後是外部驗證,視資料取得情況進行。謝謝各位！

---

### 🙏 致謝

感謝指導教授的專業指導與建議！

---

**簡報結束 - 謝謝聆聽！**