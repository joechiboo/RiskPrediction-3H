# 三高疾病預測建模成果報告

**研究主題**: 基於縱向健檢資料的三高疾病預測模型比較
**研究期間**: 2025年1月
**模型實驗**: 01-07 (Logistic Regression + Random Forest → Genetic Programming)
**報告人**: 紀伯喬
**日期**: Meeting 18
**投影片數**: 9 頁

---

## Slide 1: 研究目標與資料概況

### 📊 研究目標
預測受檢者在 T3 時間點是否罹患三高疾病：
- **高血壓** (Hypertension)
- **高血糖** (Hyperglycemia)
- **高血脂** (Dyslipidemia)

### 📈 資料集特性
- **樣本數**: 6,056 人
- **時間點**: T1 (基線) → T2 (追蹤) → T3 (預測目標)
- **特徵數**: 26 個
  - 人口統計: 性別、年齡 (2)
  - T1 生物標記: FBG, TC, Cr, UA, GFR, BMI, SBP, DBP (8)
  - T2 生物標記: 同上 (8)
  - **Δ 變化量**: T2 - T1 差異 (8)

### ⚠️ 類別不平衡問題
- 高血壓: **16.68%** (1,010 人)
- 高血糖: **5.53%** (335 人)
- 高血脂: **5.96%** (361 人)

### 📢 講稿 (1分鐘)

各位好,今天要向大家報告我們在三高疾病預測建模上的研究成果。我們的研究目標是利用縱向健檢資料,預測受檢者在第三次檢查時是否會罹患高血壓、高血糖或高血脂。我們使用了6,056位受檢者的資料,這些資料包含三個時間點,從基線T1到追蹤T2,最後預測T3的疾病狀態。我們設計了26個特徵,除了基本的人口統計資料,還包括兩個時間點的生物標記,特別重要的是我們加入了Delta變化量特徵,也就是T2減去T1的差異,用來捕捉健康狀態的動態變化。這個研究最大的挑戰是類別不平衡問題,高血壓的患病率約17%,而高血糖和高血脂更低,只有5-6%左右,這對模型訓練帶來相當大的困難。接下來我會說明我們如何解決這個問題。

---

## Slide 2: 實驗設計與模型總覽

### 🎯 評估指標
- **AUC** (主要指標): 模型區分能力
- **F1 Score**: 精確率與召回率的調和平均
- **Recall**: 疾病篩檢的敏感度（重要！）

### 🔬 測試模型 (6 種)

| 編號 | 模型 | 類型 | 主要特色 |
|------|------|------|----------|
| 01 | Logistic Regression | 傳統統計 | 可解釋性最高 |
| 02 | Random Forest | 集成學習 | 原生多輸出支援、快速訓練 |
| 03 | XGBoost | 集成學習 | 產業標準、特徵重要性 |
| 04 | Neural Networks | 深度學習 | 非線性建模 |
| 05 | SVM | 核方法 | 最大間隔分類器 |
| 06 | Genetic Programming | 演化計算 | 符號回歸、公式發現 |

### 🛠️ 類別不平衡處理
- **LR/RF/XGBoost/SVM**: `class_weight='balanced'`
- **ANN**: Custom class weight dictionary
- **GP**: ❌ gplearn 不支援 (致命缺陷)

### 📢 講稿 (1分鐘)

為了全面評估不同模型的表現,我們總共測試了6種模型,涵蓋了從傳統統計到前沿演化計算的各種方法。包括最經典的Logistic Regression、Random Forest和XGBoost這些集成學習方法、深度學習的Neural Networks、支援向量機SVM,以及較新的Genetic Programming。我們選擇AUC作為主要評估指標,因為它能有效衡量模型的區分能力,不受類別不平衡影響。同時也關注F1分數和Recall,特別是Recall在疾病篩檢中非常重要,因為我們希望能捕捉到盡可能多的潛在患者。針對類別不平衡問題,我們在大部分模型中使用了class_weight='balanced'機制,讓模型更重視少數類別的樣本。但要特別注意的是,Genetic Programming因為套件限制無法使用這個機制,這也成為它後來失敗的主要原因。

---

## Slide 3: 模型效能總覽 (AUC 比較)

### 🏆 完整效能排名表

| 疾病 | 🥇 第一名 | 🥈 第二名 | 🥉 第三名 | 第四名 | 第五名 | 第六名 |
|------|-----------|-----------|-----------|---------|--------|--------|
| **高血壓** | **ANN** 0.803 | **RF** 0.796 | XGBoost 0.795 | SVM 0.793 | LR 0.749 | **GP 0.714** |
| **高血糖** | **LR** 0.931 | **MTL RF** 0.914 | SVM 0.904 | XGBoost 0.903 | ANN 0.899 | RF 0.892 |
| **高血脂** | **LR** 0.888 | XGBoost 0.886 | **RF** 0.868 | ANN 0.861 | SVM 0.858 | **GP 0.500** |

### 📊 關鍵發現
1. **沒有單一最佳模型** - 不同疾病最佳模型不同
2. **LR 表現驚豔** - 在高血糖/高血脂達到最佳 AUC
3. **ANN 高血壓最佳** - AUC 0.803 (超越所有模型)
4. **RF 穩定優秀** - 三個疾病都在前四名 (第2-3名)
5. **MTL RF 突破** - 高血糖 AUC=0.914 達到第2名！
6. **XGBoost 最穩定** - 三個疾病都在前三名
7. **GP 全面失敗** - 高血脂 AUC=0.5 (隨機猜測)

### ⚡ 訓練速度
- LR/RF/XGBoost/SVM: **秒級** (~1-11 秒)
- ANN: **分鐘級** (~數分鐘)
- GP: **3.8 分鐘** (快但無用)

### 📢 講稿 (1分鐘)

現在來看整體的模型效能比較。這張表格展示了各模型在三種疾病上的AUC排名,我們可以看到一個非常重要的發現:沒有單一最佳模型。不同疾病的最佳模型完全不同。在高血壓預測上,ANN以0.803的AUC拿下冠軍,Random Forest和XGBoost緊追在後。但在高血糖和高血脂的預測上,最簡單的Logistic Regression反而表現最好,AUC分別達到0.931和0.888,這真的讓我們相當驚訝。XGBoost展現了最穩定的表現,在三種疾病上都進入前三名。Random Forest也相當穩定,特別值得一提的是它的多任務學習版本在高血糖預測上達到第二名,AUC 0.914。最讓人失望的是Genetic Programming,在高血脂上的AUC只有0.5,等於隨機猜測。從訓練速度來看,除了ANN需要幾分鐘,其他模型都在秒級完成,非常有效率。

---

## Slide 4: 五大模型全面比較

### 📊 綜合效能比較表

| 模型 | 高血壓 AUC | 高血糖 AUC | 高血脂 AUC | 訓練速度 | 核心優勢 | 主要劣勢 |
|------|-----------|-----------|-----------|----------|----------|----------|
| **LR** | 0.749 (5th) | **0.931 (1st)** | **0.888 (1st)** | **~1秒** | 最高Recall(0.73-0.83)、完美可解釋性 | 高血壓表現一般 |
| **RF** | 0.796 (2nd) | 0.892 (5th) | 0.868 (3rd) | **秒級** | 原生多輸出、MTL優異(高血糖0.914) | F1/Recall偏低 |
| **XGBoost** | 0.795 (3rd) | 0.903 (4th) | 0.886 (2nd) | **秒級** | 最高F1、最穩定(全進前三) | 無突出劣勢 |
| **ANN** | **0.803 (1st)** | 0.899 (4th) | 0.861 (4th) | 分鐘級 | 高血壓冠軍、高Recall(81.2%) | 訓練慢、不可解釋 |
| **SVM** | 0.793 (4th) | 0.904 (3rd) | 0.858 (5th) | 11秒 | 訓練速度驚喜(比預期快300倍) | 無明顯優勢 |

### 🎯 模型特性深度分析

#### 1️⃣ **Logistic Regression** - 醫學應用首選
- **驚豔表現**: 高血糖/高血脂雙冠軍 (AUC: 0.931, 0.888)
- **最高Recall**: 全部疾病 Recall 最高 (0.728-0.833),捕捉最多患者
- **極致效率**: 訓練僅需 ~1 秒
- **完美可解釋**: 提供係數、Odds Ratio,符合醫學邏輯
- **特徵重要性**: 高血壓看SBP/DBP、高血糖看FBG、高血脂看TC
- **適用場景**: 臨床解釋、快速部署、疾病篩檢

#### 2️⃣ **Random Forest** - 多任務學習之星
- **穩定排名**: 高血壓第2、高血脂第3名
- **MTL突破**: 多任務版本高血糖AUC=0.914(第2名),提升0.022
- **原生多輸出**: 單一模型同時預測三種疾病
- **特徵重要性**: 提供feature_importances_,可視覺化
- **缺點**: F1和Recall偏低,需調整threshold
- **適用場景**: 多疾病聯合預測、快速原型

#### 3️⃣ **XGBoost** - 最穩定通用模型
- **最穩定**: 三個疾病全進前三名 (2nd, 4th, 2nd)
- **最高F1**: 所有疾病F1分數第一 (0.449-0.537)
- **平衡效能**: Precision與Recall最佳平衡
- **訓練快速**: 秒級完成,提供特徵重要性
- **適用場景**: 實務部署首選、特徵工程、模型分析

#### 4️⃣ **Neural Networks** - 高血壓專家
- **高血壓冠軍**: AUC=0.803,超越所有模型
- **高Recall**: 高血壓Recall=0.812,捕捉81.2%患者
- **架構**: Input(26) → Dense(64,ReLU) → Dropout(0.3) → Dense(32,ReLU) → Dropout(0.3) → Output(1,Sigmoid)
- **MTL挑戰**: 初步MTL失敗(高血脂F1=0),需調整loss_weights=[1.0, 3.0, 3.0]
- **缺點**: 訓練時間長、可解釋性差
- **適用場景**: 追求極致效能、研究用途

#### 5️⃣ **SVM** - 速度驚喜但無優勢
- **速度驚喜**: 總訓練11秒,比預期快300倍(原估1-2小時)
- **中階表現**: 高血糖第3名(0.904)、高血壓第4名(0.793)
- **高Recall**: 高血壓Recall=0.738
- **原因分析**: 資料標準化良好、sklearn優化、樣本數適中
- **結論**: 穩定但無突出優勢,不如XGBoost/LR
- **適用場景**: 不推薦優先使用

### 🔑 關鍵發現總結
1. **疾病特異性**: 不同疾病需要不同模型(LR擅長高血糖/高血脂,ANN擅長高血壓)
2. **簡單有效**: LR以最簡單架構達到兩項冠軍,證明複雜≠更好
3. **穩定性價值**: XGBoost和RF展現優秀的跨疾病穩定性
4. **MTL潛力**: RF的多任務學習版本顯著提升高血糖預測
5. **速度效率**: 除ANN外,所有5個成功模型都能秒級訓練,實務可行性高

### 📢 講稿 (1分鐘)

現在來看五大成功模型的全面比較。這張表格整合了所有表現良好的模型在三種疾病上的效能。首先是Logistic Regression,它是本研究最大的驚喜,在高血糖和高血脂上都是冠軍,而且所有疾病的Recall都是最高的,加上只需要1秒訓練和完美的可解釋性,非常適合臨床應用。Random Forest展現了穩定的排名,更令人興奮的是它的多任務學習版本在高血糖上達到第二名,證明單一模型可以有效同時預測三種疾病。XGBoost是最穩定的通用模型,三個疾病全部進入前三名,F1分數最高,是實務部署的首選。ANN在高血壓上表現最好,AUC 0.803,但訓練時間較長且不可解釋。SVM雖然訓練速度比預期快300倍,但整體表現沒有突出優勢。這五個模型展現了各自的優勢和適用場景,為實務應用提供了豐富的選擇。

---

## Slide 5: Genetic Programming 徹底失敗案例分析

### ❌ 效能慘烈表現

| 疾病 | AUC | F1 Score | Recall | Precision | 結果分析 |
|------|-----|----------|--------|-----------|----------|
| **高血壓** | 0.714 | 0.265 | 0.501 | 0.175 | 最差表現,僅略優於隨機 |
| **高血糖** | 0.838 | 0.176 | 0.570 | 0.105 | 中等AUC但F1極低 |
| **高血脂** | **0.500** | 0.000 | 0.000 | 0.000 | **完全隨機猜測** |

**訓練時間**: 3.8 分鐘 (快但毫無意義)

### 🧬 演化出的公式分析

#### 高血壓 (AUC=0.714)
```python
log(abs(sqrt(abs(T1_FBG - 1.24)))) + log(abs(T2_GFR + T1_BMI))
```
- 使用了部分有意義特徵 (FBG, GFR, BMI)
- 但數學運算過於複雜且缺乏醫學解釋性

#### 高血糖 (AUC=0.838)
```python
sqrt(abs(T2_FBG)) - log(abs(T1_TC - T2_SBP))
```
- T2_FBG 是合理特徵
- 但 TC-SBP 的組合沒有臨床意義

#### 高血脂 (AUC=0.5) ⚠️ **致命案例**
```python
log(-0.058)
```
- **常數公式**:完全不使用任何特徵！
- 對所有樣本輸出相同預測值
- 等同於隨機猜測 (AUC=0.5)

### 🔍 失敗根本原因分析

#### 1️⃣ **致命缺陷:不支援 class_weight**
- gplearn 套件不支援 `class_weight='balanced'`
- 無法處理類別不平衡問題
- 三高疾病患病率極低:
  - 高血壓: 16.68% (1,010/6,056)
  - 高血糖: 5.53% (335/6,056)
  - 高血脂: 5.96% (361/6,056)
- **結果**: 模型傾向預測多數類(健康),忽略少數類(患病)

#### 2️⃣ **特徵維度詛咒**
- 使用 26 個特徵 (8 T1 + 8 T2 + 8 Δ + 2 人口統計)
- GP 適合 5-10 個特徵的簡單問題
- 搜索空間過大,難以找到有效組合

#### 3️⃣ **parsimony 係數設定不當**
- 設定 parsimony_coefficient=0.01 (懲罰複雜公式)
- 導致演化出過度簡化的公式
- 高血脂甚至退化為常數

#### 4️⃣ **缺乏領域知識引導**
- 純粹數據驅動的符號回歸
- 無法整合醫學知識 (如 SBP→高血壓、FBG→高血糖)
- 演化出的公式缺乏臨床可解釋性

### 📚 學術價值:有價值的負面結果

雖然 GP 在本研究中失敗,但這是一個**有學術價值的負面結果**:

1. **證明 class_weight 機制的重要性**
   - 與其他5個成功模型對比,凸顯類別不平衡處理的必要性

2. **揭示 GP 的適用限制**
   - GP 不適合高維度、高度不平衡的醫學資料
   - 需要特別的前處理或改進算法

3. **為未來研究指引方向**
   - 可嘗試自定義 GP fitness function 整合 class_weight
   - 或使用降維技術減少特徵數

4. **增強研究完整性**
   - 全面呈現成功與失敗案例
   - 避免 publication bias (只報告成功結果)

### ⚠️ 結論
- **GP 在不平衡醫學資料上完全不適用**
- **高血脂常數公式是經典的失敗案例**
- **強調類別不平衡處理的關鍵性**

### 📢 講稿 (1分鐘)

接下來要介紹一個徹底失敗但極具學術價值的案例:Genetic Programming。從效能表現來看,GP在高血壓的AUC只有0.714,高血糖0.838,但最驚人的是高血脂竟然只有0.5,完全等於隨機猜測。讓我們來看演化出的公式,高血壓和高血糖雖然使用了一些特徵,但數學運算過於複雜且缺乏醫學解釋性。最致命的是高血脂的公式居然是log(-0.058),一個常數!這代表對所有病人都輸出相同的預測值,完全不使用任何健檢資料。失敗的根本原因有四個:第一,gplearn不支援class_weight機制,無法處理5-17%的類別不平衡問題。第二,26個特徵對GP來說太多了,搜索空間過大。第三,parsimony係數設定導致公式過度簡化。第四,缺乏醫學領域知識引導。雖然GP失敗了,但這是有價值的負面結果,它證明了class_weight機制的重要性,也揭示了GP在高維度不平衡醫學資料上的限制,為未來研究提供了重要的參考。

---

## Slide 6: 實務建議與模型選擇指南

### 🎯 分疾病推薦方案

| 疾病 | 首選模型 | AUC | 理由 | 備選模型 |
|------|----------|-----|------|----------|
| **高血壓** | ANN | 0.803 | 最高準確率 + 高 Recall | RF 0.796 (第2名) |
| **高血糖** | LR | 0.931 | 最佳 AUC + 極快速度 | MTL RF 0.914 (第2名) |
| **高血脂** | LR | 0.888 | 最佳 AUC + 最高 Recall | XGBoost 0.886 (次高) |

---

### 🏆 通用模型推薦

#### 1️⃣ **XGBoost** - 首選通用方案
- ✅ 三個疾病都在前三名
- ✅ 最高 F1 分數 (平衡 Precision/Recall)
- ✅ 提供特徵重要性分析
- ✅ 訓練速度快 (~秒級)
- 📌 **適合**: 實務部署、特徵工程、模型分析

#### 2️⃣ **Logistic Regression** - 最高 CP 值
- ✅ 兩個疾病第一名 (高血糖/高血脂)
- ✅ 所有疾病最高 Recall (醫學應用關鍵)
- ✅ 極快速度 + 完美可解釋性
- 📌 **適合**: 臨床解釋、快速原型、基線模型

#### 3️⃣ **Random Forest** - 多任務學習首選
- ✅ 原生多輸出支援 (單模型預測三種疾病)
- ✅ MTL RF 在高血糖達到第2名 (AUC=0.914)
- ✅ 高血壓第2名、高血脂第3名
- ✅ 訓練速度快 (~秒級)
- ✅ 良好可解釋性 (特徵重要性)
- 📌 **適合**: 多疾病聯合預測、快速原型、需要同時處理三高

#### 4️⃣ **ANN** - 追求極致效能
- ✅ 高血壓最佳模型 (AUC=0.803)
- ⚠️ 訓練時間較長
- ⚠️ 可解釋性差
- 📌 **適合**: 研究用途、追求最高準確率

---

### ❌ 不推薦模型

- **SVM**: 無明顯優勢,可解釋性差
- **GP**: 嚴重失敗,不適合不平衡醫學資料

---

### 🔧 實務部署建議

**如果只能選一個模型**:
```
XGBoost (平衡效能、速度、可解釋性)
```

**如果需要最高 Recall** (疾病篩檢):
```
Logistic Regression (Recall: 0.73-0.83)
```

**如果需要極致 AUC**:
```
高血壓: ANN (0.803)
高血糖: LR (0.931)
高血脂: LR (0.888)
```

**如果需要多疾病聯合預測**:
```
Random Forest (原生多輸出、MTL 效能優異)
```

### 📢 講稿 (1分鐘)

基於前面的實驗結果,我們整理出清楚的實務建議和模型選擇指南。如果要針對特定疾病選擇模型,高血壓建議使用ANN,因為它有最高的AUC 0.803和Recall。高血糖和高血脂都建議使用Logistic Regression,不僅AUC最高,訓練速度也極快。如果需要一個通用模型來處理所有疾病,我們首推XGBoost,它在三個疾病上都進入前三名,F1分數最高,訓練快速,還能提供特徵重要性分析,非常適合實務部署。Logistic Regression是CP值最高的選擇,兩個疾病第一名,所有疾病都有最高Recall,加上極快的速度和完美的可解釋性,很適合臨床應用。Random Forest則是多任務學習的首選,它原生支援多輸出,MTL版本在高血糖達到第二名,可以用單一模型同時預測三種疾病。ANN適合追求極致效能的研究用途。至於SVM和GP我們不推薦使用,前者沒有明顯優勢,後者則嚴重失敗。

---

## Slide 7: 研究貢獻與未來方向

### 🎓 本研究貢獻

#### 1. **全面的模型比較** (6 種模型 × 3 種疾病)
- 傳統統計 (LR) vs 機器學習 (RF, XGBoost, SVM) vs 深度學習 (ANN) vs 演化計算 (GP)
- 首次在三高預測任務中系統性比較
- Random Forest 展現優異的多任務學習能力

#### 2. **Δ 特徵工程的有效性**
- T2-T1 變化量特徵顯著提升效能
- 縱向資料的時間動態資訊至關重要

#### 3. **類別不平衡處理的重要性**
- class_weight 機制顯著改善少數類預測
- GP 失敗案例證明其必要性

#### 4. **實務建議清晰**
- 分疾病推薦最佳模型
- 提供通用部署方案

#### 5. **有價值的負面結果**
- GP 在不平衡資料上的失敗
- 為模型選擇提供反面教材

---

### 🚀 未來研究方向

#### 1. **Multi-Task Learning 深化**
- ✅ Random Forest MTL 已證明有效 (高血糖 AUC=0.914)
- 進一步優化 MTL ANN 的 loss_weights
- 探索 task-specific 與 shared layers 的最佳比例
- 比較 RF MTL vs ANN MTL 的優劣

#### 2. **集成學習探索**
- Stacking: LR (高血糖/高血脂) + ANN (高血壓) + RF (通用)
- Voting: 結合 RF, XGBoost, LR 前三名模型
- 探索 RF 與 XGBoost 的互補性

#### 3. **深度特徵工程**
- 非線性 Δ 特徵 (如 T2/T1 比值)
- 特徵交互項 (SBP × BMI)

#### 4. **時間序列建模**
- LSTM/GRU 處理 T1→T2→T3 時間序列
- Transformer-based 模型

#### 5. **可解釋性 AI**
- SHAP/LIME 解釋 XGBoost/ANN 預測
- 整合臨床知識的規則抽取

#### 6. **外部驗證**
- 在其他健檢資料集驗證模型泛化能力
- 跨地區、跨族群驗證

---

### 📊 實驗記錄完整性

所有實驗均有完整 Jupyter Notebook:
- `01_EDA.ipynb` - 探索性資料分析
- `02_FeatureEngineering.ipynb` - 特徵工程
- `03_ModelBuilding.ipynb` - Logistic Regression + Random Forest
- `04_XGBoost.ipynb` - XGBoost
- `05_NeuralNetworks.ipynb` - ANN
- `06_SVM.ipynb` - SVM
- `07_GeneticProgramming.ipynb` - GP

**可重現性**: ✅ 所有程式碼、參數、結果已記錄於 GitHub

### 📢 講稿 (1分鐘)

最後總結一下本研究的貢獻和未來方向。我們進行了非常全面的模型比較,6種模型橫跨從傳統統計到演化計算的各個領域,在三高預測任務上進行系統性評估,這在相關研究中是首次。我們證明了Delta特徵工程的有效性,時間動態資訊對預測至關重要。GP的失敗案例也凸顯了class_weight機制和模型選擇的重要性。在未來研究方向上,最令人期待的是深化多任務學習,Random Forest MTL已經在高血糖上證明有效,接下來可以進一步優化ANN MTL的參數,比較不同MTL方法的優劣。集成學習也很值得探索,可以結合各模型的優勢做Stacking或Voting。此外還可以進行更深入的特徵工程,嘗試LSTM等時間序列模型,使用SHAP等工具提升可解釋性,以及在外部資料集上驗證模型的泛化能力。所有實驗都有完整的Jupyter Notebook記錄,確保研究的可重現性。感謝各位的聆聽,謝謝！

---

### 🙏 致謝

感謝指導教授的專業指導與建議！

---

**簡報結束 - 謝謝聆聽！**
