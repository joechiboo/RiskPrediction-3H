# 三高疾病預測建模成果報告

**研究主題**: 基於縱向健檢資料的三高疾病預測模型比較
**研究期間**: 2025年1月
**模型實驗**: 01-07 (Logistic Regression + Random Forest → Genetic Programming)
**報告人**: 紀伯喬
**日期**: Meeting 18
**投影片數**: 10 頁

---

## Slide 1: 研究目標與資料概況

### 📊 研究目標
預測受檢者在 T3 時間點是否罹患三高疾病：
- **高血壓** (Hypertension)
- **高血糖** (Hyperglycemia)
- **高血脂** (Dyslipidemia)

### 📈 資料集特性
- **樣本數**: 6,056 人
- **時間點**: T1 (基線) → T2 (追蹤) → T3 (預測目標)
- **特徵數**: 26 個
  - 人口統計: 性別、年齡 (2)
  - T1 生物標記: FBG, TC, Cr, UA, GFR, BMI, SBP, DBP (8)
  - T2 生物標記: 同上 (8)
  - **Δ 變化量**: T2 - T1 差異 (8)

### ⚠️ 類別不平衡問題
- 高血壓: **16.68%** (1,010 人)
- 高血糖: **5.53%** (335 人)
- 高血脂: **5.96%** (361 人)

### 📢 講稿 (1分鐘)

各位好,今天要向大家報告我們在三高疾病預測建模上的研究成果。我們的研究目標是利用縱向健檢資料,預測受檢者在第三次檢查時是否會罹患高血壓、高血糖或高血脂。我們使用了6,056位受檢者的資料,這些資料包含三個時間點,從基線T1到追蹤T2,最後預測T3的疾病狀態。我們設計了26個特徵,除了基本的人口統計資料,還包括兩個時間點的生物標記,特別重要的是我們加入了Delta變化量特徵,也就是T2減去T1的差異,用來捕捉健康狀態的動態變化。這個研究最大的挑戰是類別不平衡問題,高血壓的患病率約17%,而高血糖和高血脂更低,只有5-6%左右,這對模型訓練帶來相當大的困難。接下來我會說明我們如何解決這個問題。

---

## Slide 2: 實驗設計與模型總覽

### 🎯 評估指標
- **AUC** (主要指標): 模型區分能力
- **F1 Score**: 精確率與召回率的調和平均
- **Recall**: 疾病篩檢的敏感度（重要！）

### 🔬 測試模型 (6 種)

| 編號 | 模型 | 類型 | 主要特色 |
|------|------|------|----------|
| 01 | Logistic Regression | 傳統統計 | 可解釋性最高 |
| 02 | Random Forest | 集成學習 | 原生多輸出支援、快速訓練 |
| 03 | XGBoost | 集成學習 | 產業標準、特徵重要性 |
| 04 | Neural Networks | 深度學習 | 非線性建模 |
| 05 | SVM | 核方法 | 最大間隔分類器 |
| 06 | Genetic Programming | 演化計算 | 符號回歸、公式發現 |

### 🛠️ 類別不平衡處理
- **LR/RF/XGBoost/SVM**: `class_weight='balanced'`
- **ANN**: Custom class weight dictionary
- **GP**: ❌ gplearn 不支援 (致命缺陷)

### 📢 講稿 (1分鐘)

為了全面評估不同模型的表現,我們總共測試了6種模型,涵蓋了從傳統統計到前沿演化計算的各種方法。包括最經典的Logistic Regression、Random Forest和XGBoost這些集成學習方法、深度學習的Neural Networks、支援向量機SVM,以及較新的Genetic Programming。我們選擇AUC作為主要評估指標,因為它能有效衡量模型的區分能力,不受類別不平衡影響。同時也關注F1分數和Recall,特別是Recall在疾病篩檢中非常重要,因為我們希望能捕捉到盡可能多的潛在患者。針對類別不平衡問題,我們在大部分模型中使用了class_weight='balanced'機制,讓模型更重視少數類別的樣本。但要特別注意的是,Genetic Programming因為套件限制無法使用這個機制,這也成為它後來失敗的主要原因。

---

## Slide 3: 模型效能總覽 (AUC 比較)

### 🏆 完整效能排名表

| 疾病 | 🥇 第一名 | 🥈 第二名 | 🥉 第三名 | 第四名 | 第五名 | 第六名 |
|------|-----------|-----------|-----------|---------|--------|--------|
| **高血壓** | **ANN** 0.803 | **RF** 0.796 | XGBoost 0.795 | SVM 0.793 | LR 0.749 | **GP 0.714** |
| **高血糖** | **LR** 0.931 | **MTL RF** 0.914 | SVM 0.904 | XGBoost 0.903 | ANN 0.899 | RF 0.892 |
| **高血脂** | **LR** 0.888 | XGBoost 0.886 | **RF** 0.868 | ANN 0.861 | SVM 0.858 | **GP 0.500** |

### 📊 關鍵發現
1. **沒有單一最佳模型** - 不同疾病最佳模型不同
2. **LR 表現驚豔** - 在高血糖/高血脂達到最佳 AUC
3. **ANN 高血壓最佳** - AUC 0.803 (超越所有模型)
4. **RF 穩定優秀** - 三個疾病都在前四名 (第2-3名)
5. **MTL RF 突破** - 高血糖 AUC=0.914 達到第2名！
6. **XGBoost 最穩定** - 三個疾病都在前三名
7. **GP 全面失敗** - 高血脂 AUC=0.5 (隨機猜測)

### ⚡ 訓練速度
- LR/RF/XGBoost/SVM: **秒級** (~1-11 秒)
- ANN: **分鐘級** (~數分鐘)
- GP: **3.8 分鐘** (快但無用)

### 📢 講稿 (1分鐘)

現在來看整體的模型效能比較。這張表格展示了各模型在三種疾病上的AUC排名,我們可以看到一個非常重要的發現:沒有單一最佳模型。不同疾病的最佳模型完全不同。在高血壓預測上,ANN以0.803的AUC拿下冠軍,Random Forest和XGBoost緊追在後。但在高血糖和高血脂的預測上,最簡單的Logistic Regression反而表現最好,AUC分別達到0.931和0.888,這真的讓我們相當驚訝。XGBoost展現了最穩定的表現,在三種疾病上都進入前三名。Random Forest也相當穩定,特別值得一提的是它的多任務學習版本在高血糖預測上達到第二名,AUC 0.914。最讓人失望的是Genetic Programming,在高血脂上的AUC只有0.5,等於隨機猜測。從訓練速度來看,除了ANN需要幾分鐘,其他模型都在秒級完成,非常有效率。

---

## Slide 4: Logistic Regression 成果 (03)

### 📈 效能表現

| 疾病 | AUC | F1 | Recall | 排名 |
|------|-----|-----|--------|------|
| 高血壓 | 0.749 | 0.425 | **0.728** | 🥉 第4名 |
| 高血糖 | **0.931** | 0.470 | **0.816** | 🥇 **冠軍** |
| 高血脂 | **0.888** | 0.323 | **0.833** | 🥇 **冠軍** |

### ✅ 優勢
1. **超高 AUC** (高血糖/高血脂)
   - 高血糖 AUC=0.931 (領先第二名 0.027)
   - 高血脂 AUC=0.888 (領先第二名 0.002)
2. **最高 Recall** (全部疾病)
   - 高血糖 Recall=0.816 (捕捉 81.6% 患者)
   - 高血脂 Recall=0.833 (捕捉 83.3% 患者)
3. **極快訓練速度** (~1 秒)
4. **完美可解釋性** - 提供係數和 Odds Ratio

### 📊 特徵重要性 (Top 3)
- **高血壓**: SBP_T2, DBP_T2, Delta1_SBP
- **高血糖**: FBG_T2, FBG_T1, Delta1_FBG
- **高血脂**: TC_T2, TC_T1, BMI_T2

### 💡 結論
**Logistic Regression 是本研究的最大驚喜！**
適合：醫學應用（高 Recall）、快速部署、臨床解釋

### 📢 講稿 (1分鐘)

接下來詳細介紹各個模型,首先是Logistic Regression,它可以說是本研究最大的驚喜。在高血糖預測上,它達到了0.931的AUC,領先第二名0.027,是所有模型中的冠軍。在高血脂預測上也是第一名,AUC 0.888。更重要的是,它在所有三種疾病上都展現了最高的Recall,高血糖和高血脂的Recall都超過80%,意味著能夠捕捉到超過八成的潛在患者,這在臨床篩檢上非常關鍵。從特徵重要性來看,模型的預測也很符合醫學常識,像高血壓主要看收縮壓和舒張壓,高血糖看空腹血糖,高血脂看總膽固醇。此外,Logistic Regression訓練速度極快,只需要1秒左右,而且提供完整的係數解釋,醫師可以直接理解每個因素的影響。這些優勢讓它成為醫學應用的首選模型。

---

## Slide 5: XGBoost 與 ANN 成果 (04, 05)

### 🌳 XGBoost (04) - 最穩定的通用模型

| 疾病 | AUC | F1 | Recall | 排名 |
|------|-----|-----|--------|------|
| 高血壓 | 0.795 | **0.464** | 0.619 | 🥈 第2名 |
| 高血糖 | 0.903 | **0.537** | 0.579 | 🥉 第3名 |
| 高血脂 | 0.886 | **0.449** | 0.538 | 🥈 第2名 |

**特色**：
- ✅ **最高 F1 分數** (所有疾病)
- ✅ **平衡效能** (Precision vs Recall)
- ✅ **特徵重要性分析** (可解釋性)
- ✅ **訓練快速** (~秒級)

---

### 🧠 Neural Networks (05) - 高血壓冠軍

| 疾病 | AUC | F1 | Recall | 排名 |
|------|-----|-----|--------|------|
| 高血壓 | **0.803** | 0.467 | **0.812** | 🥇 **冠軍** |
| 高血糖 | 0.899 | 0.467 | 0.658 | 第4名 |
| 高血脂 | 0.861 | 0.330 | 0.731 | 🥉 第3名 |

**架構**：
```
Input (26) → Dense(64, ReLU) → Dropout(0.3)
          → Dense(32, ReLU) → Dropout(0.3)
          → Output(1, Sigmoid)
```

**特色**：
- 🥇 **高血壓最佳模型** (AUC=0.803)
- ✅ 最高 Recall (高血壓 81.2%)
- ⚠️ 訓練時間較長 (~分鐘級)

---

### 💡 Multi-Task Learning (MTL) 探索

**MTL ANN 結果**：
- ❌ 高血脂 F1=0 (完全失敗)
- **問題**：共享參數被高血壓主導 (16.7% vs 6%)

**解決方案**：
```python
model.compile(
    loss_weights=[1.0, 3.0, 3.0]  # 給少數類更高權重
)
```

### 📢 講稿 (1分鐘)

接著比較XGBoost和類神經網路的表現。XGBoost展現了最穩定的通用性能,在所有三種疾病上都進入前三名,而且在F1分數上全部拿下第一,顯示它在精確率和召回率之間取得了最好的平衡。訓練速度也很快,只需要幾秒鐘,加上能提供特徵重要性分析,使它成為實務部署的理想選擇。另一方面,類神經網路在高血壓預測上表現最出色,AUC達到0.803,是所有模型中的冠軍,Recall也高達81.2%。我們使用的架構相當簡潔,兩層隱藏層配合Dropout防止過擬合。不過ANN的訓練時間較長,需要幾分鐘,可解釋性也比較差。我們也嘗試了多任務學習,但初步的MTL ANN在高血脂上完全失敗,F1分數是0,主要問題是共享參數被樣本數較多的高血壓主導了。我們提出的解決方案是調整loss weights,給少數類更高的權重。

---

## Slide 6: Random Forest 成果 (03)

### 🌲 Random Forest - 穩定高效的集成學習

| 疾病 | AUC | F1 | Recall | 排名 |
|------|-----|-----|--------|------|
| 高血壓 | 0.796 | 0.065 | 0.035 | 🥈 第2名 |
| 高血糖 | 0.892 | 0.263 | 0.171 | 第6名 |
| 高血脂 | 0.868 | 0.140 | 0.077 | 🥉 第3名 |

### ✅ 優勢
1. **穩定的排名表現**
   - 高血壓 AUC=0.796 (第2名，僅次於 ANN)
   - 高血脂 AUC=0.868 (第3名)
   - 三個疾病都在前六名
2. **原生多輸出支援** (Multi-output)
   - 單一模型可同時預測三種疾病
   - 減少訓練和部署複雜度
3. **極快訓練速度** (~秒級)
   - 與 LR/XGBoost 同級別
4. **良好可解釋性**
   - 特徵重要性分析 (feature_importances_)
   - 決策樹可視覺化

### 🎯 Multi-Task Learning (MTL) 突破

**MTL Random Forest 結果**：
- 高血糖: AUC=**0.914** (🥈 第2名！)
- 高血壓: AUC=0.787
- 高血脂: AUC=? (資料不完整)

**關鍵發現**：
- ✅ **MTL RF 在高血糖達到第2名**，僅次於 LR (0.931)
- ✅ 證明 Random Forest 的多輸出特性可有效處理 MTL 任務
- ✅ 相較於單任務 RF (0.892)，MTL 提升了 0.022 AUC

### ⚠️ 劣勢
1. **F1 和 Recall 偏低**
   - 雖然 AUC 優秀，但實際預測的精確度不足
   - 可能需要調整 threshold 或 class_weight 參數
2. **高血糖表現中等**
   - 單任務 RF 僅第6名
   - 但 MTL 版本顯著改善

### 💡 結論
**Random Forest 是穩定高效的通用選擇！**
- 適合：快速原型、多疾病聯合預測、需要特徵重要性分析
- MTL RF 在高血糖的優異表現值得進一步探索

### 📢 講稿 (1分鐘)

Random Forest在這個研究中也展現了相當優異的表現。在高血壓預測上拿下第二名,AUC 0.796,僅次於ANN。在高血脂上是第三名,整體排名非常穩定。Random Forest有個很大的優勢是原生支援多輸出,也就是單一模型可以同時預測三種疾病,這在實務部署上可以大幅降低複雜度。訓練速度也很快,跟Logistic Regression和XGBoost一樣都是秒級。最令人興奮的發現是多任務學習版本的Random Forest,在高血糖預測上AUC達到0.914,拿下第二名,僅次於Logistic Regression的0.931。相較於單任務版本的0.892,MTL提升了0.022,充分證明Random Forest的多輸出特性可以有效處理多任務學習。不過它也有劣勢,就是F1和Recall偏低,雖然AUC很高,但實際預測的準確度還需要調整。總的來說,Random Forest是需要快速原型和多疾病聯合預測的理想選擇。

---

## Slide 7: SVM 成果 (06)

### ⚡ SVM (06) - 速度驚喜

| 疾病 | AUC | F1 | Recall | 訓練時間 | 排名 |
|------|-----|-----|--------|----------|------|
| 高血壓 | 0.793 | 0.460 | **0.738** | 5.6秒 | 🥉 第3名 |
| 高血糖 | 0.904 | 0.462 | 0.592 | 2.1秒 | 🥈 第2名 |
| 高血脂 | 0.858 | 0.381 | 0.628 | 3.4秒 | 第4名 |

**驚喜發現**：
- ⚡ **總訓練時間僅 11 秒** (預期 1-2 小時！)
- 🚀 **比預期快 300 倍以上**
- 原因：資料標準化良好、sklearn 優化、樣本數適中

**結論**：穩定的中階表現，但無明顯優勢

### 📢 講稿 (1分鐘)

SVM的實驗結果帶給我們一個意外的驚喜,不是在效能上,而是在訓練速度上。在效能方面,SVM的表現中規中矩,高血壓第三名AUC 0.793,高血糖第二名0.904,高血脂第四名0.858,整體來說是穩定但沒有特別突出的優勢。不過最讓我們驚訝的是訓練速度,三個疾病總共只花了11秒,其中高血糖甚至只要2.1秒就完成了。要知道,我們原本預期SVM在這個資料規模上可能需要1到2小時,結果實際速度比預期快了300倍以上。這主要歸功於良好的資料標準化、sklearn的優化實作,以及我們的樣本數還在適中範圍。雖然速度很快,但SVM在這個任務上並沒有展現明顯優勢,效能不如XGBoost穩定,可解釋性又比不上Logistic Regression,因此在實務上我們不會優先推薦使用SVM。

---

## Slide 8: Genetic Programming 成果 (07)

### 💔 Genetic Programming (07) - 徹底失敗

| 疾病 | AUC | F1 | Recall | 公式 | 排名 |
|------|-----|-----|--------|------|------|
| 高血壓 | 0.714 | 0.000 | 0.000 | `add(log(-0.140), X8)` | ❌ 最差 |
| 高血糖 | 0.838 | 0.026 | 0.013 | `log(mul(X10, -0.140))` | ❌ 最差 |
| 高血脂 | **0.500** | 0.000 | 0.000 | `log(-0.058)` | ❌ **隨機猜測** |

### 🚨 致命問題
1. **高血脂公式是常數** `log(-0.058)`
   - 完全不使用任何特徵
   - AUC=0.5 = 隨機猜測
2. **gplearn 不支援 class_weight**
   - 類別不平衡無法處理
   - 模型傾向預測全部為陰性

### 📊 失敗原因分析
1. ❌ **類別不平衡主導** (5-17% 患病率)
2. ❌ **fitness function 不適合** (log loss)
3. ❌ **特徵數過多** (26 個，GP 適合 5-10 個)
4. ❌ **parsimony coefficient 過高** (過度簡化)

### 💡 學術價值
**有價值的負面結果** - 證明了：
- ✅ class_weight 機制的重要性
- ✅ GP 不適合嚴重不平衡的醫學預測
- ✅ 模型選擇需考慮資料特性

### 📢 講稿 (1分鐘)

Genetic Programming可以說是這個研究中徹底失敗的案例,但它的失敗卻具有重要的學術價值。在高血壓上AUC只有0.714,高血糖0.838,最糟糕的是高血脂AUC只有0.5,等於隨機猜測。當我們檢視它產生的公式時,發現高血脂的公式竟然是一個常數log(-0.058),完全沒有使用任何特徵,這就難怪表現會這麼差。失敗的核心原因是gplearn這個套件不支援class_weight機制,在5%到17%的患病率下,模型根本無法有效處理類別不平衡問題,傾向把所有樣本都預測為陰性。此外,我們的26個特徵對GP來說太多了,它比較適合5到10個特徵的情境。雖然GP失敗了,但這是個非常有價值的負面結果,它證明了class_weight機制的重要性,也告訴我們GP不適合處理嚴重不平衡的醫學預測任務,提醒研究者在選擇模型時必須考慮資料特性。

---

## Slide 9: 實務建議與模型選擇指南

### 🎯 分疾病推薦方案

| 疾病 | 首選模型 | AUC | 理由 | 備選模型 |
|------|----------|-----|------|----------|
| **高血壓** | ANN | 0.803 | 最高準確率 + 高 Recall | RF 0.796 (第2名) |
| **高血糖** | LR | 0.931 | 最佳 AUC + 極快速度 | MTL RF 0.914 (第2名) |
| **高血脂** | LR | 0.888 | 最佳 AUC + 最高 Recall | XGBoost 0.886 (次高) |

---

### 🏆 通用模型推薦

#### 1️⃣ **XGBoost** - 首選通用方案
- ✅ 三個疾病都在前三名
- ✅ 最高 F1 分數 (平衡 Precision/Recall)
- ✅ 提供特徵重要性分析
- ✅ 訓練速度快 (~秒級)
- 📌 **適合**: 實務部署、特徵工程、模型分析

#### 2️⃣ **Logistic Regression** - 最高 CP 值
- ✅ 兩個疾病第一名 (高血糖/高血脂)
- ✅ 所有疾病最高 Recall (醫學應用關鍵)
- ✅ 極快速度 + 完美可解釋性
- 📌 **適合**: 臨床解釋、快速原型、基線模型

#### 3️⃣ **Random Forest** - 多任務學習首選
- ✅ 原生多輸出支援 (單模型預測三種疾病)
- ✅ MTL RF 在高血糖達到第2名 (AUC=0.914)
- ✅ 高血壓第2名、高血脂第3名
- ✅ 訓練速度快 (~秒級)
- ✅ 良好可解釋性 (特徵重要性)
- 📌 **適合**: 多疾病聯合預測、快速原型、需要同時處理三高

#### 4️⃣ **ANN** - 追求極致效能
- ✅ 高血壓最佳模型 (AUC=0.803)
- ⚠️ 訓練時間較長
- ⚠️ 可解釋性差
- 📌 **適合**: 研究用途、追求最高準確率

---

### ❌ 不推薦模型

- **SVM**: 無明顯優勢，可解釋性差
- **GP**: 嚴重失敗，不適合不平衡醫學資料

---

### 🔧 實務部署建議

**如果只能選一個模型**：
```
XGBoost (平衡效能、速度、可解釋性)
```

**如果需要最高 Recall** (疾病篩檢)：
```
Logistic Regression (Recall: 0.73-0.83)
```

**如果需要極致 AUC**：
```
高血壓: ANN (0.803)
高血糖: LR (0.931)
高血脂: LR (0.888)
```

**如果需要多疾病聯合預測**：
```
Random Forest (原生多輸出、MTL 效能優異)
```

### 📢 講稿 (1分鐘)

基於前面的實驗結果,我們整理出清楚的實務建議和模型選擇指南。如果要針對特定疾病選擇模型,高血壓建議使用ANN,因為它有最高的AUC 0.803和Recall。高血糖和高血脂都建議使用Logistic Regression,不僅AUC最高,訓練速度也極快。如果需要一個通用模型來處理所有疾病,我們首推XGBoost,它在三個疾病上都進入前三名,F1分數最高,訓練快速,還能提供特徵重要性分析,非常適合實務部署。Logistic Regression是CP值最高的選擇,兩個疾病第一名,所有疾病都有最高Recall,加上極快的速度和完美的可解釋性,很適合臨床應用。Random Forest則是多任務學習的首選,它原生支援多輸出,MTL版本在高血糖達到第二名,可以用單一模型同時預測三種疾病。ANN適合追求極致效能的研究用途。至於SVM和GP我們不推薦使用,前者沒有明顯優勢,後者則嚴重失敗。

---

## Slide 10: 研究貢獻與未來方向

### 🎓 本研究貢獻

#### 1. **全面的模型比較** (6 種模型 × 3 種疾病)
- 傳統統計 (LR) vs 機器學習 (RF, XGBoost, SVM) vs 深度學習 (ANN) vs 演化計算 (GP)
- 首次在三高預測任務中系統性比較
- Random Forest 展現優異的多任務學習能力

#### 2. **Δ 特徵工程的有效性**
- T2-T1 變化量特徵顯著提升效能
- 縱向資料的時間動態資訊至關重要

#### 3. **類別不平衡處理的重要性**
- class_weight 機制顯著改善少數類預測
- GP 失敗案例證明其必要性

#### 4. **實務建議清晰**
- 分疾病推薦最佳模型
- 提供通用部署方案

#### 5. **有價值的負面結果**
- GP 在不平衡資料上的失敗
- 為模型選擇提供反面教材

---

### 🚀 未來研究方向

#### 1. **Multi-Task Learning 深化**
- ✅ Random Forest MTL 已證明有效 (高血糖 AUC=0.914)
- 進一步優化 MTL ANN 的 loss_weights
- 探索 task-specific 與 shared layers 的最佳比例
- 比較 RF MTL vs ANN MTL 的優劣

#### 2. **集成學習探索**
- Stacking: LR (高血糖/高血脂) + ANN (高血壓) + RF (通用)
- Voting: 結合 RF, XGBoost, LR 前三名模型
- 探索 RF 與 XGBoost 的互補性

#### 3. **深度特徵工程**
- 非線性 Δ 特徵 (如 T2/T1 比值)
- 特徵交互項 (SBP × BMI)

#### 4. **時間序列建模**
- LSTM/GRU 處理 T1→T2→T3 時間序列
- Transformer-based 模型

#### 5. **可解釋性 AI**
- SHAP/LIME 解釋 XGBoost/ANN 預測
- 整合臨床知識的規則抽取

#### 6. **外部驗證**
- 在其他健檢資料集驗證模型泛化能力
- 跨地區、跨族群驗證

---

### 📊 實驗記錄完整性

所有實驗均有完整 Jupyter Notebook：
- `01_EDA.ipynb` - 探索性資料分析
- `02_FeatureEngineering.ipynb` - 特徵工程
- `03_ModelBuilding.ipynb` - Logistic Regression + Random Forest
- `04_XGBoost.ipynb` - XGBoost
- `05_NeuralNetworks.ipynb` - ANN
- `06_SVM.ipynb` - SVM
- `07_GeneticProgramming.ipynb` - GP

**可重現性**: ✅ 所有程式碼、參數、結果已記錄於 GitHub

### 📢 講稿 (1分鐘)

最後總結一下本研究的貢獻和未來方向。我們進行了非常全面的模型比較,6種模型橫跨從傳統統計到演化計算的各個領域,在三高預測任務上進行系統性評估,這在相關研究中是首次。我們證明了Delta特徵工程的有效性,時間動態資訊對預測至關重要。GP的失敗案例也凸顯了class_weight機制和模型選擇的重要性。在未來研究方向上,最令人期待的是深化多任務學習,Random Forest MTL已經在高血糖上證明有效,接下來可以進一步優化ANN MTL的參數,比較不同MTL方法的優劣。集成學習也很值得探索,可以結合各模型的優勢做Stacking或Voting。此外還可以進行更深入的特徵工程,嘗試LSTM等時間序列模型,使用SHAP等工具提升可解釋性,以及在外部資料集上驗證模型的泛化能力。所有實驗都有完整的Jupyter Notebook記錄,確保研究的可重現性。感謝各位的聆聽,謝謝！

---

### 🙏 致謝

感謝指導教授的專業指導與建議！

---

**簡報結束 - 謝謝聆聽！**
