# 第三章 研究方法

## 3.1 研究架構

本研究旨在建立一個基於縱貫性健康檢查資料的三高（高血壓、高血糖、高血脂）風險預測模型。研究架構如圖 3-1 所示，整體流程分為四個階段：資料前處理、特徵工程、模型建立與評估。

![研究架構圖](figures/fig3-1_research_framework.png)

**圖 3-1 研究架構圖**

### 3.1.1 研究時間軸設計

本研究採用三個時間點的縱貫設計，如圖 3-2 所示。

![研究時間軸設計](figures/fig3-1-1_timeline.png)

**圖 3-2 研究時間軸設計**

選擇 T3 而非 T2 作為預測目標的原因：

1. **避免資料洩漏**：若以 T2 為目標，T2 的健檢數據與疾病狀態來自同一次檢查，會造成模型「偷看答案」
2. **Δ 特徵可用**：以 T3 為目標，才能將 T2-T1 的變化量作為有效的預測因子
3. **臨床意義**：提供約 2 年的預警時間窗口，讓醫療人員有足夠時間進行早期介入

---

## 3.2 資料來源與處理

### 3.2.1 資料來源

本研究使用公開於 Dryad 數位資料庫的縱貫性健康檢查資料集 [4]。

該資料集來自中國浙江省杭州市的社區健康調查，收集期間為 2010 至 2018 年，納入 40 歲以上成人共 6,119 人，多數參與者進行了 3 次以上的健康檢查。

資料特點為僅記錄「第幾次健檢」而無具體日期，追蹤間隔以年齡差推算（例如：55 歲 → 57 歲 = 2 年間隔）。經分析，約 90% 的受檢者維持固定 2 年間隔，9.6% 為 1 年間隔（可能為提前回診），平均追蹤間隔為 1.90 年（標準差 0.36 年）。由於間隔高度一致，Δ 特徵可直接比較，無需額外的時間校正。

### 3.2.2 樣本篩選

原始資料集包含 6,119 位參與者共 25,744 筆健檢記錄。由於本研究採用三時間點縱貫設計（T1、T2、T3），需要每位參與者至少有 3 次健檢紀錄才能建構完整的特徵集與預測目標。

**納入條件**：
- 至少有 3 次以上的連續健檢紀錄
- 各時間點資料完整，無重大缺失

**排除情況**：
- 共 63 人因僅有 1-2 次健檢紀錄而被排除
- 資料保留率達 98.97%

**最終樣本數**：6,056 人

篩選後樣本之健檢次數分佈如圖 3-3 所示。約 90% 的樣本健檢次數介於 3 至 5 次之間，其中以 5 次健檢者最多（31.95%），其次為 4 次（29.33%）及 3 次（28.96%）。少數樣本有 6 次以上的健檢紀錄（合計 9.76%）。

![樣本健檢次數分佈](figures/checkup_distribution.png)

**圖 3-3 樣本健檢次數分佈（n = 6,056）**

雖然部分參與者有 4 次以上的健檢紀錄，本研究統一使用每位參與者的前 3 次健檢資料（T1、T2、T3）。此設計的理由如下：

1. **符合早期預測目標**：觀察從首次健檢開始的疾病發展軌跡
2. **資料一致性**：所有參與者從相同起點開始，避免不同進入時間點造成的偏差
3. **避免資料洩漏**：每人僅產生一筆建模紀錄，確保訓練與測試資料的獨立性

### 3.2.3 變數定義

本資料集包含人口學變數、健檢指標及目標變數三類，各變數說明如表 3-2 所示。

**表 3-2 研究變數定義**

| 變數類別 | 變數名稱 | 說明 | 單位/編碼 |
|----------|----------|------|-----------|
| 人口學 | Sex | 性別 | 1=男, 2=女 |
|  | Age | 年齡 | 歲 |
| 健檢指標 | BMI | 身體質量指數 | kg/m² |
|  | SBP | 收縮壓 | mmHg |
|  | DBP | 舒張壓 | mmHg |
|  | FBG | 空腹血糖 | mmol/L |
|  | TC | 總膽固醇 | mmol/L |
|  | Cr | 肌酐 | μmol/L |
|  | GFR | 腎絲球過濾率 | mL/min/1.73m² |
|  | UA | 尿酸 | μmol/L |

本研究之目標變數為三高疾病狀態，其操作型定義依據國際臨床指引如下：

1. **高血壓（Hypertension）**：依據美國國家聯合委員會第八次報告（JNC 8）之診斷標準 [1]，定義為收縮壓 ≥ 140 mmHg 或舒張壓 ≥ 90 mmHg。

2. **高血糖（Hyperglycemia）**：依據美國糖尿病協會（ADA, 2025）之診斷標準 [2]，定義為空腹血糖 ≥ 7.0 mmol/L（126 mg/dL）。

3. **高血脂（Dyslipidemia）**：依據美國國家膽固醇教育計畫成人治療小組第三次報告（ATP III）之診斷標準 [3]，定義為總膽固醇 ≥ 6.2 mmol/L（240 mg/dL）。

原始資料中，三項目標變數皆以 1 = 正常、2 = 患病 進行編碼，本研究於建模前將其轉換為 0 = 正常、1 = 患病 之二元格式。

### 3.2.4 類別不平衡情況

三高疾病在本資料集中呈現不同程度的類別不平衡。在 6,056 位樣本中，高血壓患者共 1,010 人（16.68%），負正類比例約為 5:1，屬於輕度不平衡；高血糖患者共 335 人（5.53%），負正類比例約為 17:1；高血脂患者共 361 人（5.96%），負正類比例約為 16:1，兩者皆屬於重度不平衡。

此類別不平衡現象反映了真實世界中三高疾病的盛行率特性，但可能導致模型偏向預測多數類（健康），進而降低對少數類（患病）的識別能力。因此，本研究將於模型訓練階段採用 class_weight 方法進行調整，詳見 3.4.7 節。

---

## 3.3 特徵工程

### 3.3.1 特徵集設計

本研究使用的特徵分為四類，共 26 個特徵，如表 3-3 所示。

**表 3-3 特徵集設計**

| 特徵類別 | 包含特徵 | 特徵數 |
|----------|----------|--------|
| 基本資訊 | Sex, Age | 2 |
| T1 時間點特徵 | FBG_T1, TC_T1, Cr_T1, UA_T1, GFR_T1, BMI_T1, SBP_T1, DBP_T1 | 8 |
| T2 時間點特徵 | FBG_T2, TC_T2, Cr_T2, UA_T2, GFR_T2, BMI_T2, SBP_T2, DBP_T2 | 8 |
| Δ 特徵（T2−T1） | Delta1_FBG, Delta1_TC, Delta1_Cr, Delta1_UA, Delta1_GFR, Delta1_BMI, Delta1_SBP, Delta1_DBP | 8 |
| 合計 | — | 26 |

### 3.3.2 Δ 特徵的意義

Δ 特徵代表 T2 與 T1 之間的變化量：

$$\Delta_i = X_{i,T2} - X_{i,T1}$$

Δ 特徵的設計理念：
- **捕捉動態趨勢**：某些疾病的發展不僅取決於當前數值，更取決於變化趨勢
- **正值代表上升**：例如 Delta1_FBG > 0 表示血糖在兩年間上升
- **負值代表下降**：例如 Delta1_GFR < 0 表示腎功能在兩年間下降

---

## 3.4 模型方法

### 3.4.1 Logistic Regression (LR)

Logistic Regression 是一種經典的線性分類模型，適用於二元分類問題。

**模型形式**：

$$P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + ... + \beta_n X_n)}}$$

**選用原因**：
- 可解釋性高：係數可直接解讀為風險因子的貢獻
- 計算效率高：適合作為基準模型
- 支援 class_weight：可處理類別不平衡問題

**實作參數**：
- `solver`: 'lbfgs'
- `max_iter`: 1000
- `class_weight`: 'balanced'（處理類別不平衡）

### 3.4.2 Random Forest (RF)

Random Forest 是一種基於 Bagging 的集成學習方法，透過多棵決策樹的投票產生預測結果。

**演算法原理**：
1. 從原始資料中有放回地抽樣（Bootstrap）產生多個子資料集
2. 在每個子資料集上訓練一棵決策樹，且每次分裂時只考慮部分特徵
3. 最終預測為所有樹的多數決（分類）或平均（回歸）

**選用原因**：
- 抗過擬合：Bagging 降低變異數
- 穩定性高：對異常值和雜訊較不敏感
- 支援 class_weight：可處理類別不平衡問題

**實作參數**：
- `n_estimators`: 100
- `max_depth`: None（完全生長）
- `class_weight`: 'balanced'

### 3.4.3 XGBoost

XGBoost (eXtreme Gradient Boosting) 是一種基於梯度提升的集成學習方法。

**演算法原理**：
透過逐步加入決策樹，每棵新樹專注於修正前面樹的預測誤差：

$$\hat{y}_i^{(t)} = \hat{y}_i^{(t-1)} + f_t(x_i)$$

**選用原因**：
- 預測效能強：在許多醫學預測任務中表現優異
- 可處理非線性關係：能捕捉特徵間的複雜交互作用
- 支援特徵重要性評估

**實作參數**：
- `n_estimators`: 100
- `max_depth`: 6
- `learning_rate`: 0.1
- `scale_pos_weight`: 自動計算（處理類別不平衡）

### 3.4.4 Artificial Neural Network (ANN)

人工神經網路透過多層神經元的非線性轉換學習複雜的特徵表示。

**網路架構**：

- 輸入層：26 個特徵
- 隱藏層：2 層，每層 64 個神經元
- 輸出層：1 個神經元（Sigmoid 激活）

**選用原因**：

- 非線性建模：可學習複雜的特徵交互
- 彈性高：可調整網路深度與寬度
- 支援 class_weight：可處理類別不平衡問題

**實作參數**：

- `hidden_layer_sizes`: (64, 64)
- `activation`: 'relu'
- `solver`: 'adam'
- `max_iter`: 500

### 3.4.5 Support Vector Machine (SVM)

支援向量機透過尋找最大間隔超平面進行分類，並可使用核函數處理非線性問題。

**演算法原理**：
尋找一個超平面 $w^T x + b = 0$，使得兩類樣本之間的間隔最大化。對於非線性問題，使用核函數將資料映射到高維空間。

**選用原因**：

- 理論基礎扎實：基於統計學習理論
- 適合中小型資料集：在樣本數有限時表現良好
- 支援 class_weight：可處理類別不平衡問題

**實作參數**：

- `kernel`: 'rbf'（徑向基函數）
- `C`: 1.0
- `gamma`: 'scale'
- `class_weight`: 'balanced'

### 3.4.6 符號回歸 (Symbolic Regression)

符號回歸透過遺傳規劃（Genetic Programming, GP）演化出可解釋的數學公式。

**演算法原理**：
1. 初始化：隨機生成一群數學公式（個體）
2. 評估：計算每個公式的預測誤差（適應度）
3. 選擇：保留表現較好的公式
4. 演化：透過交叉、突變產生新公式
5. 重複直到收斂

**選用原因**：
- 完全透明：產出的公式可直接理解
- 領域知識驗證：可檢驗公式是否符合醫學邏輯
- 輕量部署：簡單公式不需複雜運算資源

**使用套件**：
- **gplearn**：Python 原生，但不支援 class_weight
- **PySR**：基於 Julia，支援 sample_weight，效能更佳

### 3.4.7 類別不平衡處理

由於三高疾病的患病率較低（5-17%），本研究採用 class_weight 方法處理類別不平衡：

$$w_i = \frac{n_{samples}}{n_{classes} \times n_{samples_i}}$$

其中 $w_i$ 為第 $i$ 類的權重，$n_{samples}$ 為總樣本數，$n_{classes}$ 為類別數，$n_{samples_i}$ 為第 $i$ 類的樣本數。

**balanced 設定的效果**：
- 增加少數類（患病者）在損失函數中的權重
- 讓模型更注重正確識別患病者
- 提升 Sensitivity，但可能犧牲部分 Specificity

---

## 3.5 模型評估

### 3.5.1 資料切分

本研究採用 80/20 比例進行訓練集與測試集切分，並使用分層抽樣（stratified sampling）確保各類別比例一致，資料切分結果如表 3-4 所示。

**表 3-4 訓練集與測試集切分**

| 資料集 | 樣本數 | 百分比（%） |
|--------|--------|-------------|
| 訓練集 | 4,845 | 80.0 |
| 測試集 | 1,211 | 20.0 |
| 合計 | 6,056 | 100.0 |

### 3.5.2 評估指標

#### AUC-ROC (Area Under the ROC Curve)

ROC 曲線以 False Positive Rate 為 X 軸，True Positive Rate 為 Y 軸，AUC 為曲線下面積。

- AUC = 0.5：隨機猜測
- AUC = 0.7-0.8：可接受
- AUC = 0.8-0.9：良好
- AUC > 0.9：優秀

**特點**：與分類閾值無關，反映模型的整體排序能力。

#### Sensitivity（敏感度/召回率）

$$Sensitivity = \frac{TP}{TP + FN}$$

代表模型正確識別患病者的能力。在疾病篩檢中，高 Sensitivity 意味著較少漏診。

#### Specificity（特異度）

$$Specificity = \frac{TN}{TN + FP}$$

代表模型正確排除健康者的能力。高 Specificity 意味著較少誤診。

#### F1-Score

$$F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}$$

精確率與召回率的調和平均，適用於類別不平衡的情況。

#### 混淆矩陣

混淆矩陣（Confusion Matrix）為評估分類模型效能的基礎工具，用於呈現模型預測結果與實際類別之間的對應關係。在二元分類問題中，混淆矩陣包含四個元素：

- **True Positive（TP，真陽性）**：實際為患病且模型正確預測為患病的樣本數
- **True Negative（TN，真陰性）**：實際為健康且模型正確預測為健康的樣本數
- **False Positive（FP，偽陽性）**：實際為健康但模型錯誤預測為患病的樣本數（第一類錯誤）
- **False Negative（FN，偽陰性）**：實際為患病但模型錯誤預測為健康的樣本數（第二類錯誤）

上述評估指標 Sensitivity、Specificity 及 F1-Score 皆由混淆矩陣之四個基本元素計算而得。在疾病預測的臨床應用中，False Negative（漏診）通常比 False Positive（誤診）的後果更為嚴重，因此本研究特別重視 Sensitivity 指標的表現。

---

## 3.6 實驗設計

### 3.6.1 消融實驗

#### Δ 特徵消融實驗

為驗證 Δ 特徵對預測效能的貢獻，本研究設計五組特徵組合進行消融實驗，如表 3-6 所示。

**表 3-6 Δ 特徵消融實驗設計**

| 實驗組 | 特徵組合 | 特徵數 | 說明 |
|--------|----------|--------|------|
| Full | T1 + T2 + Δ | 26 | 完整特徵集 |
| No-Δ | T1 + T2 | 18 | 移除 Δ 特徵 |
| T1-Only | T1 | 10 | 僅使用基線值 |
| T2-Only | T2 | 10 | 僅使用最近值 |
| Δ-Only | Δ | 10 | 僅使用變化量 |

#### class_weight 消融實驗

為探討 class_weight 參數對模型 Sensitivity 與 Specificity 平衡的影響，本研究設計五種權重設定進行消融實驗，如表 3-7 所示。

**表 3-7 class_weight 消融實驗設計**

| 實驗組 | 權重設定 | 說明 |
|--------|----------|------|
| None | 1:1 | 無權重調整，使用原始分佈 |
| balanced | 自動計算 | 依類別比例自動平衡 |
| 1:3 | 手動設定 | 正類權重為負類 3 倍 |
| 1:5 | 手動設定 | 正類權重為負類 5 倍 |
| 1:10 | 手動設定 | 正類權重為負類 10 倍 |

### 3.6.2 可解釋性分析

本研究使用 SHAP (SHapley Additive exPlanations) 進行模型可解釋性分析：

- **SHAP 值**：量化每個特徵對預測結果的貢獻
- **特徵重要性排序**：識別最具影響力的風險因子
- **交互效應**：分析特徵間的協同或拮抗作用

---

## 3.7 實驗環境

本研究之實驗環境與使用套件如表 3-8 所示。

**表 3-8 實驗環境與工具**

| 類別 | 項目 | 規格/版本 |
|------|------|-----------|
| 硬體環境 | 處理器 | Intel Core i7-11700 @ 2.50GHz (8 核心) |
|  | 記憶體 | 32 GB DDR4 3200 MHz |
|  | 顯示卡 | NVIDIA GeForce RTX 3050 (6 GB VRAM) |
|  | 儲存裝置 | SSD (ADATA SX8200PNP + WDC WDS200T2B0A) |
| 軟體環境 | 作業系統 | Windows 10 專業版 |
|  | 程式語言 | Python 3.10 |
|  | 開發環境 | Jupyter Notebook, VS Code |
| 主要套件 | 機器學習 | scikit-learn, XGBoost |
|  | 神經網路 | MLPClassifier (scikit-learn) |
|  | 符號回歸 | gplearn, PySR |
|  | 可解釋性 | SHAP |
|  | 資料處理 | pandas, numpy |
|  | 視覺化 | matplotlib, seaborn |
