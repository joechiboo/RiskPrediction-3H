# Memo 20: GP 收斂分析（gplearn vs PySR）

> **日期**：2025-12-30
> **主題**：演化代數與收斂行為比較

---

## gplearn 收斂分析

來源：`results/11_GP_Parameter_Tuning_output.txt`

### 高血壓實驗（gen=100, ts=2）

| 代數 | Best Fitness | 觀察 |
|------|-------------|------|
| Gen 0 | 0.472 | 初始 |
| Gen 3 | 0.452 | 快速改善 |
| Gen 12 | 0.417 | **最佳點** |
| Gen 20~32 | 0.424~0.452 | 開始震盪 |
| Gen 33~100 | 0.451~0.452 | **完全停滯** |

**結論**：gplearn 約在 **Gen 10~20 就收斂**，之後 80 代幾乎沒有改善。

### 不同設定比較

| 設定 | AUC | 訓練時間 | 觀察 |
|------|-----|----------|------|
| gen=20, ts=20 | 0.745 | 2.0 分鐘 | 原始設定 |
| gen=20, ts=2 | 0.704 | 2.0 分鐘 | 降低選擇壓力 |
| gen=50, ts=2 | 0.500 | 4.2 分鐘 | 反而變差 |
| gen=100, ts=2 | 0.544 | 9.0 分鐘 | 增加代數無幫助 |

---

## PySR 收斂分析

來源：`results/12_PySR_Experiment_output.txt`

### 設定與實際執行

- **設定**：`niterations=200`
- **內部機制**：每個 iteration 有 15 個 ncycles，共 3000 total iterations
- **實際執行**：高血壓只跑到 **990/3000 iterations（33%）** 就停止

### 高血壓實驗

| 階段 | Iterations | 進度 | 觀察 |
|------|------------|------|------|
| 開始 | 0 | 0% | 初始化 |
| 早期 | 200 | 6.7% | 找到簡單公式 |
| 中期 | 500 | 16.7% | 公式穩定 |
| 停止 | 990 | **33%** | 提早收斂，輸出結果 |

**訓練時間**：20.7 分鐘（但只用了 1/3 的預算）

### PySR 為什麼提早停止？

PySR 有內建的收斂檢測機制：
1. 當最佳公式一段時間沒有改善
2. 複雜度-準確度的 Pareto front 穩定
3. 自動提早終止以節省時間

---

## 比較總結

| 項目 | gplearn | PySR |
|------|---------|------|
| 設定代數 | 100 | 200 (×15 = 3000) |
| 實際收斂 | ~20 代 | ~33% iterations |
| 收斂檢測 | ❌ 無 | ✅ 有 |
| 訓練時間 | 9 分鐘（跑滿） | 20.7 分鐘（提早停止） |
| 最終 AUC | 0.544 | 0.745 |

**關鍵差異**：
- gplearn 會跑滿所有代數，即使早已收斂
- PySR 有智能提早停止，效率更高
- PySR 最終效能更好（0.745 vs 0.544）

---

## 建議

1. **gplearn**：gen=20~30 足夠，增加代數無意義
2. **PySR**：`niterations=200` 設定合理，系統會自動判斷何時停止
3. **根本問題**：收斂不是問題，**class_weight 不支援**才是 gplearn 失敗主因
